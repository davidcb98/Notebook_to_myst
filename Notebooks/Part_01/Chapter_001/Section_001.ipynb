{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddaeb38",
   "metadata": {},
   "source": [
    "<figure><center>\n",
    "<img   src=\"../../Figuras/Fig_logo_UMA_scbi.png\" align=center  width=\"2000px\"/>\n",
    "</center></figure>\n",
    "\n",
    "$ \\newcommand{\\bra}[1]{\\langle #1|} $\n",
    "$ \\newcommand{\\ket}[1]{|#1\\rangle} $\n",
    "$ \\newcommand{\\braket}[2]{\\langle #1|#2\\rangle} $\n",
    "$ \\newcommand{\\i}{{\\color{blue} i}} $ \n",
    "$ \\newcommand{\\Hil}{{\\cal H}} $\n",
    "$ \\newcommand{\\cg}[1]{{\\rm C}#1} $\n",
    "$ \\newcommand{\\lp}{\\left(} $\n",
    "$ \\newcommand{\\rp}{\\right)} $\n",
    "$ \\newcommand{\\lc}{\\left[} $\n",
    "$ \\newcommand{\\rc}{\\right]} $\n",
    "$ \\newcommand{\\lch}{\\left\\{} $\n",
    "$ \\newcommand{\\rch}{\\right\\}} $\n",
    "$ \\newcommand{\\Lp}{\\Bigl(} $\n",
    "$ \\newcommand{\\Rp}{\\Bigr)} $\n",
    "$ \\newcommand{\\Lc}{\\Bigl[} $\n",
    "$ \\newcommand{\\Rc}{\\Bigr]} $\n",
    "$ \\newcommand{\\Lch}{\\Bigl\\{} $\n",
    "$ \\newcommand{\\Rch}{\\Bigr\\}} $\n",
    "$ \\newcommand{\\rqa}{\\quad \\Rightarrow \\quad} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fe82e",
   "metadata": {},
   "source": [
    "\\section*{Código de colores}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Teoremas, Lemmas, Definiciones, Demostraciones y conceptos importantes\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{mybox_gray}{Cuadros grises con bordes}\n",
    "Ejercicios\n",
    "\\end{mybox_gray}\n",
    "\n",
    "\\begin{mybox_blue}{Cuadros azules}\n",
    "Notas o aclaraciones\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_green}{Cuadros verdes}\n",
    "Ejemplos\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\begin{mybox_orange}{Cuadros naranjas}\n",
    "Referencias a cuadernos de Jupyter Notebook\n",
    "\\end{mybox_orange}\n",
    "\n",
    "\\part{Conceptos básicos}	 \\label{part_conceptos_basicos}\n",
    "\n",
    "\\chapter{Formalismo matemático} \\label{cap_formalismo}\n",
    "\n",
    "La Mecánica Cuántica (así como la Computación Cuántica) hace uso de unas matemáticas con las que es necesario familiarizarse. En esta capítulo vamos a repasar el formalismo matemático básico para el resto del curso.\n",
    "\n",
    "A pesar de que la expresión ``formalismo matemático'' puede llegar a imponer respeto, a lo largo de este capítulo veremos que las cosas son más simples de lo que pudieran parecer en un principio. La Mecánica Cuántica  alcanza unos niveles de complejidad matemática insospechados, pero al mismo tiempo es sorprendente como se pueden entender los fundamentos de la misma con una serie de pinceladas de ciertos conceptos matemáticos: \\textit{numeros complejos}, \\textit{vectores}, \\textit{operadores (matrices)}, \\textit{tensores} y algo de \\textit{probabilidad}.\n",
    "\n",
    "Los conceptos que se presentan a continuación están un pasito por encima del nivel de matemáticas de bachillerato, pero no mucho más. Nuestro objetivo es entender las bases de la Mecánica Cuántica, sin llegar a plantearnos trabajar de forma seria con sus ecuaciones. Es decir, ser capaces de entender los conceptos y trabajar con las soluciones, no con las ecuaciones. Por este motivo, los conceptos matemáticos más complejos como integrales o resolución de ecuaciones diferenciales están más allá del objetivo de este curso.\n",
    "\n",
    "En resumen, no hay que tener miedo a las matemáticas de este curso, son sencillas. \n",
    "\n",
    "Este capítulo se basa en \\cite{Curso-JMas}, que a su vez toma como referencias los capítulo 2 de  \\cite{Claude}, \\cite{le_bellac_2006} y \\cite{khatri2020principles}\n",
    "\n",
    "\\section{Números complejos}\n",
    "\n",
    "\\subsection{Introducción}\n",
    "\n",
    "Para entender de donde surge la idea de los número complejos, tenemos que recordar primero que el cuadrado de cualquier número real, $a \\in \\mathbb{R}$, es \\textit{siempre} positivo: $a^2 > 0$. Por ejemplo\n",
    "\\begin{equation*}\n",
    "2^2 = (-2)^2 = +4\n",
    "\\end{equation*}\n",
    "Por eso, la raíz cuadrada de un número real \\textit{sólo} existe (como número real) si el número es positivo y tiene dos soluciones, la positiva y la negativa:\n",
    "\\begin{equation*}\n",
    "\\sqrt{4} = \\pm 2\n",
    "\\end{equation*}\n",
    "En este punto, surge la siguiente pregunta: cual es la solución de la siguiente ecuación?\n",
    "\\begin{equation}\n",
    "x^2 + 1 = 0 \\rqa x^2 = -1 \\rqa x = \\sqrt{-1}\n",
    "\\end{equation}\n",
    "Como comentamos, no hay ningún número real que cumpla esa ecuación. Podemos pues, definir un nuevo número. Este número no pertenece a los números reales:\n",
    "\n",
    "\\Definicion{Se postula la existencia de un número, $i$, que es solución de la ecuación\n",
    "\\begin{equation}\n",
    "i^2 = -1\n",
    "\\end{equation}}\n",
    "\n",
    "Equivalentemente $i = \\sqrt{-1}$. No hay nada misterioso en $i$, se puede sumar, restar, multiplicar y dividir normalmente:\n",
    "\\begin{align*}\n",
    "i + i & = 2i \\\\\n",
    "i - i & = 0 \\\\\n",
    "i + 2i & = 3i \\\\\n",
    "i^3 & = i^2 \\cdot i = -i \\\\\n",
    "i^4 & = i^2 \\cdot i^2  = 1 \\\\\n",
    "\\frac{i}{i} & = 1\n",
    "\\end{align*}\n",
    "\n",
    "Una vez definido este número, podemos resolver cualquier raíz con un número negativo:\n",
    "\\begin{equation}\n",
    "x^2 + 4 = 0  \\rqa x = \\sqrt{-4} = \\sqrt{4} \\sqrt{-1} = 2i\n",
    "\\end{equation}\n",
    "\n",
    "En resumen: la solución pasa por ampliar el conjunto de los número reales definiendo un nuevo conjunto, el de los \\textbf{números imaginarios} o \\textbf{complejos}, $\\mathbb{C}$\n",
    "\n",
    "\\subsection{Forma cartesiana, polar y conjugación compleja}\n",
    "\n",
    "Los números complejos pueden escribirse de dos formas diferentes: la forma \\textbf{cartesiana} y la forma \\textbf{polar}.\n",
    "\n",
    "\\SubsubiIt{Forma cartesiana}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Un \\textit{número complejo}, $z \\in \\mathbb{C}$, se representa en la \\textbf{forma cartesiana} mediante dos números reales $x,y \\in \\mathbb{R}$,\n",
    "\\begin{equation}\n",
    "z = x + iy \\hspace{0.5cm} \\text{donde} \\hspace{0.5cm} \n",
    "\\lch \n",
    "\\begin{split}\n",
    "x & \\quad \\text{ es la \\textit{parte real}} \\\\\n",
    "y & \\quad \\text{ es la \\textit{parte imaginaria}} \\\\\n",
    "\\end{split}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Como podemos ver, tenemos dos casos:\n",
    "\\begin{itemize}\n",
    "\\item Si $y=0 \\rightarrow z = x$ es un \\textbf{número real puro}. \n",
    "\\item Si $x = 0 \\rightarrow z = iy$ es un \\textbf{número imaginario puro}.\n",
    "\\end{itemize}\n",
    "Aquí podemos ver perfectamente que los número complejos (o imaginarios) son una extensión de los números reales, en el sentido de que los engloban: como acabamos de ver, un número real puede verse como un número complejo con la parte imaginaria igual a cero.\n",
    "\n",
    "Es bien conocido que los números reales se representan sobre una recta, la \\textbf{recta real}. Los números complejos por su parte se representan en un plano, el \\textbf{plano complejo}, donde el eje horizontal es la recta real y el eje vertical es el eje imaginario. Esto se ve precisamente muy bien en la forma cartesiana, pues $x$ sería el valor del eje real e $y$ sería el valor del eje imaginario. Podemos ver esto más claramente en la Fig. \\ref{Fig_formalismo_Complex_number_illustration_modarg}. \n",
    "\n",
    "\\begin{figure}[H] \\setcounter{subfigure}{0}\n",
    "\\centering\n",
    "\\subfigure[Representación de un número $z=a+bi$ en el plano complejo. \\label{Fig_formalismo_Complex_number_illustration}]{\\includegraphics[width=0.3\\linewidth]{Figuras/Fig_formalismo_Complex_number_illustration.png}}\n",
    "\\hspace{0.5cm}\n",
    "\\subfigure[Representación polar de un número complejo $z = x +iy$. En el texto se usan $\\rho$ y $\\theta$ en lugar de $r$ y $\\phi$, pero es lo mismo. \\label{Fig_formalismo_Complex_number_illustration_modarg}]{\\includegraphics[width=0.3\\linewidth]{Figuras/Fig_formalismo_Complex_number_illustration_modarg.png}}\n",
    "\\hspace{0.5cm}\n",
    "\\subfigure[Un número complejo y su conjugado \\label{Fig_formalismo_conjugación}]{\\includegraphics[width=0.3\\linewidth]{Figuras/Fig_formalismo_conjugación.png}}\n",
    "\\caption{Representaciones de números en el plano complejo.}\n",
    "\\end{figure}\n",
    "\n",
    "\\SubsubiIt{Forma Polar}\n",
    "\n",
    "\\Teorema{Dado un ángulo $\\theta \\in [0,2 \\pi)$ las dos expresiones siguientes son equivalentes\n",
    "\\begin{equation}\n",
    "\\cos \\theta + i \\sin \\theta = e^{i \\theta}\n",
    "\\end{equation}\n",
    "A esta identidad se la denomina \\textbf{Fórmula de Euler}.}\n",
    "\n",
    "\\begin{proof}\n",
    "La demostración de la Fórmula de Euler viene de expandir ambos miembros en serie de Taylor en torno a $\\theta = 0$ y comprobar que ambas series son iguales\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "e^{i\\theta} &=& 1 + i\\theta + \\frac{1}{2}(i\\theta)^2 + \\frac{1}{3!}(i\\theta)^3+\\, ... \\\\\n",
    "&=& 1 -\\frac{1}{2}\\theta^2 ~+~ ... ~+~ i \\left(\\theta - \\frac{1}{3!} \\theta^3+ \\, ...\\right) \\\\\n",
    "&=& \\cos \\theta  + i \\sin \\theta \n",
    "\\end{array} \n",
    "$$\n",
    "\\end{proof}\n",
    "\n",
    "Con esto, veamos lo que es la forma polar:\n",
    "\\begin{mybox_gray2}{}\n",
    "El número $z=x + i y$ se puede representar en \\textbf{forma polar}\n",
    "\\begin{equation}  \\label{ec_formalismo_forma_polar}\n",
    "z = \\rho e^{i\\theta} = \\rho (\\cos\\theta + i \\sin\\theta)  \n",
    "\\end{equation}\n",
    "de donde obtenemos las componentes cartesianas \n",
    "\\begin{equation}\n",
    "x=\\rho\\cos\\theta ~~,~~y=\\rho\\sin\\theta.\n",
    "\\end{equation}\n",
    "Tanto $\\rho$ como $\\theta$ son números reales y se denominan \\textbf{módulo} y \\textbf{fase}.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "En principio, esta forma de representar los números complejos puede parecer rara, pero es muy fácil de entender. Para ello, solo hay que recordar que los números complejos los podemos representar en un plano. Los puntos en un plano pueden verse como \\textbf{vectores} que parten del origen y cuya punta acaba en el punto que queremos describir. La forma habitual de referirse a estos vectores (puntos) es usar las coordenadas sobre los dos ejes, es decir, usar lo que en matemáticas se llama \\textbf{sistema de coordenadas cartesiano} (ver la Fig. \\ref{Fig_formalismo_Complex_number_illustration_modarg}). Sin embargo, otra forma de describir estos puntos es usando el módulo del vector (su longitud) y el ángulo que este forma con el eje horizontal (ver la Fig. \\ref{Fig_formalismo_Complex_number_illustration_modarg}). A esta forma de describir el plano se la llama \\textbf{sistema de coordenadas polar}.\n",
    "\n",
    "La forma polar que acabamos de ver de los número complejos (Ec. \\ref{ec_formalismo_forma_polar}) no es más que describir el número complejo usando el sistema de coordenadas polar. En concreto, el número real $\\rho$ es el módulo del vector y el número real $\\theta$ es su fase, es decir, el ángulo con el eje horizontal. Usando el \\textbf{teorema de Pitágoras} para los triángulos rectángulos es muy fácil comprobar que $\\rho$ es el módulo si tenemos en cuenta que $x$ e $y$ son los catetos:\n",
    "$$\n",
    "x^2 + y^2 = \\rho^2 \\cos^2 \\theta + \\rho^2 \\sin^2 \\theta = \\rho^2 (\\cos^2 \\theta +  \\sin^2 \\theta) =  \\rho^2.\n",
    "$$\n",
    "\n",
    "\\begin{mybox_blue}{Números con módulo 1}\n",
    "Como ya comentamos, a $\\theta$ se le denomina \\textbf{fase}. Habitualmente también se denominan fases a los números complejos con $\\rho =1$ pues en estos casos tenemos $z = e^{i \\theta}$. Esto es un abuso del lenguaje pero es algo muy extendido.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Conversión entre forma cartesiana y polar}\n",
    "\n",
    "La conversión de la representación \\textit{polar a cartesiana} es muy sencilla gracias a las fórmula de Euler\n",
    "\\begin{equation}\n",
    "\\boxed{z = r e^{i\\theta} = x + i y ~~~\\hbox{ con }  ~~~\\left\\{\\begin{array}{l} x=r \\cos \\theta \\\\ \\rule{0mm}{4mm} y = r\\sin \\theta . \\end{array} \\right. }\n",
    "\\end{equation}\n",
    "La conversión inversa, \\textit{de cartesiana a polar} es un poco más delicada. Formalmente sería\n",
    "\\begin{equation} \\label{ec_formalismo_de_cartesiana_a_polar}\n",
    "\\boxed{z = x + i y  = r e^{i\\theta} ~~~ \\hbox{ con } ~~~ \\left\\{\\begin{array}{l} r=\\sqrt{x^2+y^2} \\\\  \\rule{0mm}{4mm} \\theta = \\arctan(y/x) . \\end{array} \\right.} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Signo de la arcotangente}\n",
    "En la formula de la arcotangente de la Ec. (\\ref{ec_formalismo_de_cartesiana_a_polar}) hay que elegir el signo con cuidado. La arcotangente devuelve valores en $(-\\pi/2$, $\\pi/2)$, pero sabemos que los ángulos en la circunferencia está en  $[0,2\\pi)$. Por ello, hay que aplicar el siguiente criterio:\n",
    "\\begin{itemize}\n",
    "\\item Si $x=0$ e $y>0$ (sobre el eje $y$) $\\Rightarrow \\theta = \\pi$\n",
    "\\item Si $x=0$ e $y<0$ (sobre el eje $y$) $ \\Rightarrow \\theta = 3\\pi/2$\n",
    "\\item Si $x>0$ e $y \\geq 0$ (primer cuadrante) $ \\Rightarrow \\theta = \\arctan (y/x)$\n",
    "\\item Si $x<0$ e $y \\geq 0$ (segundo cuadrante) $ \\Rightarrow \\theta = \\arctan (-y/x) + \\pi/2$\n",
    "\\item Si $x<0$ e $y<0$ (tercer cuadrante) $ \\Rightarrow \\theta = \\arctan (y/x) + \\pi$\n",
    "\\item Si $x<0$ e $y<0$ (cuarto cuadrante) $ \\Rightarrow \\theta = \\arctan (-y/x) + 3\\pi/2$\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\Ejercicio{Calcula a mano la forma polar de los números: \n",
    "$$\n",
    "4 + 3i, \\quad 7 - 2i, \\quad - 5 + 5i, \\quad - 3 + 4i\n",
    "$$}\n",
    "\n",
    "\\SubsubiIt{Conjugación compleja}\n",
    "\n",
    "Todo número complejo, $z$, lleva \\textit{asociado} otro, $z^*$, denominado el \\textbf{complejo conjugado} que se obtiene cambiando $i \\to -i$, tanto en forma cartesiana\n",
    "\\begin{equation}\n",
    "\\boxed{z = x+i y ~~~~\\leftrightarrow~~~~ z^* = x - i y}\n",
    "\\end{equation}\n",
    "como en forma polar\n",
    "\\begin{equation}\n",
    "\\boxed{z = \\rho e^{i \\theta} ~~~~\\leftrightarrow~~~~ z^* = \\rho e^{- i \\theta}}\n",
    "\\end{equation}\n",
    "\n",
    "Hablando de representaciones, la conjugación compleja no es más que una reflexión sobre el eje horizontal como podemos ver en la Fig. \\ref{Fig_formalismo_conjugación}.\n",
    "\n",
    "Matemáticamente, el complejo conjugado $z^*$ de un número complejo $z$ es el número por el cual hay que multiplicar $z$ para obtener el módulo cuadrado, es decir:\n",
    "\\begin{equation}\n",
    "\\boxed{|z|^2 = z \\cdot z^* = \\rho^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\subsection{Operaciones básicas}\n",
    "\n",
    "Los números complejos ${\\mathbb C}$ forman una estructura matemática denominada \\textit{cuerpo}. Esto  quiere decir que admiten dos operaciones \\textit{internas}: la \\textbf{suma} y la \\textbf{multiplicación}. Vamos a estudiarlas por separado\n",
    "\n",
    "\\SubsubiIt{Suma}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item En \\textit{forma cartesiana} se \\textit{suman las partes real e imaginaria por separado}\n",
    "\\begin{equation}\n",
    "(a + i b) + (c + i d) = (a+c) + i (b+d)\n",
    "\\end{equation} \n",
    "La resta es obvia, ya que $a,b,c,d$ pueden ser números negativos. 	\n",
    "\n",
    "\\item En  \\textit{forma polar}, la suma de dos números complejos no admite ninguna simplificación, y deben transformarse primeramente a forma cartesiana, para sumarse. \n",
    "\\begin{equation}\n",
    "z + w = \\rho e^{i\\theta} + \\sigma e^{i\\phi} = (\\rho\\cos\\theta + \\sigma\\cos\\phi) + i(\\rho\\sin\\theta +  \\sigma\\sin\\phi) \n",
    "\\end{equation}	\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Multiplicación}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item En \\textit{forma cartesiana} debemos multiplicar todos los factores entre sí, y teniendo en cuenta que $i^2= -1$\n",
    "\\begin{equation}\n",
    "(a + i b) (c + i d) =ac +  ai d +i bc +i^2 bd = (ab - bd) + i(ac + bd)\n",
    "\\end{equation} \n",
    "\n",
    "\\item En la \\textit{forma polar}, la cosa es más simple, pues solo hay que multiplicar los módulos y sumar las fases: \n",
    "\\begin{equation}\n",
    "z w = r e^{i\\theta} s e^{i\\phi} = rs\\,   e^{i(\\theta + \\phi)} \n",
    "\\end{equation}\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Valor absoluto}\n",
    "\n",
    "El cuadrado de un número real $a\\in {\\mathbb R}$ es otro número real positivo $a^2 >0$. Ello nos permite definir\n",
    "el valor absoluto $|a| = \\sqrt{a^2}$ que es el mismo para $a$ y para $-a$.\n",
    "\n",
    "Esto no sucede con un número complejo $z$. En efecto,  $z^2 = x^2 - y^2 +2i xy$ es complejo. Sin embargo, el producto de un número por su conjugado es un número \\textit{real} y \\textit{positivo}\n",
    "$$\n",
    "z z^*  = (x + i y) (x-i y) = x^2 + y^2 >0\n",
    "$$\n",
    "lo nos permite definir el \\textbf{valor absoluto} de un número complejo\n",
    "\\begin{equation}\n",
    "\\boxed{|z| = \\sqrt{z z^*} = \\sqrt{x^2 + y^2}}\n",
    "\\end{equation}\n",
    "\n",
    "El valor absoluto de una fase es 1\n",
    "\\begin{equation}\n",
    "|e^{i\\theta}| = \\sqrt{ e^{i\\theta}   e^{-i\\theta}}=\\sqrt{ e^{i(\\theta-\\theta)}}=\\sqrt{e^0} = 1\n",
    "\\end{equation}\n",
    "El valor absoluto de un número complejo coincide con el \\textbf{módulo} escrito en forma polar\n",
    "\\begin{equation}\n",
    "|z| = \\sqrt{zz^*} = \\sqrt{\\rho e^{i\\theta} \\rho e^{-i\\theta}}=\\sqrt{\\rho^2} ~~ \\Rightarrow ~~ \\boxed{|z| = \\rho}\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{División}\n",
    "\n",
    "Al igual que la multiplicación, en forma cartesiana, la división no es simple. Sea $z = a+ i b$ y $w=c+i d$ \n",
    "\\begin{equation}\n",
    "\\frac{z}{w} = \\frac{z}{w}\\frac{w^*}{w^*} = \\frac{( a+ i b)(c-i d)}{|w|^2} = \\frac{ac+bd + i(bc-ad)}{c^2+d^2}  = \\frac{ac+bd}{c^2+d^2} +i\\frac{bc-ad}{c^2+d^2}\n",
    "\\end{equation}\n",
    "\n",
    "En forma polar la división es tan sencilla como la multiplicación. Se toma el  cociente de los módulos y la resta de las fases\n",
    "\\begin{equation}\n",
    "\\frac{z}{w} = \\frac{\\rho e^{i\\theta}}{\\sigma e^{i\\phi}} = \\frac{\\rho}{\\sigma} e^{i(\\theta-\\phi)}\n",
    "\\end{equation}\n",
    "\n",
    "\\subsection{Casos particulares}\n",
    "\n",
    "\\SubsubiIt{Sumas nulas}\n",
    "\n",
    "En muchas ocasiones nos encontraremos la siguiente representación del numero cero (complejo) $0 = 0 + i 0$\n",
    "\\begin{equation}\n",
    "\\sum_{k=0}^{N-1} e^{2\\pi i k/N} =   e^{2\\pi i\\, 0/N} +  e^{2\\pi i\\, 1/N}  +~...~ +   e^{2\\pi i\\, (N-2)/N}+   e^{2\\pi i\\, (N-1)/N} ~=~  ~0.\n",
    "\\end{equation}\n",
    "No es trivial ver que esta igualdad es cierta, así que no vamos a demostrarla.\n",
    "\n",
    "Si multiplicamos todas la fases por un número entero $j$ tal que $1\\leq j \\leq N-1$, el resultado es el mismo\n",
    "$$\n",
    "\\sum_{k=0}^{N-1} e^{2\\pi i j k/N} =   e^{2\\pi i \\, 0/N} +  e^{2\\pi i \\, j/N}  +~...~ +   e^{2\\pi i \\, j(N-2)/N}+   e^{2\\pi i \\, j(N-1)/N} ~=~  ~0.\n",
    "$$\n",
    "\n",
    "Sin embargo si $j = 0, N, 2N,... = 0\\,\\hbox{mod} N$, entonces \\textbf{la suma no se anula} y su valor es igual a $N$. Tomemos por ejemplo $j=N$ \n",
    "$$\n",
    "\\sum_{k=0}^{N-1} e^{2\\pi i (N) k/N} = \\sum_{k=0}^{N-1} e^{2\\pi i  k}  =  \\sum_{k=0}^{N-1} 1 =~  ~N.\n",
    "$$\n",
    "\n",
    "Una manera de resumir todos los casos anteriores en una sola expresión involucra la función $\\delta$ \\textbf{de Kronecker}\n",
    "\\begin{equation} \\label{ec_fundamentos_delta_de_kronecker}\n",
    "\\delta_{ij} = \\left\\{ \\begin{array}{rcl} 0 & \\hbox{si} & i\\neq j \\\\ 1 & \\hbox{si} & i = j \\end{array} \\right.\n",
    "\\end{equation}\n",
    "Con ella podemos enunciar el siguiente resultado \n",
    "\\begin{equation}\n",
    "\\boxed{\\frac{1}{N}\\sum_{k=0}^{N-1} e^{2\\pi i \\, j k/N} =  \\delta_{j\\, 0{\\rm mod} N}},\n",
    "\\end{equation}\n",
    "que usaremos al estudiar la transformada de Fourier cuántica.\n",
    "\n",
    "\\SubsubiIt{Desigualdad triangular}\n",
    "\n",
    "\\begin{mybox_gray2}{}			\n",
    "\\textbf{Desigualdad triangular}:\n",
    "\n",
    "El módulo de la suma de dos números complejos verifica que\n",
    "$$\n",
    "| z+w| \\leq |z| + |w| \\,\n",
    "$$\n",
    "donde la igualdad sólo se verifica cuando ambos números complejos son paralelos en el plano complejo. \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\section{Vectores}\n",
    "\n",
    "\\subsection{Espacio Vectorial Complejo}\n",
    "\n",
    "\\SubsubiIt{Definición}\n",
    "\n",
    "\\Definicion{\n",
    "De forma poco rigurosa, definiremos un \\textbf{vector de dimensión} $N$ como una columna de $N$ números complejos \n",
    "$$\n",
    "|u\\rangle = \\begin{bmatrix} {u_1}\\\\ {u_2}\\\\ \\vdots \\\\ {u_N} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "}\n",
    "\\begin{itemize}\n",
    "\\item El símbolo $\\ket{u}$  \\textit{representa }al vector y se denomina \\textbf{ket} en la \\textbf{notación de Dirac}. Otra notación sería $\\vec{u}$, pero esta nunca se usa en Mecánica Cuántica.\n",
    "\n",
    "\\item Los números complejos $u_i \\in {\\mathbb C}$ con $\\, i=1,...,N$ se denominan \\textbf{componentes} del vector $\\ket{u}$. Estas componentes toman un valor concreto cuando especificamos una \\textbf{base}. En otra base, estos elementos pueden tener otro valores. Es decir, el vector es un objeto abstracto.\n",
    "\\end{itemize}\n",
    "\n",
    "\\Definicion{\n",
    "La colección de todos los posibles vectores de $N$ componentes,  con las  propiedades de suma y multiplicación forman un \\textbf{espacio vectorial}, $V$ de dimension compleja $N$.\n",
    "}			\n",
    "\n",
    "Es decir,  en un espacio vectorial  tenemos las siguientes propiedades:\n",
    "\\begin{itemize}\n",
    "\\item Dos operaciones posibles: \\textbf{suma }de dos vectores y \\textbf{multiplicación de un vector por un número complejo }$\\lambda\\in {\\mathbb C}$\n",
    "\\begin{equation}\n",
    "|u\\rangle + \\ket{v}~ =~\\, \n",
    "\\begin{bmatrix} {u_1}+v_1\\\\ {u_2}+v_2\\\\ \\vdots \\\\ {u_N}+v_n \\end{bmatrix} ~= ~\\ket{w}\\ , \\qquad \\lambda|u\\rangle ~ =~   \\begin{bmatrix} {\\lambda u_1}\\\\ {\\lambda u_2}\\\\ \\vdots \\\\ {\\lambda u_N} \\end{bmatrix} ~\\equiv~\\ket{\\lambda u}\n",
    "\\end{equation}\n",
    "\n",
    "\\item Existencia de un \\textbf{elementos neutro} (respecto a la suma). Todo vector de $V$ se denota mediante el símbolo $\\ket{v}$ menos el elemento neutro, que se escribe como $0$.\n",
    "\\begin{equation}\n",
    "\\ket{v} + 0 = \\ket{v}\n",
    "\\end{equation}\n",
    "\n",
    "\\item La existencia de un \\textbf{elemento opuesto} (respecto a la suma):\n",
    "\\begin{equation}\n",
    "\\ket{v} + \\ket{-v} = \\ket{v}-\\ket{v} = 0\n",
    "\\end{equation}\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_blue}{Dimensión de un espacio vectorial complejo}\n",
    "La \\textbf{dimensión} es igual al número de cantidades (\\textit{grados de libertad}) que debemos fijar para especificar un vector. Como estamos lidiando con un espacio vectorial complejo donde nuestro vector está compuesto por $N$ números complejos, la cantidad de números reales que debemos fijar es $2N$.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Entonces, podemos decir que la \\textbf{dimensión compleja} de un espacio vectorial complejo $V$ es $N$, o que su \\textbf{dimensión real} es $2N$ \n",
    "\\begin{equation}\n",
    "{\\rm dim}_{\\mathbb C} V = N ~~~~\\Longleftrightarrow ~~~   {\\rm dim}_{\\mathbb R} V = 2N\n",
    "\\end{equation}\n",
    "Habitualmente, cuando se habla simplemente de \\textit{dimensión} se habla de la real.\n",
    "\\end{mybox_blue}	\n",
    "\n",
    "\\SubsubiIt{Conjugación adjunta}\n",
    "\n",
    "La operación \\textbf{conjugación adjunta},  $\\dagger$, es una \\textit{extensión} de la \\textbf{conjugación compleja}  a los vectores.\n",
    "\n",
    "\\Definicion{Asociado a cada \\textit{ket }$\\ket{u}$, definimos un vector \\textbf{adjunto}, o \\textbf{bra} $\\bra{u}\\equiv\\left(\\ket{u}\\right)^\\dagger$,  que representamos mediante un vector fila con las componentes conjugadas complejas:  \n",
    "\\begin{equation}\n",
    "\\dagger \\,: \\quad\\,|u\\rangle = \\begin{bmatrix} {u_1}\\\\ {u_2}\\\\ \\vdots \\\\ {u_N} \\end{bmatrix} \n",
    "~~~~~{\\rightarrow}~~~~~~ \\left(\\ket{u}\\right)^\\dagger \\equiv \\bra{u} =\\begin{bmatrix} {u_1^*} & {u_2^*} & \\cdots & {u_N^*}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "Consistentemente encontramos para el producto de un vector por un número complejo $\\lambda$\n",
    "\\begin{equation}\n",
    "\\dagger \\,:\\quad\\,  \\lambda\\ket{u}=\\ket{\\lambda u} ~~~~~{\\rightarrow}~~~~~~ \\left(\\lambda\\ket{u}\\right)^\\dagger=\\lambda^*\\bra{u} = \\bra{u}\\lambda^* = \\bra{\\lambda u}\n",
    "\\end{equation}\n",
    "ya que el producto de un vector por un número es conmutativo.		\n",
    "\n",
    "\\begin{mybox_blue}{Notación}\n",
    "En la notación con \\textit{kets} y \\textit{bras} vemos que es lo mimos escribir $\\lambda\\ket{u}$ que $\\ket{\\lambda u}$. Esto podemos pensarlo como que los números complejos entran y salen de los kets sin modificaciones. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Sin embargo, en los bras tenemos $\\bra{u}\\lambda^* = \\bra{\\lambda u}$. Es decir, sacar o meter un número complejo dentro de los bras implica una conjugación compleja del número. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Esto, como comentamos, es solo \\textbf{notación}, es decir, un convenio para escribir las cosas.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "Al igual que la conjugación compleja, la conjugación adjunta es una \\textbf{involución}: su aplicación sucesiva devuelve el vector original\n",
    "$$\n",
    "(\\ket{u}^\\dagger)^\\dagger =\\bra{u}^\\dagger =  \\ket{u}\n",
    "$$\n",
    "es decir, $\\dagger^2 = I$, el operador identidad.		\n",
    "\n",
    "\\subsection{Bases}\n",
    "\n",
    "\\Definicion{\n",
    "En un espacio vectorial $V$ de dimensión $N$ una \\textbf{base} es una colección de $N$ vectores  $\\{\\ket{e_1},...,\\ket{e_N}\\}$ tales que, cualquier vector $\\ket{v}\\in V$ se puede expresar como una \\textbf{combinación lineal} de ellos\n",
    "$$\n",
    "\\ket{v} = \\sum_{i=1}^N v_i \\ket{e_i}\n",
    "$$  \n",
    "Los coeficientes $v_i$ son las \\textbf{componentes} de $\\ket{v}$ \\textit{en la base dada}.\n",
    "}		\n",
    "\n",
    "Existen \\textit{infinitas bases} en un espacio vectorial. Podemos escoger una de ellas y asociarle el siguiente conjunto de columnas\n",
    "\\begin{equation} \\label{ec_formalismo_base_cartesina}\n",
    "|e_1\\rangle \\sim \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ \\vdots \n",
    "\\\\ 0 \\\\ 0 \\end{bmatrix}~~~~\n",
    "|e_2\\rangle \\sim \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\\\ \\vdots \n",
    "\\\\ 0 \\\\ 0 \\end{bmatrix}~~~~~~~~~\n",
    "\\cdots ~~~~~~~~\n",
    "|e_{N-1}\\rangle \\sim \\begin{bmatrix} 0 \\\\ 0 \\\\ 0\\\\\\vdots \n",
    "\\\\ 1 \\\\ 0 \\end{bmatrix}~~~~\n",
    "|e_N\\rangle \\sim \\begin{bmatrix} 0 \\\\ 0 \\\\0\\\\ \\vdots \n",
    "\\\\ 0 \\\\ 1 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "De esta forma, cualquier vector, escrito como una combinación lineal de sus elementos adquiere la representación usual\n",
    "\\begin{align}\n",
    "|u\\rangle ~&=~ {u_1} |e_1 \\rangle + {u_2} | e_2\\rangle +... + {u_{ N}}|e_{ N}\\rangle~=~ \\sum_{i=1}^N {u_ i} |e_i\\rangle \\,\\sim \\\\\n",
    "\\sim &~ {u_1} \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ \\vdots \n",
    "\\\\ 0 \\\\ 0 \\end{bmatrix} \\,+\\,{u_2} \\begin{bmatrix} 0 \\\\ 1 \\\\ 0\\\\ \\vdots \\\\ 0 \\\\ 0 \\end{bmatrix}~+~ ... ~+ ~\n",
    "{u_{N-1}} \\begin{bmatrix} 0 \\\\ 0 \\\\ 0\\\\\\vdots \n",
    "\\\\ 1 \\\\ 0 \\end{bmatrix}+ \n",
    "\\,{u_N}\\,  \\begin{bmatrix} 0 \\\\ 0 \\\\0\\\\ \\vdots \n",
    "\\\\ 0 \\\\ 1 \\end{bmatrix}~~~= ~~~\n",
    "\\begin{bmatrix} {u_1} \\\\ {u_2} \\\\{u_3}\\\\ \\vdots \n",
    "\\\\ \\,{u_{N-1}}\\, \\\\ {u_{N}} \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "\\SubsubiIt{Cambio de base}\n",
    "\n",
    "Existen \\textit{infinitas} bases  en un espacio vectorial de dimensión finita.\n",
    "Todas ellas sirven para representar un vector arbitrario.\n",
    "\n",
    "Consideremos dos bases \n",
    "$\\{\\ket{e_i}\\}$ y $\\{\\ket{f_j}\\}$ donde $ i,j = 1,...,N$.\n",
    "Cualquier vector $\\ket{v}$ se puede expandir de forma diferente en cada una de ellas\n",
    "$$\n",
    "\\ket{v} ~=~ \\sum_{i=1}^N v_i \\ket{e_i} ~=~ \\sum_{i=1}^N \\tilde v_i \\ket{f_i}\n",
    "$$\n",
    "donde las componente $v_i$ y $\\tilde v_i$ \\textit{deben ser distintas} pero \\textit{estar relacionadas}. Es decir, las componentes de los vectores dependen de la base elegida y tiene una \\textit{regla de cambio} cuando decidimos escribir nuestro vector en otra base.\n",
    "\n",
    "Para encontrar esta relación entre los elementos del vector en distintas bases tenemos que primero encontrar la relación entre la  bases. Como ya dijimos, cualquier vector se puede escribir como combinación lineal de elementos de una base, sin ninguna excepción. Es decir, como caso particular tenemos que cualquier elemento (vector) de una base se puede expresar como una combinación lineal de elementos de la otra. Tomemos por ejemplo, $\\ket{v}= \\ket{f_1}$\n",
    "\\begin{equation}\n",
    "\\ket{f_1} = \\sum_{i=1}^N A_{ i 1} \\ket{e_i}\n",
    "\\end{equation}\n",
    "donde $A_{ i 1}\\in \\mathbb{C}$ son las componentes del vector $\\ket{f_1}$ en la base $\\{\\ket{e_i}\\}$. Haciendo esto para todos los elementos de la base $\\{\\ket{f_j}\\}$, los coeficientes constituyen una \\textbf{matriz de cambio de base} $A_{ij}$:\n",
    "\\begin{equation} \\label{ec_formalismo_cambio_base_base}\n",
    "\\boxed{\\ket{f_j} = \\sum_{i=1}^N A_{ i j} \\ket{e_i} ~,~~~~~~j=1,..., N}\n",
    "\\end{equation}\n",
    "\\begin{mybox_blue}{Nota}\n",
    "La forma en que están sumados los índices $\\ket{f_j} = \\sum_{i=1}^N A_{ \\textcolor{red}{i} j} \\ket{e_{\\textcolor{red}{i}}}$.\n",
    "\\end{mybox_blue}\n",
    "Dado un vector $\\ket{v}$ con coordenadas $(v_1,\\dots,v_N)$ en la base $\\{\\ket{e_i}\\}$ y coordenadas $(\\tilde{v}_1,\\dots,\\tilde{v}_N)$ en la base $\\{\\ket{f_i}\\}$, es decir,\n",
    "$$\n",
    "\\ket{v} ~=~ \\sum_{i=1}^N v_i \\ket{e_i} ~=~ \\sum_{i=1}^N \\tilde{v}_i \\ket{f_i}\n",
    "$$\n",
    "la fórmula de cambio de base expresa las coordenadas sobre la base antigua, $\\{\\ket{e_i}\\}$, en términos de las coordenadas sobre la base nueva, $\\{\\ket{f_i}\\}$:\n",
    "\\begin{equation} \\label{ec_formalismo_cambio_de_base}\n",
    "\\boxed{v_i = \\sum_{i=1}^N A_{ij} \\tilde{v}_j}\n",
    "\\end{equation}\n",
    "\\begin{mybox_blue}{Nota}\n",
    "La forma en que están sumados los índices $v_i = \\sum_{i=1}^N A_{i\\textcolor{red}{j}} \\tilde{v}_{\\textcolor{red}{j}} $.\n",
    "\\end{mybox_blue}\n",
    "En términos de matrices, la formula de cambio de base es\n",
    "\\begin{equation}\n",
    "\\boxed{\\ket{v}_{\\{\\ket{e_i}\\}} = A \\ket{v}_{\\{\\ket{f_i}\\}}}\n",
    "\\end{equation}\n",
    "donde $\\ket{v}_{\\{\\ket{e_i}\\}}$ y $\\ket{v}_{\\{\\ket{e_i}\\}}$ son los vectores columna con las coordenadas de $\\ket{v}$  en las bases $\\{\\ket{e_i}\\}$ y $\\{\\ket{f_i}\\}$ respectivamente. \n",
    "\\begin{proof}\n",
    "Usando definición (\\ref{ec_formalismo_cambio_base_base}) de la matriz de cambio de base, tenemos\n",
    "\\begin{align*}\n",
    "\\ket{v} ~&= ~ \\sum_{j=1}^N \\tilde{v}_j \\ket{f_j} \\\\\n",
    "& = ~ \\sum_{j=1}^N \\tilde{v}_j \\lp \\sum_{i=1}^N A_{ i j} \\ket{e_i} \\rp \\\\\n",
    "& =   \\sum_{i=1}^N \\lp  \\sum_{j=1}^N A_{ i j} \\tilde{v}_j \\rp \\ket{e_i} \n",
    "\\end{align*}\n",
    "Como $\\ket{v} ~=~ \\sum_{i=1}^N v_i \\ket{e_i}$, la Ec. (\\ref{ec_formalismo_cambio_de_base}) se demuestra debido a la unicidad de la descomposición de un vector sobre una base.\n",
    "\\end{proof}\n",
    "\n",
    "Por supuesto, el cambio de base de la Ec. (\\ref{ec_formalismo_cambio_de_base}) se puede \\textbf{invertir} para \n",
    "obtener las coordenadas sobre la base nueva, $\\{\\ket{f_i}\\}$, en términos de las coordenadas sobre la base vieja,  $\\{\\ket{e_i}\\}$:\n",
    "\\begin{equation} \\label{ec_formalismo_cambio_de_base_inv}\n",
    "\\boxed{\\tilde{v}_i = \\sum_{j=1}^N A^{-1}_{ij} v_j ~, ~~~~~~~ \n",
    "\\ket{v}_{\\{\\ket{f_i}\\}} = A^{-1} \\ket{v}_{\\{\\ket{e_i}\\}}}\n",
    "\\end{equation}\n",
    "Es más, que el cambio de base sea invertible es un \\textbf{requisito}. Si no lo es, no es un cambio de base.\n",
    "\n",
    "\\begin{mybox_blue}{Los elementos de la base expresados en la propia base}\n",
    "Quizás la siguiente afirmación parezca contradictoria, pero veremos que no: dadas dos bases $\\{\\ket{e_i}\\}$ y $\\{\\ket{f_i}\\}$, los elementos de la base $\\{\\ket{e_i}\\}$ expresados en la base $\\{\\ket{e_i}\\}$ toman la forma\n",
    "\\begin{equation*}\n",
    "|e_1\\rangle \\sim \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots \n",
    "\\\\ 0 \\end{bmatrix}~~~~\n",
    "|e_2\\rangle \\sim \\begin{bmatrix} 0 \\\\ 1 \\\\  \\vdots \n",
    "\\\\ 0 \\end{bmatrix}~~~~~~~~~\n",
    "\\cdots ~~~~~~~~\n",
    "|e_N\\rangle \\sim \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \n",
    "\\\\ 1 \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "mientras que los elementos de la base $\\{\\ket{f_i}\\}$ expresados en la base $\\{\\ket{f_i}\\}$ toman la forma\n",
    "\\begin{equation*}\n",
    "|f_1\\rangle \\sim \\begin{bmatrix} 1 \\\\ 0 \\\\  \\vdots \n",
    "\\\\ 0 \\end{bmatrix}~~~~\n",
    "|f_2\\rangle \\sim \\begin{bmatrix} 0 \\\\ 1 \\\\ \\vdots \n",
    "\\\\ 0 \\end{bmatrix}~~~~~~~~~\n",
    "\\cdots ~~~~~~~~\n",
    "|f_N\\rangle \\sim \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \n",
    "\\\\ 1 \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "La pregunta ahora es, ¿dónde está el truco? Lo engañoso aquí es la notación de los vectores como columnas de números. Como ya comentamos, un vector es un elemento abstracto que toma la forma de una columna de números complejos \\textbf{cuando especificamos una base}. Es decir, cuando escribimos un vector como una columna de números, esa columna está expresada en una base de la forma (\\ref{ec_formalismo_base_cartesina}). Es decir, si tenemos un vector $\\ket{u}$ y trabajamos, por ejemplo, en la base $\\{\\ket{e_i}\\}$ tenemos\n",
    "\\begin{equation*}\n",
    "\\ket{u} = u_1 \\ket{e_1} + u_2 \\ket{e_2} + \\dots + u_n \\ket{e_N} = \\sum_{i=1}^{N} u_i \\ket{e_i} = \n",
    "\\begin{bmatrix}\n",
    "u_1 \\\\ u_2\\\\ \\vdots \\\\ u_N\n",
    "\\end{bmatrix}_{\\{\\ket{e_i}\\}}\n",
    "\\end{equation*}\n",
    "mientras que si trabajamos en la base $\\{\\ket{f_i}\\}$ tenemos\n",
    "\\begin{equation*}\n",
    "\\ket{u} = \\tilde{u}_1 \\ket{f_1} + \\tilde{u}_2 \\ket{f_2} + \\dots + \\tilde{u}_n \\ket{f_N} = \\sum_{i=1}^{N} \\tilde{u}_i \\ket{f_i} = \n",
    "\\begin{bmatrix}\n",
    "\\tilde{u}_1 \\\\ \\tilde{u}_2\\\\ \\vdots \\\\ \\tilde{u}_N\n",
    "\\end{bmatrix}_{\\{\\ket{f_i}\\}}\n",
    "\\end{equation*}\n",
    "Es decir, cuando escribimos los elementos de una base como vectores columna \\textbf{en su propia base}, siempre toman la forma de vectores con todo 0's menos un 1.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "Complementando a la nota anterior, cuando elegimos una base y decimos, por ejemplo, que nuestra base es\n",
    "\\begin{equation*}\n",
    "\\ket{f_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "1 \\\\ 1\n",
    "\\end{bmatrix} ~~~~,~~~~\n",
    "\\ket{f_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "1 \\\\ - 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "lo que estamos haciendo al escribirlos como vectores columna es expresar la nueva base $\\{\\ket{f_i}\\}$, en la base\n",
    "\\begin{equation*}\n",
    "\\ket{e_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix} ~~~~,~~~~\n",
    "\\ket{e_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "0 \\\\  1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "Es decir, siempre que escribimos un vector como una columna de números, esa columna está expresada en una base de la forma (\\ref{ec_formalismo_base_cartesina}). Si queremos pasar a trabajar en la base $\\{\\ket{f_i}\\}$ debemos transformar todos los vectores para expresarlos en la base donde $\\ket{f_1}$ y $\\ket{f_2}$ toman la forma\n",
    "\\begin{equation*}\n",
    "\\ket{f_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix} ~~~~,~~~~\n",
    "\\ket{f_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}\n",
    "0 \\\\  1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "Después de aplicar esta transformación (el cambio de base), los vectores $\\ket{e_1}$ y $\\ket{e_2}$ dejarán de tener la forma anterior.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "\n",
    "Cuando escribimos la base nueva en componentes\\footnote{Aquí con ``en componentes'' nos referimos a las componentes respecto a la base antigua, $\\{\\ket{e_i}\\}$. Es decir, todos los vectores de este ejemplo están escritos en la base $\\{\\ket{e_i}\\}$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a \\\\b\n",
    "\\end{bmatrix} = a \\ket{e_1} + b \\ket{e_2}\n",
    "$$}, automáticamente estamos dando el cambio de base:\n",
    "Por ejemplo, sea una nueva base $\\{\\ket{f_1},\\ket{f_2}\\}$ definida en términos de la antigua mediante \n",
    "$$\n",
    "\\ket{f_1} = \\frac{1}{\\sqrt{2}}\\left(\\rule{0mm}{4mm}\\ket{e_1} + i\\ket{e_2}\\right)~,~~\\ket{f_2} = \\frac{1}{\\sqrt{2}}\\left( \\rule{0mm}{4mm}\\ket{e_1} - i\\ket{e_2}\\right)\\, .\n",
    "$$\n",
    "En componentes, esto quiere decir que\n",
    "$$\n",
    "\\ket{f_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\i \\end{bmatrix}~,\n",
    "\\ket{f_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\-i \\end{bmatrix}~.\n",
    "$$\n",
    "Poniendo las dos columnas en una sola matriz, obtenemos   \n",
    "$$\n",
    "A_{ij} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ i & -i \\end{bmatrix}\\, ,\n",
    "$$\n",
    "que es, efectivamente, la matriz que efectúa el cambio de los vectores de la base\n",
    "\n",
    "$$\n",
    "\\ket{f_j} = \\sum_{i=1}^N A_{i j}\\ket{e_{i}} \\, ,\n",
    "$$\n",
    "así como de las componentes de los nuevos vectores en la antigua base\n",
    "$$\n",
    "\\ket{f_1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\i \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ i & -i \\end{bmatrix}\\begin{bmatrix} 1 \\\\0 \\end{bmatrix}~.\n",
    "\\ket{f_2} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\-i \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ i & -i \\end{bmatrix}\\begin{bmatrix} 0 \\\\1 \\end{bmatrix}~.\n",
    "$$\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\subsection{Espacios de Hilbert}\n",
    "\n",
    "\\Definicion{\n",
    "Un \\textbf{espacio de Hilbert}, $\\mathcal{H}$, es un espacio vectorial (real o complejo) dotado de una operación interna denominada \\textbf{producto escalar}.\n",
    "}\n",
    "\n",
    "En matemáticas, los espacios de Hilbert (llamados así por David Hilbert) permiten generalizar los métodos del álgebra lineal y el cálculo de \\textit{espacios vectoriales euclidianos} (de dimensiones finitas) a espacios que pueden ser de dimensiones infinitas. Los espacios de Hilbert surgen de forma natural y frecuente en matemáticas y física, normalmente como espacios de funciones. Formalmente, un espacio de Hilbert es un espacio vectorial equipado con un producto interior que induce una función de \\textbf{distancia} según la cual el espacio es un espacio métrico completo.\n",
    "\n",
    "\\SubsubiIt{Producto escalar}\n",
    "\n",
    "\\Definicion{\n",
    "El \\textbf{producto escalar} de dos vectores $\\ket{u}$ y $\\ket{v}$ es un \\textit{número complejo} $a\\in{\\mathbb C}$ que denotamos con un \\textbf{braket}, $a \\equiv \\braket{u}{v} $. El producto escalar verifica las tres propiedades siguientes\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Linealidad}: \n",
    "\\begin{equation}\n",
    "\\bra{u}\\big(a\\ket{v}+b\\ket{w}\\big) = a\\braket{u}{v} + b\\braket{u}{w}\n",
    "\\end{equation}	\n",
    "para cualquier $a,b \\in  \\mathbb{C}$ y cualquier vector $\\ket{u}$, $\\ket{v}$ y $\\ket{w}$.\n",
    "\n",
    "\\item \\textbf{Hermiticidad}: \n",
    "\\begin{equation}\n",
    "\\braket{v}{u} = \\braket{u}{v}^*\n",
    "\\end{equation}\n",
    "\\item \\textbf{Positividad}: \n",
    "\\begin{equation}\n",
    "\\braket{u}{u} >0 \\text{ para todo ket } \\ket{u}\\neq 0\n",
    "\\end{equation}	\n",
    "\\end{itemize}\n",
    "}\n",
    "Combinando las dos primeras propiedades, el producto escalar también es lineal en el primer argumento\n",
    "$$\n",
    "(a\\bra{u}+b\\bra{w})\\ket{v} = a\\braket{u}{v} + b\\braket{w}{v}~,\n",
    "$$\n",
    "es decir, el producto escalar es \\textbf{bilineal}.\n",
    "\n",
    "\\SubsubiIt{Norma}\n",
    "\n",
    "La positividad del producto escalar de un vector por sí mismo permite definir su \\textbf{norma}:\n",
    "\\begin{equation}\n",
    "\\boxed{\\|\\ket{v}\\| = \\sqrt{\\braket{v}{v}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Notar que:}\n",
    "\\begin{itemize}\n",
    "\\item En contraste con la definición de producto escalar en espacios vectoriales reales, en el caso complejo se hace necesario conjugar (usar un  \\textit{bra}), para  que la \\textit{norma} de un vector sea siempre real y positiva. Esta es la idea detrás de la definición de la \\textit{conjugación adjunta}.\n",
    "\n",
    "\\item El único vector que tiene norma nula en un espacio de Hilbert es el elemento neutro\n",
    "$$\n",
    "\\braket{v}{v} = 0 ~~~ \\Leftrightarrow ~~~\\ket{v} = 0\n",
    "$$\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo: espacio Euclidiano}\n",
    "Uno de los ejemplos más conocidos de espacio de Hilbert es el \\textbf{espacio vectorial euclídeo}\\footnote{Es el espacio real de tres dimensiones, $\\mathbb{R}^3$, habitual, el clásico de geometría.} formado por vectores tridimensionales, denotado por $\\mathbb{R}^3$, y dotado del \\textbf{producto punto}. El producto punto toma dos vectores $\\vec{x}$ e $\\vec{y}$ y produce un número real $\\vec{x} \\cdot \\vec{y}$. Si $\\vec{x}$ e $\\vec{y}$ se representan en coordenadas cartesianas, el producto punto se define como\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\ y_2 \\\\ y_3\n",
    "\\end{bmatrix} \n",
    "= x_1y_1 + x_2y_2 + x_3y_3\n",
    "\\end{equation*}\n",
    "El producto punto satisface las siguientes propiedades:\n",
    "\\begin{itemize}\n",
    "\\item Es lineal en su primer argumento: $(a \\vec{x}_1 + b \\vec{x}_2) \\cdot \\vec{y} = a (\\vec{x}_1 \\cdot \\vec{y}) + b (\\vec{x}_2 \\cdot \\vec{y})$, para cualquier escaleres $a$, $b$ y vectores $\\vec{x}_1$, $\\vec{x}_2$ y $\\vec{y}$.\n",
    "\n",
    "\\item Es simétrico: $\\vec{x} \\cdot \\vec{y} = \\vec{y} \\cdot \\vec{x}$\n",
    "\\item Es definido positivo: para todo vector $\\vec{x}$, $\\vec{x} \\cdot \\vec{x} \\geq 0$, cuya igualdad solo se satisface si $\\vec{x} = 0$.\n",
    "\\end{itemize}\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\SubsubiIt{Desigualdades}\n",
    "\n",
    "En muchas ocasiones será necesario acotar cantidades. \n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Desigualdad de Cauchy-Schwarz:}\n",
    "\\begin{equation}\n",
    "|\\braket{u}{v}| \\leq \\|\\ket{u}\\|\\, \\|\\ket{v}\\|\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Una consecuencia inmediata  de la desigualdad de Cauchy-Schwarz es la desigualdad triangular\n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Desigualdad triangular:}\n",
    "\\begin{equation}\n",
    "\\|\\ket{u}+\\ket{v}\\| \\leq \\|\\ket{u}\\|+ \\|\\ket{v}\\|\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\subsection{Bases ortogonales}\n",
    "\n",
    "Hasta ahora, a los vectores de una base $\\{\\ket{e_i}\\}$ sólo se les ha pedido que sean $N$ vectores \\textit{linealmente independientes}, donde $N$ es la dimensión del espacio vectorial $V$. En un espacio de Hilbert $\\mathcal{H}$ tiene sentido calcular el producto escalar de dos elementos de una base. \n",
    "\n",
    "\\SubsubiIt{Base ortonormal}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Una base \\textbf{ortornormal} se caracteriza por la siguiente lista de productos escalares\n",
    "\\begin{equation}\n",
    "\\braket{e_i}{e_j} = \\delta_{ij}\n",
    "\\end{equation}\n",
    "Es decir:\n",
    "\\begin{itemize}\n",
    "\\item Por un lado, dos elementos distintos de la base son ortogonales $\\braket{e_1}{e_2} = 0$.\n",
    "\\item Por otro, todos están normalizados  $ \\| e_i \\| = \\sqrt{\\braket{e_1}{e_1}} = \\sqrt{1} = 1$.\n",
    "\\end{itemize}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "En este curso siempre supondremos que las bases con las que trabajamos son ortonormales. Ello se justifica en base al siguiente teorema:\n",
    "\\Teorema{ \\label{teorema_formalismo_gramm_schmidt}\n",
    "Dada una base general $\\{\\braket{f_i}{f_j}\\neq \\delta_{ij}\\}$ de vectores no ortonormales, existe una procedimiento iterativo (de Gramm-Schmidt \\cite{wiki_GramSchmidt}) para construir, a partir de ella, una nueva base ortonormal $\\{\\braket{e_i}{e_j}\\}=\\delta_{ij}$.\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item Dado un vector  $\\ket{v} = \\sum_{i=1}^N v_i \\ket{e_i}$ donde $\\ket{e_i}$ es una base ortonorma, la \\textit{componente} $v_k$ se extrae mediante la \\textbf{proyección} ortogonal\n",
    "\\begin{equation}\n",
    "\\boxed{v_k =\\braket{e_k}{v}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{proof}\n",
    "\\begin{align*}\n",
    "\\braket{e_k}{v} &=  \\bra{e_k}\\left(\\sum_{j=1}^N v_j\\ket{e_j}\\right) \\nonumber\\\\\n",
    "&=  \\sum_{j=1}^N  v_j\\braket{e_k}{e_j}  \\nonumber\\\\\n",
    "&=  \\sum_{j=1}^N  v_j\\delta_{kj} = v_k\n",
    "\\end{align*}\n",
    "\\end{proof}\n",
    "\n",
    "\\item Calcular el valor de un \\textit{producto escalar} $a=\\braket{u}{v}$ es muy simple si conocemos las componentes de $\\ket{u}$ y $\\ket{v}$ en una base ortonormal:\n",
    "\\begin{equation*}\n",
    "a = \\braket{u}{v}\n",
    "= \\left(\\sum_{i}u_i^*\\bra{e_i}\\right)\\left(\\sum_{j}v_j\\ket{e_j} \\right) \n",
    "= \\sum_{ij} u_i^* v_j  \\braket{e_i}{e_j}\n",
    "= \\sum_{ij} u_i^* v_j \\delta_{ij} = \\sum_{i} u_i^* v_i  ~~ \\Rightarrow \\\\\n",
    "\\end{equation*}\n",
    "\\begin{equation}\n",
    "\\Rightarrow \\boxed{a =  \\braket{u}{v} = \\begin{bmatrix} {u_1^*} & {u_2^*} & \\cdots & {u_N^*} 	\\end{bmatrix}\n",
    "\\begin{bmatrix} {v_1}\\\\ {v_2}\\\\ \\vdots \\\\ {v_N} \\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_blue}{Importante:}\n",
    "La expresión de la izquierda  $a = \\braket{u}{v}$ \\textbf{no hace referencia a ninguna base}. Por tanto, el resultado $\\sum_{i=1}^n{ u_i^* v_i} $ debe ser independiente de la base que utilizamos para representar estos vectores mediante sus componentes $u_i$ y $v_i$. \n",
    "\\vspace{0.3cm}    \n",
    "\n",
    "Este resultado es \\textit{no trivial} y subrayamos su importancia: $\\braket{u}{v}$ puede ser calculado en la base más conveniente.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\section{Operadores}\n",
    "\n",
    "\\subsection{Operadores y matrices}\n",
    "\n",
    "En un espacio vectorial, además de los vectores, será esencial entender la manera en que estos se pueden transformar entre sí. Un tipo de transformaciones es aquella dada por un \\textit{operador lineal}:\n",
    "\\Definicion{\n",
    "Un \\textbf{operador lineal }es una aplicación  que transforma un vector  en otro \n",
    "\\begin{equation}\n",
    "A: \\ket{u} ~~\\to ~~ \\ket{v} \n",
    "\\end{equation}\n",
    "de forma \\textit{lineal}, esto es que sobre una \\textit{combinación lineal} de vectores actúa de forma lineal. Es decir, para todo $\\alpha,\\beta \\in {\\mathbb C}$: \n",
    "\\begin{equation}\n",
    "A: (\\alpha\\ket{u} + \\beta\\ket{w})~~\\to ~~ \\ket{v} =\\alpha A\\ket{u} + \\beta A\\ket{w}\n",
    "\\end{equation}   \n",
    "}\n",
    "Podemos escribir también $\\ket{v} = A\\ket{u} \\equiv \\ket{Au}$ (donde $Au$ debe entenderse como una etiqueta).\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "Con números (reales o complejos), un ejemplo de una operación que no es lineal es \\textit{elevar a una potencia}, por ejemplo, al cuadrado:\n",
    "\\begin{equation}\n",
    "f(x) = x^2 ~~ \\Rightarrow ~~ f(a+b) = (a+b)^2 \\neq a^2 + b^2\n",
    "\\end{equation}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_blue}{El cambio en física}\n",
    "Podemos ver la física como \\textit{el arte de estudiar el cambio}, es decir, estudiar como varía un sistema con el tiempo. Como acabamos de comentar, los \\textit{operadores lineales} nos introducen una noción de cambio (de evolución): un vector se transforma (evoluciona) a otro. Ya adelantamos aquí que en Mecánica Cuántica los vectores representan \\textbf{estados} del sistema, con lo cual, el hecho de aplicar un operador sobre un vector implica pasar de un estado del sistema a otro. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Existen transformaciones inducidas por operadores \\textit{no lineales}. Sin embargo, \\textbf{la Mecánica Cuántica es intrínsicamente lineal}: todas las evoluciones se dan por medio de operadores lineales.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "Un \\textit{operador}  fácil de visualizar es el operador de \\textbf{rotación en un plano}. Dado un ángulo $\\theta \\in (0,2\\pi)$ el operador $A = R(\\theta)$ gira cualquier vector un ángulo $\\theta$ en el sentido antihorario.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Un vector en el plano ${\\vec{u}} =  (u_1,u_2)$  es equivalente al número complejo $u = u_1 + i u_2$ en el plano complejo $V = {\\mathbb C}$.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Escrito en polares, $u=|u|e^{i\\phi}$, y sabemos que una rotación de ángulo $\\theta$ es equivalente a añadirle dicho  ángulo a la fase \n",
    "$$\n",
    "v = R(\\theta) u = |u| e^{i(\\phi + \\theta)} =  |u| e^{i\\phi } e^{i\\theta} = u\\cdot e^{i\\theta} \n",
    "$$\n",
    "Por tanto, para rotar un número complejo un ángulo $\\theta$ basta con multiplicarlo por la fase $e^{i\\theta}$, que se corresponde con el operador $R(\\theta)$ en el espacio vectorial $V = \\mathbb{C}$.       \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "La propiedad fundamental de una rotación es la de mantener invariante el módulo  $|v| = |u|$.    \n",
    "\\end{mybox_green}\n",
    "\n",
    "\\SubsubiIt{Matriz de un operador}\n",
    "\n",
    "Dada una base, un vector queda especificado por una colección de números, sus \\textit{componentes}. Igualmente, un operador queda definido por una \\textit{matriz numérica}.\n",
    "\n",
    "Efectivamente, en una base, la relación $\\ket{v} = A\\ket{u}$ equivale a una ecuación que relacione las componentes de ambos vectores\n",
    "\\begin{equation}\n",
    "\\boxed{v_i = \\sum_{j=1}^N A_{ij} u_j } \\, .\n",
    "\\end{equation}\n",
    "Esta operación se corresponde con la siguiente composición de matrices\n",
    "\\begin{equation}\n",
    "\\boxed{\\begin{bmatrix}\n",
    "v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_N \\end{bmatrix} =  \\begin{bmatrix} \n",
    "A_{11} & A_{12} & \\cdots & A_{1N} \\\\\n",
    "A_{21} & A_{22} & \\cdots & A_{2N} \\\\\n",
    "\\vdots & \\vdots &  \\ddots      & \\vdots \\\\\n",
    "A_{N1} & A_{N2} &    \\cdots    & A_{NN}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_N\\end{bmatrix}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "Continuando con el ejemplo del operador de rotación en un plano, hemos visto que las componentes de $u = u_1 + i u_2$ y las de $R(\\theta)u = v = v_1 + i v_2$ se obtienen mediante la multiplicación por una fase pura \n",
    "\\begin{equation*}\n",
    "v= u e^{i\\theta}\n",
    "\\end{equation*}\n",
    "Vamos a desarrollar cada miembro en cartesianas, separando las partes real e imaginaria\n",
    "\\begin{align*}\n",
    "v = v_1 + i v_2 &= u e^{i\\theta} =  (u_1 + iu_2) (\\cos \\theta + i \\sin \\theta)  \\\\\n",
    "\\rule{0mm}{6mm}\n",
    "&= (\\cos\\theta \\, u_1 - \\sin \\theta\\,  u_2) + i(\\sin\\theta\\,  u_1 + \\cos \\theta\\,  u_2)\n",
    "\\end{align*}	   \n",
    "es decir las coordenadas del vector origen y el vector rotado imagen se relacionan en la  forma \n",
    "\\begin{equation*}\n",
    "v_1 = \\cos\\theta \\, u_1 - \\sin \\theta\\,  u_2 ~~~~~~~,~~~~~~~~\n",
    "v_2 = \\sin\\theta \\, u_1 + \\cos \\theta\\,  u_2     \n",
    "\\end{equation*}\n",
    "que podemos expresar en forma matricial\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta &\\cos\\theta\\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\subsection{Producto externo}\n",
    "\n",
    "\\SubsubiIt{Producto externo de vectores}\n",
    "\n",
    "Consideremos dos vectores $\\ket{u}$ y $\\ket{v}$. Dependiendo del orden en que los compongamos, $\\braket{u}{v}$ o $\\ketbra{v}{u}$, el resultado produce dos cantidades muy distintas.\n",
    "\\begin{itemize}\n",
    "\\item El \\textbf{producto interno}, o \\textit{producto escalar} es un \\textbf{número complejo}\n",
    "$$\n",
    "a = \\braket{u}{v} = \\braket{v}{u}^* \n",
    "$$\n",
    "\n",
    "\\item El \\textbf{producto externo  }es un \\textbf{operador}\n",
    "\\begin{equation}\n",
    "A = \\ketbra{v}{u}\n",
    "\\end{equation}\n",
    "Para comprender por qué es un operador, observamos que dicha expresión aplicada a un vector $\\ket{w}$ da otro, paralelo a $\\ket{v}$\n",
    "\\begin{equation}\n",
    "A : \\ket{w} ~\\to ~ A\\ket{w} =  \\ket{v}\\braket{u}{w}=\\ket{v} b  = b \\ket{v} \n",
    "\\end{equation}\n",
    "El número complejo $b=\\braket{u}{w}$ es  la \\textit{proyección} de $\\ket{w}$ en la dirección de $\\ket{u}$.\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_blue}{Notar que:}\n",
    "\\begin{enumerate}\n",
    "\\item El \\textit{orden} en que escribimos las cosas es \\textit{muy} relevante.\n",
    "\\vspace{0.1cm}	\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item $\\braket{u}{v}$ y $\\ketbra{v}{u}$ son objetos \\textit{radicalmente distintos}: el primero es un número y el segundo es un operador. Decimos que los vectores no conmutan.\n",
    "\\vspace{0.1cm}		\n",
    "\n",
    "\\item En cambio $\\ket{v} b  = b \\ket{v}$, así como $\\bra{u}b = b\\bra{u}$, es decir,  los números complejos y los $kets$ o $bras$ pueden escribirse en cualquier orden (decimos que conmutan).\n",
    "\\end{itemize}\n",
    "\\vspace{0.2cm}\n",
    "\n",
    "\\item La acción del operador  $A = \\ket{v}\\!\\bra{u}$ es muy fácil de expresar con palabras: \n",
    "el operador $A$ toma \\textit{cualquier vector} $\\ket{w}$ y lo convierte en un vector \\textit{paralelo} a $\\ket{v}$ proporcionalmente a su proyección $b=\\braket{u}{w}$. \n",
    "\\vspace{0.1cm}\n",
    "\n",
    "Si la proyección es nula $b=0$, el operador aniquila, es decir, da el elemento neutro.\n",
    "\\end{enumerate}\n",
    "\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Producto externo de vectores (en componentes)}\n",
    "\n",
    "La diferencia entre el \\textit{producto interno} $a=\\braket{u}{v}$ y el \\textit{externo} $A=\\ketbra{u}{v}$ tiene su reflejo. Expresando ambos vectores en la misma base ortonormal, $\\ket{u} = \\sum_i u_i\\ket{e_i}$ y $\\ket{v} = \\sum_j v_j \\ket{e_j}$:\n",
    "\\begin{itemize}\n",
    "\\item El \\textit{número complejo} $a$  es el \\textit{producto escalar}\n",
    "\\begin{equation}\n",
    "a = \\braket{u}{v}  = \\begin{bmatrix} u_1^*,...,u_N^*\\end{bmatrix}\n",
    "\\begin{bmatrix} v_1 \\\\ \\vdots \\\\ v_N\\end{bmatrix}\\, =  \\sum_i u_i^*v_i\n",
    "\\end{equation}\n",
    "\n",
    "\\item La matriz $A_{ij}$ \\textit{representa} el operador $A$ en la base $\\{\\ket{e_i}\\}$\n",
    "\\begin{equation}\n",
    "\\boxed{A = \\ketbra{v}{u} ~\\sim ~\\begin{bmatrix} v_1 \\\\ \\vdots \\\\ v_N\\end{bmatrix}\n",
    "\\begin{bmatrix} u_1^*,...,u_N^*\\end{bmatrix} ~=~ \n",
    "\\begin{bmatrix} v_1 u_1^* & v_1u_2^* & ... & v_1 u_N^* \\\\\n",
    "v_2 u_1^* & v_2 u_1^*& ... & v_2 u_N^* \\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "v_N u_1^* & & ... & v_N u_N^* \\end{bmatrix} ~ = ~A_{ij}}\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsection{Base canónica de operadores}\n",
    "\n",
    "\\SubsubiIt{Producto externo de operadores de la base}\n",
    "\n",
    "Un caso importante es cuando $A$ es el producto externo de \\textit{dos elementos de la base ortonormal} $\\ket{i}$ y $\\ket{j}$ \n",
    "\\begin{equation}\n",
    "A = \\ketbra{i}{j}\n",
    "\\end{equation}\n",
    "La acción de $A$ sobre un vector $\\ket{k}$ arbitrario de la base es sencilla:  cambia el vector $\\ket{j}\\to \\ket{i}$ y aniquila a todos los demás\n",
    "\\begin{equation}\n",
    "A \\ket{k} = \\ket{i}\\braket{j}{k} = \\ket{i} \\delta_{jk} = \\left\\{ \\begin{array}{rl}\n",
    "0 & {\\rm if} ~~k\\neq j \\\\ \\ket{i} & {\\rm if} ~~ k=j \\end{array} \\right.\n",
    "\\end{equation}\n",
    "La matriz asociada al operador  tiene sólo un 1 en el elemento $(ij)$ y cero en todos los demás. Por ejemplo, supongamos que \n",
    "$N=4$ \n",
    "\\begin{equation}\n",
    "\\ketbra{2}{3} ~\\to ~~\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\begin{bmatrix} 0 & 0 & 1 & 0 \\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 &  0 & 0 &  0 \\\\  0 &  0 & 1&  0 \\\\ 0 &  0 & 0 &  0 \\\\ 0 &  0 & 0 &  0\n",
    "\\end{bmatrix} ~~\\Rightarrow ~~ A_{ij} = \\delta_{i2}\\delta_{j3}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Cambio de notación en la base}\n",
    "Véase que en esta sección se han denominado a los elementos de la base simplemente como $\\ket{i}$ en vez de como $\\ket{e_i}$. Esto es simplemente un cambio de notación. Las dos notaciones son habituales en matemáticas y física, pero la usada en computación cuántica es la primera, $\\ket{i}$.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Expansión de un operador general}\n",
    "\n",
    "Ahora podemos obtener una nueva perspectiva sobre la matriz $A_{ij}$ asociada a un operador $A$. \n",
    "\\begin{mybox_gray2}{}\n",
    "De la misma manera que las componentes $u_i$ expresan la \\textit{expansión de un vector} $\\ket{u}$ en una base \\textit{ortonormal de vectores},  $\\to \\ket{u} = \\sum_{i=1}^N u_i \\ket{i}$, los \\textit{elementos de matriz} $A_{ij}$ expresan la \\textit{expansión de un operador} en una \\textbf{base de operadores} $\\ketbra{i}{j}$\n",
    "\\begin{equation} \\label{ec_formalismo_base_operadores}\n",
    "A= \\sum_{i,j=1}^N A_{ij} \\ketbra{i}{j} \n",
    "\\end{equation} \n",
    "Esta base es la \\textbf{base canónica}.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Escribiendo las matrices asociadas a $\\ketbra{i}{j}$, es evidente que $\\sum_{i,j=1}^N A_{ij} \\ketbra{i}{j} $ reconstruye la mariz $A_{ij}$ asociada a $A$\n",
    "\\begin{equation}\n",
    "A= \\sum_{i,j=1}^N A_{ij} \\ketbra{i}{j} \\,~~~~ \\Longleftrightarrow ~~~~\n",
    "\\begin{bmatrix} \n",
    "A_{11} & A_{12} & \\cdots & A_{1N} \\\\\n",
    "A_{21} & A_{22} & \\cdots & A_{2N} \\\\\n",
    "\\vdots & \\vdots &  \\ddots      & \\vdots \\\\\n",
    "A_{N1} & A_{N2} &    \\cdots    & A_{NN}\n",
    "\\end{bmatrix} .\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{Elementos de matriz}\n",
    "\n",
    "De la misma manera que obteníamos las componentes de un vector proyectando sobre un elemento de la base\n",
    "\\begin{equation}\n",
    "v_i = \\braket{i}{v}\n",
    "\\end{equation}\n",
    "ahora podemos obtener los \\textit{elementos de matriz} de un operador $A$ en la forma\n",
    "\\begin{equation}\n",
    "\\boxed{A_{ij} = \\bra{i} A \\ket{j}}\n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{\n",
    "Demuestra la expresión $A_{ij} = \\bra{i} A \\ket{j}$. Para ello usa la Ec. (\\ref{ec_formalismo_base_operadores})\n",
    "}\n",
    "\n",
    "\\begin{mybox_blue}{Resumen}\n",
    "Dada una base $\\{\\ket{e_i}\\}$ podemos expresar un operador mediante una matriz $A_{ij}$. La relación concreta es \n",
    "\\begin{itemize}\n",
    "\\item Como operador $\\to ~ A = \\sum_{ij} A_{ij}\\ketbra{i}{j}$\n",
    "\\item Como elemento de matriz $\\to ~ A_{ij} = \\bra{i}A\\ket{j}$\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Cambios de base}\n",
    "\n",
    "Sean  dos bases ortonormales relacionadas mediante el cambio unitario $ \\ket{j} \\to  \\ketnew{\\tilde{j}} = \\sum_{ij}U_{ij} \\ket{i}$. En cada una de ellas, un operador adquiere una forma matricial concreta \n",
    "\\begin{equation}\n",
    "A_{ij} = \\bra{i} A \\ket{j} ~~~~,~~~~~ \\tilde A_{ij} = \\branew{\\tilde i} A \\ketnew{\\tilde j} \\, .\n",
    "\\end{equation}\n",
    "Ambas se relacionan muy sencillamente\n",
    "\\begin{equation}\n",
    "\\tilde A_{ij} = \\branew{\\tilde i} A \\ketnew{\\tilde j} = \\sum_{k,l}\\bra{e_k}U^*_{ki} A U_{lj}\\ket{e_l} =  \\sum_{k,l} U_{lj}\\bra{e_k} A  \\ket{e_l} U^\\dagger_{ik}  = \\sum_{k,l} U^\\dagger_{ik}A_{kl} U_{lj} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "\\Lemma{\n",
    "Bajo un cambio de base $ \\ket{e_j} \\to \\ket{\\tilde e_j} = \\sum_{ij}U_{ij} \\ket{e_i}$ las matrices\n",
    "asociadas a un operador $A$ cambian según la regla\n",
    "\\begin{equation}\n",
    "\\tilde A_{ij} = (U^\\dagger A U)_{ij}\n",
    "\\end{equation}\n",
    "}\n",
    "\\SubsubiIt{Relación de completitud}\n",
    "\n",
    "La acción del operador identidad es \n",
    "\\begin{equation}\n",
    "I\\ket{v} = \\ket{v}\n",
    "\\end{equation}\n",
    "En particular sobre todo elemento de la base $I\\ket{i} = \\ket{i}$. En otras palabras,\n",
    "el operador identidad $I$ tiene por matriz $I_{ij}=\\delta_{ij}={\\rm diagonal}\\, (1,1,...,1)$ con lo que\n",
    "\\begin{equation}\n",
    "\\boxed{ I = \\sum_{i}  \\ketbra{i}{i} } = \\sum_{ij} \\delta_{ij}\\ketbra{i}{j} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\dots & 0 \\\\\n",
    "0 & 1 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "Esta expresión se conoce también como \\textit{relación de completitud} o, también \\textbf{relación de cierre} y se utiliza muy frecuentemente.\n",
    "\n",
    "La relación de completitud es, en realidad, una propiedad de  \\textbf{cualquier base}. Dicho de otro modo, si $\\{\\ket{e_i}\\}$ y $\\{\\ket{f_i}\\}$ son, ambas, bases entonces $I\\ket{e_i} = \\ket{e_ i}$ y $I\\ket{f_j} = \\ket{f_j}$, entonces \n",
    "\\begin{equation}\n",
    "I =  \\sum_{i}  \\ketbra{e_i}{e_i} =  \\sum_{j}  \\ketbra{f_j}{f_j}\\, .\n",
    "\\end{equation}\n",
    "La relación de cierre, o completitud,  siempre se puede insertar en cualquier momento del cálculo. Se utiliza con frecuencia para efectuar cambios de base.\n",
    "\n",
    "Por ejemplo, vamos a ver que el producto escalar $\\braket{u}{v}$ puede calcularse en cualquier. \n",
    "Sea $\\ket{u} = \\sum_i u_i\\ket{e_i} = \\sum_i \\tilde u_i \\ket{f_i}$  y $\\ket{v} = \\sum_i  v_i\\ket{e_i}=\\sum_i \\tilde v_i\\ket{f_i}$. Entonces\n",
    "\\begin{equation}\n",
    "\\braket{v}{u} = \\bra{v} I \\ket{u} = \\bra{v}\\left(\\sum_i\\ketbra{e_i}{e_i}\\right)\\ket{u} = \n",
    "\\sum_i \\braket{v}{e_i}\\braket{e_i}{u} = \\sum_i v_i^* u_i\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\braket{v}{u} = \\bra{v} I \\ket{u} = \\bra{v}\\left(\\sum_i\\ketbra{f_i}{f_i}\\right)\\ket{u} = \n",
    "\\sum_i \\braket{v}{f_i}\\braket{f_i}{u} = \\sum_i \\tilde v_i^* \\tilde u_i\n",
    "\\end{equation}\n",
    "\n",
    "\\subsection{El espacio vectorial ${\\rm L}(\\mathcal{H})$}\n",
    "\n",
    "El \\textit{conjunto} de \\textbf{todos} los \\textit{operadores lineales} sobre un espacio vectorial $\\mathcal{H}$ tiene, de forma natural, una estructura de espacio vectorial que denominamos ${\\rm L}(\\mathcal{H})$.\n",
    "\n",
    "En efecto, sean $A$ y $B$ dos operadores, y $\\lambda\\in {\\mathbb{C}}$ un número complejo. Tanto la suma $C = A+B$ como la multiplicación externa $D=\\lambda A$ son nuevos operadores definidos por su acción sobre un vector cualquiera $\\ket{v}\\in \\mathcal{H}$\n",
    "\\begin{equation}\n",
    "C\\ket{v} ~=~ (A + B) \\ket{v} = A\\ket{v} + B\\ket{v}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "D\\ket{v} ~=~ (\\lambda A) \\ket{v} = \\lambda (A\\ket{v})\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{Operador Adjunto}\n",
    "\n",
    "La conjugación \\textit{adjunta} se puede extender a ${\\rm L}(\\mathcal{H})$\n",
    "\\begin{equation}\n",
    "\\dagger ~\\to ~\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "z & \\leftrightarrow  &  z^* \\\\\n",
    "|u\\rangle & \\leftrightarrow &   \\langle u | \\\\\n",
    "A & \\leftrightarrow & A^{\\dagger}\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "pero añadiendo dos reglas que permiten aplicar $\\dagger$ a sumas y productos de \\textit{objetos} $a,b \\in\\{z,\\ket{u},A\\}$\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{linealidad} $( a + b)^\\dagger = a^\\dagger + b^\\dagger $\n",
    "\\item \\textbf{trasposición} $(ab)^\\dagger = b^\\dagger a^\\dagger$ (sólo relevante cuando $a$ y $b$ no conmuten)\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplos}\n",
    "\\begin{itemize}\n",
    "\\item $\\ket{v} = A\\ket{u} ~~\\Leftrightarrow ~~\\bra{v} = \\bra{u}A^\\dagger$ donde el operador en la derecha actúa sobre el \\textit{bra} a su izquierda.\n",
    "Notar que, como $\\ket{v}^\\dagger=\\ket{Au}^\\dagger = \\bra{Au}$, la ecuación anterior implica\n",
    "$$\n",
    "\\bra{Au} = \\bra{u} A^\\dagger\n",
    "$$\n",
    "\\item $\\bra{w}A\\ket{u}^* = (\\bra{w}A\\ket{u})^\\dagger = \\bra{u}A^\\dagger\\ket{w}$\n",
    "\n",
    "\\end{itemize}\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\SubsubiIt{Matriz Adjunta}\n",
    "\n",
    "Estas reglas nos permiten obtener el adjunto de un operador\n",
    "\\begin{equation}\n",
    "\\boxed{A^\\dagger = \\sum_{ij}\\left( A_{ij}\\ketbra{i}{j}\\right)^\\dagger = \\sum_{ij} \\, \\ketbra{j}{i}A_{ij}^* =  \\sum_{ji} \\, A_{ji}^*\\ketbra{i}{j}}\n",
    "\\end{equation} \n",
    "donde en la última ecuación hemos intercambiado los nombres $i\\leftrightarrow j$.\n",
    "\n",
    "Vemos que la matriz que representa $A^\\dagger$ es la \\textit{matriz adjunta} de $A_{ij}$, es decir, la traspuesta y conjugada\n",
    "\\begin{equation}\n",
    "(A^\\dagger)_{ij} = A^*_{ji} = (A^{*}_{ij})^t \\equiv (A_{ij})^\\dagger\n",
    "\\end{equation}\n",
    "donde $^\\dagger$ significa el adjunto de un operador a la izquierda, y de una matriz a la derecha.\n",
    "\n",
    "\\SubsubiiIt{Dimensión de ${\\rm L}(\\mathcal{H})$}\n",
    "\n",
    "Si $\\mathcal{H}$ tiene dimensión $N$, un \\textit{operador general} $A\\in {\\rm L}(\\mathcal{H})$ se especifica mediante una matriz de $N^2$ números complejos $\\Rightarrow A = A_{ij}\\ket{e_i}\\bra{e_j}$. Además, $N^2$ números complejos equivalen a $2N^2$ números reales. \n",
    "\n",
    "En otras palabras: $A$  tiene $N^2$ grados de libertad complejos y, por tanto, ésta es la dimension del espacio ${\\rm L}(\\mathcal{H})$ \n",
    "\\begin{equation}\n",
    "{\\rm dim}_{\\bf C}({\\rm L}(\\mathcal{H})) = N^2 ~~~ \\Longleftrightarrow ~~~ {\\rm dim}_{\\bf R}({\\rm L}(\\mathcal{H})) =  2N^2\n",
    "\\end{equation}\n",
    "\n",
    "\\subsection{Clases de operadores}\n",
    "\n",
    "Vamos a considerar clases de operadores que satisfagan algún tipo de \\textit{condición} o \\textit{restricción}.\n",
    "\n",
    "\\SubsubiIt{Operador Unitario}\n",
    "\n",
    "\\Definicion{\n",
    "Un \\textbf{operador unitario} $U$ es tal que su \\textit{adjunto} es igual a su \\textit{inverso}. Es decir verifica la siguiente ecuación\n",
    "\\begin{equation}\n",
    "U^\\dagger = U^{-1}  \\, \n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "Naturalmente, esta ecuación se traduce en la misma ecuación para las matrices asociadas\n",
    "\\begin{equation}\n",
    "(U_{ij})^\\dagger = U_{ji}^* = U^{-1}_{ij}\n",
    "\\end{equation}\n",
    "Veamos ahora por qué hemos definido esta clase de operadores.\n",
    "\n",
    "\\Teorema{\n",
    "La acción de un operador unitario conserva \\textbf{intacto el producto escalar} de dos vectores cualesquiera. En particular, conserva también la \\textit{norma} de cualquier vector. \n",
    "}\n",
    "\n",
    "\\begin{proof}\n",
    "Sea $U$ un operador unitario, y $\\ket{\\varphi'}=U\\ket{\\varphi}$ y $\\ket{\\psi'} = U\\ket{\\psi}$ dos vectores transformados por $U$, entonces\n",
    "$$\n",
    "\\braket{\\varphi'}{\\psi'} = \\left(\\bra{\\varphi}U^\\dagger\\right)U\\ket{\\psi} = \\bra{\\varphi} U^\\dagger U \\ket{\\psi} = \n",
    "\\braket{\\varphi}{\\psi}\n",
    "$$\n",
    "particularizando para $\\ket{\\varphi} = \\ket{\\psi}$ tenemos que un operador unitario conserva la norma.\n",
    "$$\n",
    "\\|U \\ket{\\varphi}\\| = \\|\\ket{\\varphi}\\|\n",
    "$$\n",
    "\\end{proof}\n",
    "\n",
    "\\Lemma{\n",
    "La \\textbf{composición} de dos operadores $U$ y $V$  unitarios es unitaria. Sin embargo, la \\textbf{combinación lineal} de operadores unitarios no es unitaria.\n",
    "}\n",
    "\n",
    "\\Ejercicio{\n",
    "Demuestra este resultado, es decir, demuestra que:\n",
    "\\begin{align*}\n",
    "(UV)^\\dagger & = (UV)^{-1} \\\\\n",
    "(U+V)^\\dagger & \\neq (U+V)^{-1}\n",
    "\\end{align*}\n",
    "}\n",
    "\n",
    "Por tanto, los operadores unitarios \\textit{no forman} un subespacio vectorial dentro de ${\\rm L}(\\mathcal{H})$. La estructura matemática que forman se denomina \\textbf{grupo}: el grupo unitario $U(m)$, donde $m$ es la dimensión del espacio de Hilbert $\\mathcal{H}$.\n",
    "\n",
    "Aun así, forman una \\textit{variedad}: un conjunto continuo  que se puede parametrizar mediante una colección de parámetros, la \\textit{dimensión de la variedad}. Como hay una relación 1 a 1 entre un operador una matriz (en una base), esa dimensión será igual a \\textit{la dimensión del conjunto de matrices unitarias}.\n",
    "\n",
    "\\Ejercicio{\n",
    "Resta de ${\\rm dim}_{\\bf R}({\\rm L}(\\mathcal{H})) =  2N^2$ el número de ecuaciones que restringen la matriz de un operador unitario y halla así la dimensión (real) de la \\textit{variedad de operadores unitarios}.\n",
    "}\n",
    "\n",
    "\\SubsubiIt{Operador Unitario sobre bases ortonormales}\n",
    "\n",
    "Como caso particular, aplicando un operador unitario $U$ a una base ortonormal $\\{\\ket{e_i}\\}$ obtenemos otra base ortonormal $\\{\\ket{f_i}\\}$\n",
    "\\begin{equation}\n",
    "\\left. \\begin{array}{c}\\ket{f_i} = U\\ket{e_i}\\\\ U^{-1} =  U^\\dagger \\end{array} \\right\\}\n",
    "~~~~ \\Longleftrightarrow ~~~~\\braket{f_i}{f_j} = \\braket{e_i}{e_j} = \\delta_{ij}\n",
    "\\end{equation}\n",
    "Inversamente, dadas dos bases ortonormales, $\\{\\ket{e_i}\\}$ y $\\{\\ket{f_i}\\}$, el operador que las relaciona es un operador unitario\n",
    "\\begin{equation}\n",
    "\\begin{array}{rcl} \n",
    "U = \\sum_i \\ketbra{f_i}{e_i} & \\Rightarrow &  U\\ket{e_j} = \\ket{f_j} \n",
    "\\\\ \\rule{0mm}{5mm}\n",
    "U^\\dagger = \\sum_i \\ketbra{e_i}{f_i}  & \\Rightarrow &    U^\\dagger\\ket{f_j} = \\ket{e_j} \n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiiIt{Operador ortogonal}\n",
    "\n",
    "Un  \\textbf{operador ortogonal} es un caso particular de operador  unitario con \\textit{elementos de matriz reales}. El operador de rotación $R(\\theta)$ que hemos estudiado al comienzo de este tema es un operador ortogonal. Es inmediato comprobar que \n",
    "$$ \n",
    "R(\\theta)^t = R(-\\theta) = R(\\theta)^{-1}\n",
    "$$\n",
    "\n",
    "\\SubsubiIt{Operador Normal}\n",
    "\n",
    "\\Definicion{\n",
    "Un operador $N$  es \\textbf{normal} si conmuta con su adjunto\n",
    "$$\n",
    "NN^\\dagger = N^\\dagger N\n",
    "$$\n",
    "}\n",
    "\n",
    "\\SubsubiIt{Operador Hermítico}\n",
    "\n",
    "\\Definicion{\n",
    "Un operador  $H$ es \\textbf{Hermítico} (o \\textbf{autoadjunto})  si  verifica la ecuación siguiente\n",
    "\\begin{equation}\n",
    "H = H^\\dagger\n",
    "\\end{equation}\n",
    "}\n",
    "\\begin{itemize}\n",
    "\\item Es evidente que un operador hermítico es un operador normal, pero a la inversa no tiene por qué.\n",
    "\\item La \\textbf{combinación lineal} de dos operadores \\textit{hermíticos} con coeficientes \\textit{reales} es un operador \\textit{hermítico}\n",
    "$$\n",
    "C^\\dagger = (a A + b B)^\\dagger = a^* A^\\dagger + b^* B^\\dagger = aA + b B = C\n",
    "$$\n",
    "En otras palabras, los operadores autoadjuntos forman un subespacio vectorial $\\subset {\\rm L}(\\mathcal{H})$.\n",
    "\n",
    "\\item En cambio la composición (producto) de dos operadores hermíticos, en general no es hermítico\n",
    "$$\n",
    "(A B)^\\dagger = B^\\dagger A^\\dagger = BA \\neq AB\n",
    "$$\n",
    "salvo que $A$ y $B$ conmuten.\n",
    "\n",
    "\\item La matriz asociada a un operador hermítico también se llama hermítica, y coincide con su traspuesta y conjugada\n",
    "$$\n",
    "A_{ij} = A^\\dagger_{ij} \\equiv  A^{*t}_{ij} = A^*_{ji} \n",
    "$$\n",
    "Naturalmente, las matrices hermíticas también forman un subespacio vectorial dentro del espacio vectorial de matrices. \n",
    "\\item A partir de cualquier operador $C\\neq C^\\dagger $ siempre podemos construir un operador hermítico $A=A^\\dagger$ mediante la combinación lineal\n",
    "$$\n",
    "A = C + C^\\dagger\n",
    "$$\n",
    "donde $a$ es un número real. Esto se extiende trivialmente a las matrices que los representan en cualquier base\n",
    "$$\n",
    "A_{ij} = C_{ij} + C_{ji}^*\n",
    "$$ \n",
    "\\end{itemize}\n",
    "\n",
    "\\Ejercicio{Resta de $2N^2$ el número de ecuaciones que restringen la matriz de un operador hermítico y halla así la dimensión del \\textit{subespacio vectorial hermítico}}\n",
    "\n",
    "\\SubsubiIt{Operador anti-Hermítico}\n",
    "\n",
    "\\Definicion{\n",
    "Un operador  $A$ es \\textbf{anti-hermítico} si  verifica la ecuación siguiente\n",
    "\\begin{equation}\n",
    "A = -A^\\dagger\n",
    "\\end{equation}\n",
    "}\n",
    "\\begin{itemize}\n",
    "\\item Un operador anti-hermitico siempre se puede obtener de un operador hermítico mediante el número $i$\n",
    "\\begin{equation}\n",
    "A = i H ~~~\\Longleftrightarrow ~~~A^\\dagger = (i H)^\\dagger = -i H\n",
    "\\end{equation}\n",
    "\\item Se deduce de lo anterior que un operador anti-hermítico es también un operador normal\n",
    "\\begin{equation}\n",
    "A A^\\dagger = A (-A) = -A A = A^\\dagger A\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Proyectores}\n",
    "\n",
    "El operador $P = \\ketbra{u}{u}$ proyecta cualquier vector en la dirección de $\\ket{u}$\n",
    "\\begin{equation}\n",
    "P \\ket{w} = \\ket{u}\\!\\braket{u}{w} = a \\ket{u}\n",
    "\\end{equation}\n",
    "donde $a = \\braket{u}{w}$.\n",
    "\n",
    "Aplicado al vector $\\ket{u}$ lo deja invariante\n",
    "\\begin{equation}\n",
    "P \\ket{u} = \\ket{u}\\!\\braket{u}{u} =  \\ket{u}\n",
    "\\end{equation}\n",
    "Es por esto que, una segunda aplicación de $P$, no modifica el resultado\n",
    "$$\n",
    "P(P \\ket{w}) =  \\braket{u}{w} P(\\ket{u}) = \\braket{u}{w} \\ket{u}\n",
    "$$\n",
    "Como el vector $\\ket{w}$ es arbitrario, que $P^2\\ket{w} = P\\ket{w}$ sean siempre iguales es una propiedad del operador $P$. De hecho \\textbf{esta propiedad define una clase de operadores}. \n",
    "\n",
    "\\Definicion{\n",
    "Un \\textbf{proyector }es un operador hermítico que verifica la ecuación\n",
    "$$\n",
    "P^2 = P\n",
    "$$\n",
    "}\n",
    "\n",
    "\\begin{mybox_blue}{Los proyectores son no-unitarios}\n",
    "El proyector es un operador \\textit{no-unitario}: la proyección reduce la norma.\n",
    "Supongamos que $\\ket{u}$ y $\\ket{w}$ son vectores unitarios y distintos\n",
    "\\begin{equation}\n",
    "\\| P\\ket{w}\\|^2 = \\bra{w}P^\\dagger P\\ket{w} = \\bra{w} P\\ket{w}= \\braket{w}{u}\\braket{u}{w} = |\\braket{u}{w}|^2 < \\|\\ket{u}\\|\\|\\ket{w}\\| = 1  \n",
    "\\end{equation}\n",
    "donde hemos aplicado la desigualdad de Cauchy Schwarz estricta, al suponer que $\\ket{u}\\neq\\ket{w}$.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{itemize}\n",
    "\n",
    "\\item \\textbf{Matriz asociada a un proyector}\n",
    "\n",
    "\\begin{enumerate}\n",
    "\n",
    "\\item Si $\\ket{u} = \\ket{e_1}$ el operador $P_1 = \\ket{e_1}\\bra{e_1}$ proyecta cualquier vector sobre su componente a lo largo de $\\ket{e_1}$.    En forma matricial\n",
    "$$\n",
    "\\ketbra{e_1}{e_1} = \\begin{bmatrix} 1 \\\\ 0 \\\\ \\vdots\\\\ 0 \\end{bmatrix} \\begin{bmatrix} 1 & 0 & ...& 0 \\end{bmatrix}  =\n",
    "\\begin{bmatrix} 1 & 0 &  \\cdots & 0 \\\\ 0 & 0  & \\cdots & 0 \\\\ \n",
    "\\vdots & \\vdots &\\vdots & \\vdots  \\\\\n",
    "0  & 0 & \\cdots & 0\\end{bmatrix}\n",
    "$$\n",
    "de modo que\n",
    "$$\n",
    "\\ket{e_1} \\! \\braket{e_1}{u} ~= ~\\begin{bmatrix} 1 & 0 &  \\cdots & 0 \\\\ 0 & 0  & \\cdots & 0 \\\\ \n",
    "\\vdots & \\vdots &\\vdots & \\vdots  \\\\\n",
    "0  & 0 & \\cdots & 0\\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_N \\end{bmatrix}\n",
    "= \\begin{bmatrix} u^1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} = u^1 \\ket{e_1}\n",
    "$$\n",
    "\n",
    "\\item Si $\\ket{u} = \\sum_i u^i\\ket{e_i}$ es un vector unitario  $\\|\\ket{u}\\|=1$, entonces el proyector a lo largo de $\\ket{u}$ viene dado por\n",
    "\\begin{equation}\n",
    "\\boxed{P(u) = \\ketbra{u}{u} = \\sum_{i,j} u_i u^*_j \\ketbra{e_i}{e_j}}\n",
    "\\end{equation}\n",
    "Es decir, le está asociada una matriz dada por $P_{ij}=u_iu^*_j$. Es trivial verificar que \n",
    "$$\n",
    "\\sum_j P_{ij}P_{jk} = \\sum_j u_i u^*_j u_j u^*_k = u_i\\left(\\sum_j u^*_j u_j\\right) u_k = u_i u_k^* = P_{ik}\n",
    "$$\n",
    "como corresponde a un proyector.\n",
    "\\end{enumerate}		\n",
    "\n",
    "\\item \\textbf{Proyectores ortogonales}\n",
    "\n",
    "Si $\\{\\ket{\\mu_i}\\}$ es un conjunto de vectores ortonormales, forman la base de un subsespacio $S\\subset \\mathcal{H}$. El operador \n",
    "\\begin{equation}\n",
    "P_S = \\sum_i P(\\mu_i) = \\sum_i \\ketbra{\\mu_i}{\\mu_i}\n",
    "\\end{equation}\n",
    "es un proyector sobre el subespacio $S$, es decir $P_S\\ket{u}\\in S$ para todo $\\ket{u}\\in \\mathcal{H}$.\n",
    "\n",
    "\\item \\textbf{Proyector perpendicular}\n",
    "\n",
    "Cualquier vector se puede descomponer como combinación de un vector y otro perpendicular\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = a \\ket{u} + b \\ket{u_\\perp}\n",
    "\\end{equation}\n",
    "Si tomamos $\\ket{u}$ y $\\ket{u_\\perp}$ unitarios, los proyectories asociados \n",
    "\\begin{equation}\n",
    "P_\\| = P(u)  = \\ketbra{u}{u}~~~~~,~~~~~P_\\perp = P(u_\\perp)= \\ketbra{u_\\perp}{u_\\perp}\n",
    "\\end{equation}\n",
    "son perpendiculares\n",
    "\\begin{equation}\n",
    "P_\\|\\ P_\\perp = 0  ~~~~~~,~~~~~~P_\\| + P_\\perp = I\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Reflectores}\n",
    "\n",
    "Cualquier vector se puede descomponer como combinación de un vector y otro perpendicular\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = a \\ket{u} + b \\ket{u_\\perp}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Reflector paralelo a $\\ket{u}$: $\\ket{u}~$: $R_u = R_\\|$}\n",
    "\n",
    "El operador que \\textit{refleja  paralelamente} a $\\ket{u}$ será  el que invierte la componente de $\\ket{\\psi}$ en esa dirección\n",
    "\\begin{equation}\n",
    "\\boxed{R_\\| =  I - 2P_\\| = I - 2\\ketbra{u}{u}}\n",
    "\\end{equation}\n",
    "Efectivamente \n",
    "$$ R_\\|\\ket{\\psi} = - a \\ket{u} + b \\ket{u_\\perp}\\, .$$ \n",
    "\n",
    "\\item \\textbf{Reflector perpendicular a $~\\ket{u}~$: $R_{u_\\perp} = R_\\perp$}\n",
    "\n",
    "El operador que \\textit{refleja  perpendiculamente} a $\\ket{u}$ debe invertir la componente de $\\ket{\\psi}$ a lo largo de $\\ket{u_\\perp}$ \n",
    "\\begin{eqnarray*}\n",
    "R_\\perp\\ket{\\psi} &=&  a \\ket{u} - b \\ket{u_\\perp}\\,  \\\\ \\rule{0mm}{8mm}\n",
    "&=& - (-a \\ket{u} + b \\ket{u_\\perp}) \\\\ \\rule{0mm}{8mm}\n",
    "&=& -R_\\| \\ket{\\psi}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "De modo que \n",
    "\\begin{equation}\n",
    "\\boxed{R_\\perp = -R_\\| = 2P_\\| - I} \\, ,\n",
    "\\end{equation}\n",
    "Si tenemos en cuenta la relación  $P_\\| + P_\\perp = I~ \\Rightarrow ~P_\\| = I - P_\\perp$, podemos concluir que\n",
    "\\begin{equation}\n",
    "R_\\perp = I - 2\\ket{u_\\perp}\\bra{u_\\perp} = I - 2 P_\\perp\n",
    "\\end{equation}\n",
    "\\end{itemize}	\n",
    "\n",
    "\\subsection{Conmutador y Traza}\n",
    "\n",
    "\\SubsubiIt{Conmutador}\n",
    "\n",
    "A diferencia de los números, el orden en el que se componen dos operadores es relevante.\n",
    "\n",
    "\\Definicion{\n",
    "Dados dos operadores, $A$ y $B$, definimos el \\textbf{conmutador}\n",
    "\\begin{equation}\n",
    "[A,B] = AB-BA \\,.\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "El conmutador tiene las dos siguientes propiedades algebraicas, elementales de probar\n",
    "\\begin{align}\n",
    "{\\rm Derivacion} ~~~& \\to  ~ [A,BC] = B[A,C] + [A,B]C \\nonumber\\\\ \\rule{0mm}{9mm}\n",
    "{\\rm Identidad \\ de \\, Jacobi}~~~~ & \\to  ~ [A,[B,C]] + [B,[C,A]] + [C,[A,B]] = 0 \n",
    "\\end{align}	\n",
    "\n",
    "La conmutatividad de dos operadores $[A,B]=0$ es una propiedad algebraica muy deseable que, cuando se da, implica propiedades  muy ventajosas.\n",
    "\n",
    "\\SubsubiIt{Traza de un operador}	\n",
    "\n",
    "\\Definicion{\n",
    "La \\textbf{traza de un operador} se define como la suma de los elementos diagonales de la matriz que lo representa en una base\n",
    "\\begin{equation}\n",
    "{\\rm tr} A \\equiv \\sum_{i} A_{ii} =   \\sum_{i} \\bra{i}A\\ket{i} \n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item La traza de $A$ es \\textit{independiente de la base}. Por eso decimos que es la \\textit{traza del operador}.\n",
    "\\begin{proof}\n",
    "\\begin{eqnarray*}\n",
    "{\\rm tr} A &=& \\sum_{i} \\bra{i}A\\ket{i} =\\sum_{i} \\bra{i}A\\left( \\sum_j\\ketbra{\\tilde j}{\\tilde j}\\right)\\ket{i}\n",
    "\\nonumber\\\\\n",
    "&=& \\sum_{ij}\\bra{i}A\\ketnew{\\tilde j} \\braket{\\tilde j}{i} = \\sum_{ij}\\braket{\\tilde j}{i}\\bra{i}A\\ketnew{\\tilde j}  \\nonumber\\\\\n",
    "&=& \\sum_{j} \\branew{\\tilde j}\\left(\\sum_i\\ketbra{i}{i}\\right) A \\ketnew{\\tilde j}= \\sum_{j} \\branew{\\tilde j}A\\ketnew{\\tilde j}\\nonumber\\\\\n",
    "&=& \\sum_j \\tilde A_{jj}\n",
    "\\end{eqnarray*}\n",
    "\\end{proof}\n",
    "\n",
    "\\item La traza es una operación \\textbf{lineal}\n",
    "\\begin{equation}\n",
    "{\\rm tr} (A + B ) = {\\rm tr}A + {\\rm tr}B\n",
    "\\end{equation}\n",
    "\n",
    "\\item La traza de un producto de operadores es \\textbf{cíclica}: es invariante bajo permutaciones cíclicas de los operadores en su argumento. Por ejemplo, para tres operadores $A, B$ y $C$\n",
    "\\begin{equation}\n",
    "{\\rm tr}(ABC)= {\\rm tr}(BCA)\n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{Demuestra este resultado}\n",
    "Para un producto de dos operadores, el anterior resultado implica que la\\textit{ traza de un conmutador es cero}. Dicho de otra forma\n",
    "\\begin{equation}\n",
    "{\\rm tr}(AB) = {\\rm tr}(BA) ~~~\\Rightarrow ~~~~{\\rm tr}([A,B]) = 0 \\, .\n",
    "\\end{equation}\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsection{Autovalores y autovectores}\n",
    "\n",
    "\\Definicion{\n",
    "Existen vectores, $\\ket{\\lambda}$, para los cuales \\textit{la acción de un operador} $A$ devuelve un vector \\textbf{paralelo}\n",
    "\\begin{equation} \\label{ec_formalismo_ec_de_autovalores}\n",
    "A\\ket{\\lambda} = \\lambda \\ket{\\lambda}\\, .\n",
    "\\end{equation} \n",
    "Decimos que $\\ket{\\lambda}$ es un vector propio (o \\textbf{autovector}) de $A$ con valor propio (o \\textbf{autovalor}) asociado $\\lambda\\in {\\mathbb C}$.\n",
    "}\n",
    "\n",
    "Si $\\ket{\\lambda}$ es un autovector, también lo es $\\ket{\\mu} = \\alpha \\ket{\\lambda}$, para cualquier número complejo $\\alpha \\in \\mathbb{C}$. En efecto\n",
    "\\begin{equation}\n",
    "A \\ket{\\mu} = A \\lp \\alpha \\ket{\\lambda} \\rp =  \\alpha A \\ket{\\lambda} =  \\alpha \\lambda \\ket{\\lambda} = \n",
    "\\lambda \\alpha \\ket{\\lambda} = \\lambda \\ket{\\mu}\n",
    "\\end{equation}\n",
    "Es decir, asociado a un autovalor tenemos infinitos autovectores paralelos.\n",
    "\n",
    "\\SubsubiIt{Autovalores degenerados}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Decimos que un autovalor $\\lambda_k$ es $d_k$ veces \\textbf{degenerado} si existen $d_k$ autovectores \\textbf{linealmente independientes},  $\\ket{\\lambda_k^{a}}$ con $a=1,...,d_k$ asociados al \\textbf{mismo} autovalor\n",
    "$$A\\ket{\\lambda_k^a} = \\lambda_k \\ket{\\lambda_k^a} ~,~~~ {\\rm con } ~~ a = 1,...,d_k$$ \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\SubsubiIt{Subespacio propio}\n",
    "\n",
    "Bajo la acción del operador, los autovalores generan un \\textbf{subespacio propio} $S(\\lambda_k) \\in \\mathcal{H}$. Esto quiere decir que aquellos vectores que pertenecen a un subespacio, siguen perteneciendo al mismo subespacio tras la aplicación del operador.\n",
    "\n",
    "Por ejemplo, sea un operador $A$ tal que\n",
    "\\begin{equation}\n",
    "A\\ket{\\lambda_k^a} = \\lambda_k \\ket{\\lambda_k^a} ~,~~~ {\\rm con } ~~ a = 1,...,d_k\n",
    "\\end{equation}\n",
    "Podemos construir\n",
    "\\begin{equation}\n",
    "\\ket{u} = \\sum_{a=1}^{d_k} c_a\\ket{\\lambda^a_k} \n",
    "\\end{equation}\n",
    "como una combinación de los autovectores asociados a un autovalor concreto $\\lambda_k$. Entonces, bajo la acción del operador $A$ tenemos\n",
    "\\begin{equation*}\n",
    "A \\ket{u} \n",
    "=  \\sum_{a=1}^{d_k} c_a A\\ket{\\lambda^a_k}  =  \\sum_{a=1}^{d_k} c_a \\lambda_k\\ket{\\lambda^a_k}  =   \\lambda_k \\sum_{a=1}^{d_k} c_a \\ket{\\lambda^a_k}  =\\lambda_k\\ket{u}\n",
    "\\end{equation*}\n",
    "Por tanto $\\ket{u}\\in S(\\lambda_k)$.\n",
    "\n",
    "El Teorema de Gramm-Schmidt (Teorema \\ref{teorema_formalismo_gramm_schmidt}) garantiza que podemos elegir (mediante un cambio adecuado) el conjunto $\\{\\ket{\\lambda_{k}^a}\\}\\in (\\lambda_k), a=1,...,d_k$ de forma que que sea una  \\textit{base ortonormal}\n",
    "$$\n",
    "\\braket{\\lambda_{k}^a}{\\lambda_{k}^b}=\\delta_{ab}\n",
    "$$\n",
    "El \\textbf{proyector ortogonal} sobre el subespacio propio $S(\\lambda_k)$ será\n",
    "\\begin{equation} \\label{ec_formalismo_proyec_subespacio_propio}\n",
    "\\boxed{P_k = \\sum_{a=1}^{d_k} \\ketbra{\\lambda_{k}^a}{\\lambda_{k}^a}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "Llamemos $R_z(\\theta)$ el operador que efectúa una rotación  de ángulo $\\theta$ entorno al eje $z$. Cuando $\\theta = \\pi$ encontramos las siguiente acción sobre los tres elementos $\\{\\hat{\\bf x},\\hat{\\bf y},\\hat{\\bf z}\\}$\n",
    "de la base cartesiana\n",
    "\\begin{eqnarray*}\n",
    "R_z(\\pi)\\hat{\\bf x} &=&-\\hat{\\bf x}  \\\\ \\rule{0mm}{6mm}\n",
    "R_z(\\pi)\\hat{\\bf y} &=& -\\hat{\\bf y}  \\\\ \\rule{0mm}{6mm}\n",
    "R_z(\\pi)\\hat{\\bf z} &=& + \\hat{\\bf z}  \n",
    "\\end{eqnarray*}    \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Vemos que hay un autovector $\\hat{\\bf z}$ con autovalor $+1$ y dos autovectores $\\hat{\\bf x} $ y $\\hat{\\bf y} $\n",
    "con autovalor $-1$.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "El espacio ${\\mathbb R}^3$ se divide en dos subespacios propios de $R_z(\\pi)$, uno de dimensión 1 (a lo largo del eje $\\hat{\\bf z}$) y otro de dimensión 2 (en el plano $(\\hat{\\bf x},\\hat{\\bf y})$).\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Los proyectores asociados serán\n",
    "$$\n",
    "P_{\\hat{\\bf z}}= \\ket{\\hat{\\bf z}}\\bra{\\hat{\\bf z}}=\\begin{bmatrix} 0 & & \\\\ & 0 & \\\\ & & 1 \\end{bmatrix}~~~,~~~\n",
    "P_{\\hat{\\bf x}\\hat{\\bf y}}= \\ket{\\hat{\\bf x}}\\bra{\\hat{\\bf x}}+\\ket{\\hat{\\bf y}}\\bra{\\hat{\\bf y}}=\\begin{bmatrix} 1 & & \\\\ & 1 & \\\\ & & 0 \\end{bmatrix}~~~,~~~\n",
    "$$\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\SubsubiIt{Espectro de Operadores Normales}\n",
    "\n",
    "Recordemos la definición de un operador normal. $N$ será un operador normal si conmuta con su adjunto\n",
    "$$\n",
    "NN^\\dagger = N^\\dagger N\n",
    "$$\n",
    "La importancia de los operadores normales radica en el siguiente lema     \n",
    "\n",
    "\\Lemma{\n",
    "Dos autovectores de un operador normal asociados a dos autovalores \\textbf{distintos}  son \\textbf{ortogonales}\n",
    "$$\n",
    "\\lambda_i\\neq \\lambda_j~~~~\\Longleftrightarrow ~~~~ \\braket{\\lambda_i}{\\lambda_j} = 0\n",
    "$$\n",
    "}\n",
    "\n",
    "\\begin{proof}\n",
    "De la ecuación de autovalores $N\\ket{\\lambda_j} =  \\lambda_j \\ket{\\lambda_j}$, y de $NN^\\dagger = N^\\dagger N$, se sigue que\n",
    "$$\n",
    "\\bra{\\lambda_j}(N^\\dagger - \\lambda_j^*)(N - \\lambda_j) \\ket{\\lambda_j} = \\bra{\\lambda_j}(N - \\lambda_j)(N^\\dagger - \\lambda_j^*) \\ket{\\lambda_j}  = 0\\,\n",
    "$$\n",
    "de donde obtenemos $(N^\\dagger - \\lambda_j^*) \\ket{\\lambda_j} = 0 \\Rightarrow \\bra{\\lambda_j} N = \\bra{\\lambda_j}\\lambda_j$. Entonces\n",
    "$$\n",
    "\\bra{\\lambda_j}N\\ket{\\lambda_i} = \\lambda_j \\braket{\\lambda_j}{\\lambda_i} = \\lambda_i \\braket{\\lambda_j}{\\lambda_i} \\, ,\n",
    "$$\n",
    "de donde se sigue que, para $\\lambda_i \\neq \\lambda_j \\Rightarrow \\braket{\\lambda_i}{\\lambda_j} = 0$. \n",
    "\\end{proof}\n",
    "\n",
    "En general, cada autovalor $\\lambda_k$ será $d_k \\geq 1$ veces degenerado. En ese caso hay  $\\{\\ket{\\lambda^a_k}\\}, a=1,...,d_k$ autovectores que generan el subespacio propio, $S(\\lambda_k)\\subset \\mathcal{H} $, de dimensión $d_k$. \n",
    "\n",
    "Según este lemma, los subespacios $S(\\lambda_k)\\perp S(\\lambda_j)$ son ortogonales para $k\\neq j$. \n",
    "\n",
    "En resumen: siempre podemos encontrar una base  ortonormal de $\\mathcal{H}$, formada por autovectores de un operador normal $N$\n",
    "$$\n",
    "I = \\sum_k\\sum_{a=1}^{d_k} \\ketbra{\\lambda^a_k}{\\lambda^a_k} ~~~~~~~~~~~;~~~~~~~~~ \\braket{\\lambda^a_j}{\\lambda^b_k} = \\delta_{ab}\\delta_{jk}\n",
    "$$\n",
    "\n",
    "El proyector sobre el subespacio propio $S(\\lambda_k)$ será\n",
    "$$\n",
    "P_k = \\sum_{a=1}^{d_k} \\ketbra{\\lambda^a_k}{\\lambda^a_k}\n",
    "$$\n",
    "\n",
    "\\SubsubiIt{Descomposición Espectral}\n",
    "\n",
    "\\Teorema{ (\\textbf{Teorema Espectral}) \n",
    "Para todo operador normal $N$ existe una base de  autovectores ortonormales,  $\\{\\ket{\\lambda^a_k}\\}$,  tales que  $N$ admite la siguiente  \\textbf{descomposición espectral }\n",
    "\\begin{equation}\n",
    "N = \\sum_{k=1}^d \\lambda_k   P_k\n",
    "\\end{equation} \n",
    "donde $d=  {\\rm dim}(\\mathcal{H})$ y $P_k = \\sum_{a=1}^{d_k} \\ketbra{\\lambda^a_k}{\\lambda^a_k}$ es el proyector sobre el subespacio propio $S(\\lambda_k)$\n",
    "}\n",
    "La matriz $N_{ij}$ que expresa $N$ en la base $\\ket{\\lambda_i}$ es diagonal \n",
    "$$\n",
    "N_{ij} = \\bra{\\lambda^a_i} N\\ketnew{\\lambda^b_j} =  \\lambda_k \\delta_{kj} \\delta_{ab} =\\begin{bmatrix} \\lambda_1 &  &  &  &  \\\\ & \\ddots & & & \\\\ & & \\lambda_2 & &  \\\\&  & & \\ddots & \\\\  & & & &  \\lambda_N \\end{bmatrix}\n",
    "$$\n",
    "donde $\\lambda_k$ aparecerá $d_k$ veces repetido.\n",
    "\n",
    "\\begin{mybox_blue}{El operador identidad}\n",
    "El operador identidad tiene a cualquier vector por autovector $ I\\ket{v} = \\ket{v}$, con autovalores $\\lambda_ i = 1$. Por tanto, en \\textbf{cualquier base}, la matriz asociada a $I$ tiene la forma diagonal\n",
    "$$\n",
    "I_{ij} = \\delta_{ij} = \\begin{bmatrix} 1 &  &  &  \\\\ & 1 & &  \\\\ & & \\ddots & \\\\ & & &  1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "La descomposición espectral de $I$ no es otra que la \\textbf{relación de completitud}, que es cierta \\textit{para cualquier base}, ya que todas las bases son bases de autoestados de $I$\n",
    "$$\n",
    "I ~=~ \\sum_{i=1}^N \\ketbra{\\lambda_i}{\\lambda_i} ~=~ \\sum_{i=1}^N \\ketbra{e_i}{e_i}\n",
    "$$	\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Espectro de Operadores Hermíticos}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "El \\textbf{espectro de un operador hermítico}  $A = A^\\dagger$,  tiene dos propiedades importantes:\n",
    "\\begin{enumerate}\n",
    "\\item Los \\textbf{autovalores} de un operador hermíticos son reales $\\lambda_i \\in {\\mathbb R}$.\n",
    "\\item Los \\textbf{autovectores} $\\ket{\\lambda_i}$ de un operador hermítico asociados a autovalores distintos son ortogonales. Es decir\n",
    "\\begin{equation} \\label{ec_op_hermitico_autovec_ortogonal}\n",
    "\\lambda_i\\neq \\lambda_j ~~~\\Longleftrightarrow ~~~\\braket{\\lambda_i}{\\lambda_j} = 0\\, .\n",
    "\\end{equation}\n",
    "\\end{enumerate} \n",
    "\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{proof}\n",
    "\\begin{enumerate}\n",
    "\\item Tomemos un autovector normalizado de $A$, $\\ket{\\lambda}$ de autovalor $\\lambda$.\n",
    "$$\n",
    "\\lambda = \\bra{\\lambda}A\\ket{\\lambda} =  (\\bra{\\lambda}A^\\dagger\\ket{\\lambda})^* = (\\bra{\\lambda}A\\ket{\\lambda})^*= \\lambda^* .~~~\n",
    "$$   \n",
    "\n",
    "\\item Los operadores hermíticos son también normales, así que la demostración ya la vimos para esos operadores.\n",
    "\\end{enumerate}\n",
    "\\end{proof}\n",
    "\n",
    "\\textbf{Base ortonormal}: el conjunto de autovectores $\\ket{\\lambda_i}$ de un operador hermítico forma una base ortogonal. Puede normalizarse para formar una base ortonormal\n",
    "\\begin{equation} \\label{ec_op_hermitico_autovec_ortonorm}\n",
    "\\braket{\\lambda_i}{\\lambda_j} = \\delta_{ij} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{Espectro de Operadores Unitarios}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "\n",
    "Los autovalores de un \\textbf{operador unitario} son \\textbf{fases puras}\n",
    "$$\n",
    "U^\\dagger = U^{-1} ~~~\\Longleftrightarrow ~~~\\lambda_i = e^{i\\phi_i}\n",
    "$$ \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{proof}\n",
    "Es evidente puesto que sólo estos números complejos verifican que el complejo conjugado y el inverso coinciden $\\lambda^* = \\lambda^{-1} \\Leftrightarrow \\lambda = e^{i\\phi}$. \n",
    "\\end{proof}\n",
    "\n",
    "\\SubsubiIt{Operadores que conmutan}\n",
    "\n",
    "Cuando dos operadores conmutan se dan ciertas propiedades algebráicas que son muy ventajosas. En cierto modo se parecen más a c-números. Veamos la primera.\n",
    "\n",
    "\\Teorema{\n",
    "Dados dos operadores $A$ y $B$ que conmutan, existe una base $\\{\\ket{\\lambda_i}\\}$ de autovalores simultáneos de ambos operadores, es decir \n",
    "$$\n",
    "A = \\lambda_i^A\\ketbra{\\lambda_i}{\\lambda_i} ~~~~,~~~~~ B= \\lambda_i^B\\ketbra{\\lambda_i}{\\lambda_i} \n",
    "$$\n",
    "}\n",
    "\n",
    "\\begin{proof}\n",
    "Supongamos que $A$ y $B$ conmutan. Entonces la acción de $A$ \\textit{estabiliza} los subespacios propios de $B$. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Es decir, si $\\ket{\\lambda}$ es autoestado de $A$, entonces $\\ket{\\mu} = B\\ket{\\lambda}  $ también es autoestado con idéntico autovalor. Se comprueba fácilmente\n",
    "$$\n",
    "A \\ket{\\mu} = A(B\\ket{\\lambda} ) = B(A\\ket{\\lambda}) = B(\\lambda\\ket{\\lambda}) = \\lambda (B\\ket{\\lambda})\n",
    "$$\n",
    "\n",
    "Por tanto $\\ket{\\lambda}$ y $B\\ket{\\lambda}$ pertenecen al \\textit{mismo subespacio propio}. Esto es lo que se entiende por \\textit{estabilizar el subespacio}. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Si $\\lambda$ es degenerado esto sólo asegura que $B\\ket{\\lambda} = \\ket{\\lambda'}$ pertenece al subespacio propio del mismo autovalor $\\lambda$. Esto quiere decir que, dento de cada subespacio propio de $B$, podemos escoger la base que queramos. En particular podemos escoger una base que diagonalice $A$ dentro de dicho subespacio.  \n",
    "\\end{proof}\n",
    "\n",
    "En otras palabras, dos operadores que conmutan, son diagonalizables simultáneamente. Su matriz en la base $\\{\\ket{\\lambda_i}\\}$ es\n",
    "$$\n",
    "A = \\begin{bmatrix} \\lambda^A_1 & & &  \\\\ & \\lambda^A_2 & &   \\\\ & & \\ddots &  \\\\ & & & \\lambda^A_n \n",
    "\\end{bmatrix}~~~~~~~,~~~~~~~~\n",
    "B = \\begin{bmatrix} \\lambda^B_1 & & &  \\\\ & \\lambda^B_2 & &   \\\\ & & \\ddots &  \\\\ & & & \\lambda^B_n \n",
    "\\end{bmatrix}\\, .\n",
    "$$\n",
    "\n",
    "\\subsection{Factorización de unitarios}\n",
    "\n",
    "Como ya vimos, fabricar un operador hermítico $A$ a partir de otro operados $B$ no hermítico, es facil:\n",
    "$A = B + B^\\dagger$. Sin embargo, fabricar operadores unitarios no es tan fácil. Veamos dos métodos para ello.\n",
    "\n",
    "\\SubsubiIt{Descomposición Polar (PD)}\n",
    "\n",
    "\\Teorema{Todo operador $A\\in{\\rm L}(\\mathcal{H})$ admite la descomposición polar $A = UR$ donde $U$ es un operador unitario, y $R$ es un operador semi-definido positivo (sólo tiene autovalores positivos o cero)\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item La descomposición polar es \\textit{única} y generaliza la representación polar de números complejos $z = r e^{i\\phi}$ a operadores.\n",
    "\\item El hecho de que $r\\geq 0$ es la contrapartida a que $R$ sea semi-definida positiva. \n",
    "\\item El factor $e^{i\\phi}$ es análogo al hecho de que un operador unitario, como veremos, sólo tiene autovalores que son fases puras.\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Descomposición en valores singulares (SVD)}\n",
    "\n",
    "Vamos a enunciar este teorema para matrices. Concretamente el teorema habla de una matriz $m\\times n$. Este tipo de matrices se corresponden con operadores $O \\in{\\rm L}(\\mathcal{H}_A,\\mathcal{H})$ entre espacios de dimensiones $m$ y $n$.\n",
    "\n",
    "\\Teorema{\n",
    "Sea $A$ una matriz compleja $m\\times n$. Entonces  admite la siguiente forma (\\textbf{descomposición en valores singulares})\n",
    "$$\n",
    "A = U\\Sigma V^{\\dagger} \\, ,\n",
    "$$\n",
    "donde $U\\in U(m)$, $V\\in U(n)$ son matrices unitarias y $\\Sigma$ es una matriz  $m\\times n$ con $\\lambda_1, ...,\\lambda_r$ \\textbf{valores singulares} reales y positivos en la diagonal, con $r\\leq {\\rm min}(m,n)$. \n",
    "}\n",
    "\n",
    "\\subsection{Funciones de Operadores}\n",
    "\n",
    "\\SubsubiIt{Funciones analíticas}\n",
    "\n",
    "Estamos acostumbrados a escribir funciones \\textit{de una variable real o compleja}. Por ejemplo $f(x)= x^2$, ó, $ f(z) = e^z$. Querríamos dar sentido a una función \\textit{de un operador} \n",
    "$\n",
    "A \\to f(A)\n",
    "$\n",
    "\n",
    "Como en operadores la operación de composición la tenemos bien definida (multiplicación de matrices), en el caso de que $f(z)$ sea una función analítica expresable como una \\textbf{serie de Taylor} en torno a $x=0$ \n",
    "\\begin{equation}\n",
    "f(z) = \\sum_{n=0}^\\infty \\frac{1}{n!} f^{(n)}(0)\\,  z^n\n",
    "\\end{equation}\n",
    "tomaremos como \\textbf{definición} la \\textit{misma serie} cambiando el argumento $x\\to A$\n",
    "\\begin{equation}\n",
    "f(A) = \\sum_{n=0}^\\infty \\frac{1}{n!} f^{(n)}(0)\\,  A^n\n",
    "\\end{equation}\n",
    "Vemos que esta definición es una definición formal, que nos puede ser útil para algunas demostraciones, pero que no es práctica, en el sentido de que no sabemos como lidiar con infinitos términos. Veremos otra forma de lidiar con esto en el Teorema \\ref{teorema_formalismo_funciones_sobre_operador_diagonal}.\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "De la misma forma que, para funciones analíticas $f(z)^* = f(z^*)$, también la definición anterior asegura que $f(A)^\\dagger = f(A^\\dagger)$\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Exponencial de un operador}\n",
    "\n",
    "La exponencial de un operador será\n",
    "\\begin{equation}\n",
    "\\exp(A) = e^A = I + A + \\frac{1}{2} A^2 + \\frac{1}{3!} A^3 + ...\n",
    "\\end{equation}\n",
    "Una propiedad importante de la función exponencial es  $e^xe^y = e^{x+y}$. La propiedad análoga para operadores \\textit{sólo es cierta cuando conmutan entre sí}. Para el caso genérico tenemos dos opciones\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Teorema de Baker-Campbel-Haussdorf}\n",
    "\\Teorema{\n",
    "Sean $A,B\\subset{\\rm L}(\\mathcal{H})$ dos operadores lineales genéricos. Entonces\n",
    "\\begin{equation}\n",
    "e^A e^B = e^{\\left({A+B + \\frac{1}{2}[A,B] + \\frac{1}{12}[A,[A,B]]+ \\frac{1}{12}[B,[B,A]] + ...}\\right)}\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "Vemos que:\n",
    "\\begin{enumerate}\n",
    "\\item Si $A$ y $B$ conmutan, \n",
    "$$[A,B]=0 ~\\Leftrightarrow ~e^A e^B = e^{A+B}$$\n",
    "\n",
    "\\item Si el conmutador de $A$ y $B$  es un c-número \n",
    "$$[A,B]= c I  ~\\Leftrightarrow ~  e^A e^B = e^{A+B + \\frac{c}{2}}$$\n",
    "\n",
    "\\item El inverso de $e^A$ es $e^{-A}$. Efectivamente, como \n",
    "$$[A,A]=0 \\Rightarrow e^A e^{-A} = e^{A-A} = e^0 = I$$\n",
    "\n",
    "\\end{enumerate}\n",
    "\n",
    "\\item \\textbf{Teorema de Lie-Suzuki-Trotter}\n",
    "\n",
    "\\Teorema{Sean $A,B\\subset{\\rm L}(\\mathcal{H})$ dos operadores lineales genéricos. Entonces\n",
    "\\begin{equation}\n",
    "e^{A+B} = \\lim_{n\\to\\infty} \\left(e^{{A/n}} e^{B/n}\\right)^n\n",
    "\\end{equation}\n",
    "}\n",
    "Esta segunda opción es de uso muy frecuente en el contexto de la \\textit{simulación cuántica}. \n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Operadores unitarios a partir de hermíticos}\n",
    "\n",
    "Todo operador unitario $U$ se puede expresar como la exponencial imaginaria de un operador hermítico $H$\n",
    "\\begin{equation}\n",
    "U = e^{i H}\n",
    "\\end{equation}\n",
    "Efectivamente, \n",
    "\\begin{equation}\n",
    "U^\\dagger = \\left(e^{i H}\\right)^\\dagger = e^{-i H^\\dagger} = e^{-i H}=U^{-1}\n",
    "\\end{equation}\n",
    "por tanto, $U$ es unitario si y sólo si $H$ es hermítico.\n",
    "\n",
    "\\SubsubiIt{Funciones generales}\n",
    "\n",
    "No siempre $f(z)$ admite una expansión en serie de Taylor. Por ejemplo $f(z) = \\exp(1/z)$ en torno a $z=0$ no es analítica. En estos casos, el operador $f(A)$ existe, pero para construirlo es necesario recurrir a la \\textit{forma diagonalizada}\n",
    "\n",
    "\\Teorema{\\label{teorema_formalismo_funciones_sobre_operador_diagonal}\n",
    "Sea $A$ un operador diagonalizable, y sea $A= \\sum_i \\lambda_i \\ket{\\lambda_i}\\bra{\\lambda_i}$ su representación espectral. Entonces el operador $f(A)$ tiene la representación espectral siguiente  \n",
    "\\begin{equation}\n",
    "f(A) = \\sum_i f(\\lambda_i) \\ket{\\lambda_i}\\bra{\\lambda_i}~~~~\\Longleftrightarrow~~~~~\n",
    "f(A^{(D)}_{ij}) = \\begin{bmatrix} f(\\lambda_1)& &  & \\\\ & f(\\lambda_2) & &  \\\\ & & \\ddots & \\\\ & & & f(\\lambda_n)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplos}\n",
    "$$e^{1/A} = \\sum_i e^{1/\\lambda_i} \\ket{\\lambda_i}\\bra{\\lambda_i}$$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "{\\rm tr}(A \\log A) &=& {\\rm tr}\\left[\\left(\\sum_j \\lambda_j \\ket{\\lambda_j}\\bra{\\lambda_j}\\right)\\left(\\sum_k\\log \\lambda_k \\ket{\\lambda_k}\\bra{\\lambda_k}\\right)\\right]\\nonumber\\\\\n",
    "&=& {\\rm tr}\\left[\\sum_k \\lambda_k \\log\\lambda_k \\ket{\\lambda_k}\\bra{\\lambda_k} \\right] \\\\\n",
    "&=& \\sum_k \\lambda_k \\log \\lambda_k \\rule{0mm}{8mm}\n",
    "\\end{eqnarray*}\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\subsection{Matrices de Pauli} \\label{sec_qubit_matrices_Pauli}\n",
    "\n",
    "\\SubsubiIt{Definición}\n",
    "\n",
    "\\Definicion{\n",
    "Se donominan matrices de Pauli a las tres matrices siguientes:\n",
    "\\begin{equation} \\label{ec_qubits_matrices_de_Pauli}\n",
    "\\sigma_x =  \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} ,   ~~~~\n",
    "\\sigma_y =  \\begin{bmatrix} 0 & -i \\\\ i & 0 \\end{bmatrix} ,  ~~~~\n",
    "\\sigma_z =  \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} .\n",
    "\\end{equation}		\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item También se usan los subíndices enteros $\\sigma_1=\\sigma_x, ~\n",
    "\\sigma_2=\\sigma_y$  y  $\\sigma_3=\\sigma_z$. \n",
    "\n",
    "\\item Las matrices de Pauli son hermíticas y unitarias.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\Ejercicio{\n",
    "Escribe la descomposición espectral de las tres matrices de Pauli, $\\sigma_x, \\sigma_y $ y $\\sigma_z$.\n",
    "}\n",
    "\n",
    "\\SubsubiIt{Base ortogonal del espacio de Hilbert de matrices hermiticas $2\\times2$}\n",
    "\n",
    "Estas tres matrices, junto con la matriz identidad, forman una \\textbf{base ortogonal del espacio de Hilbert de matrices hermiticas} $2\\times2$. En otras palabras, cualquier matriz hermítica $2\\times2$ puede escribirse como una combinación lineal de estas matrices\n",
    "\\begin{equation}\n",
    "A = c I + \\sum_k^3 a_k \\sigma^k.\n",
    "\\end{equation}\n",
    "Es decir\n",
    "\\begin{eqnarray*}\n",
    "A &=&  a_0 I + a_1 \\sigma_1 + a_2 \\sigma_2 + a_3 \\sigma_3  \\\\ \n",
    "&=& \n",
    "\\begin{bmatrix}\n",
    "a_0 + a_3 & a_1 - i a_2 \\\\ a_1 + i a_2 & a_0 - a_3\n",
    "\\end{bmatrix} = A^\\dagger \\,.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\SubsubiIt{Composición}\n",
    "\n",
    "La \\textbf{composición} de dos matrices de Pauli es otra matriz de Pauli (o la identidad $I$) que cumple la siguiente propiedad\n",
    "\\begin{equation}\n",
    "\\sigma_i \\sigma_j = \\delta_{ij} I + i \\varepsilon_{ijk} \\sigma_k,  \\label{ec_qubit_pauli_sigma_ijk}\n",
    "\\end{equation}\n",
    "donde \n",
    "\\begin{equation}\n",
    "\\epsilon_{123}=\\epsilon_{231}=\\epsilon_{312} = 1 ~~, ~~~~ \\epsilon_{213}=\\epsilon_{132}=\\epsilon_{312} = 1\n",
    "\\end{equation}\n",
    "y el resto son cero. La propiedad (\\ref{ec_qubit_pauli_sigma_ijk}) se refiere a que las matrices de Pauli forman un grupo cerrado, es decir, al multiplicar dos matrices nos da otra matriz de Pauli (o la identidad). \n",
    "\n",
    "De la Ec. (\\ref{ec_qubit_pauli_sigma_ijk}) se deduce que\n",
    "\\begin{equation}\n",
    "\\sigma_x^2 = \\sigma_y^2 = \\sigma_z^2 = - i \\sigma_x \\sigma_y \\sigma_z = I \\,.   \\label{ec_qubit_pauli_sigma^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{Traza y ortogonalidad}\n",
    "\n",
    "Las matrices de Pauli tiene \\textbf{traza nula}\n",
    "\\begin{equation}\n",
    "\\text{tr} ~ \\sigma_j = 0 \\label{ec_qubit_sigma_tr} \n",
    "\\end{equation}\n",
    "Tomando la traza de la relación de composición obtenemos que las matrices de Pauli son \\textbf{ortogonales} en el sentido siguiente\n",
    "\\begin{equation}\n",
    "{\\rm tr}(\\sigma_i\\sigma_j) = {\\rm tr}(\\delta_{ij}I + i\\epsilon_{ijk}  \\sigma_k) = 2\\delta_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{Demuestra las siguientes relaciones de (anti)conmutación\n",
    "$$\n",
    "\\{\\sigma_i,\\sigma_j \\} = 2\\delta_{ij}~~~~~~~,~~~~~~~\n",
    "~~~[\\sigma_i,\\sigma_j] = 2i\\epsilon_{ijk}\\sigma_k\n",
    "$$}\n",
    "\n",
    "\\begin{mybox_blue}{Conmutador y anti-conmutador}\n",
    "\\begin{itemize}\n",
    "\\item Conmutador:\n",
    "\\begin{equation}\n",
    "\\lc A, B \\rc = AB - BA\n",
    "\\end{equation}\n",
    "\\item Anti-conmutador\n",
    "\\begin{equation}\n",
    "\\lch A,B \\rch = AB + BA\n",
    "\\end{equation}\n",
    "\\end{itemize} \n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Exponencial de matrices de Pauli}\n",
    "\n",
    "Recordar que la fórmula de Euler permite escribir, para una fase compleja $ e^{i\\alpha} = \\cos\\alpha + i \\sin\\alpha $. Ahora estamos en disposición de probar la generalización a matrices de Pauli.  Sea \n",
    "$$\n",
    "{\\bf a} = (a_1,a_2,a_3) =a \\left( \\frac{a_1}{a},\\frac{a_2}{a},\\frac{a_3}{a}\\right) =  a\\, \\hat{\\bf n}\n",
    "$$ \n",
    "donde $a=|{\\bf a}|=\\sqrt{a_1^2+a_2^3+a_3^2}$ es el módulo\n",
    "\n",
    "Entonces, escribimos\n",
    "$$\n",
    "{\\bf a} \\cdot \\boldsymbol{\\sigma} =  a\\, \\hat{\\bf n} \\cdot \\boldsymbol{\\sigma}\n",
    "$$\n",
    "\n",
    "\\Teorema{\n",
    "\\begin{equation}\n",
    "\\exp \\left( \\rule{0mm}{4mm} i\\,   {\\bf a} \\cdot \\boldsymbol{\\sigma}  \\right) = \\exp \\left( \\rule{0mm}{4mm} i\\,   a\\, \\hat{\\bf n} \\cdot \\boldsymbol{\\sigma}  \\right) = \\cos a \\, I + i \\sin a \\,(\\hat{\\bf n} \\cdot  \\boldsymbol{\\sigma}) \\, .\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\SubsubiIt{Matrices de Pauli en otras bases}\n",
    "\n",
    "Un punto importante es que la representación de las matrices de Pauli que acabamos de ver en la Ec. (\\ref{ec_qubits_matrices_de_Pauli}) no es única (aunque sí la mas extendida). Como podemos ver, esta representación es aquella en la que se diagonaliza la matriz $\\sigma_z$. Es decir, están representadas en la base de \\textbf{autoestados} (autovectores) de la matriz $\\sigma_z$\n",
    "\\begin{align*}\n",
    "& \\boxed{\\ket{z_+} = \\ket{\\uparrow} = \\begin{bmatrix}  1 \\\\ 0  \\end{bmatrix}},\n",
    "& \\boxed{\\ket{z_-} = \\ket{\\downarrow} = \\begin{bmatrix}  0 \\\\ 1  \\end{bmatrix}}\n",
    "\\end{align*}\n",
    "donde\n",
    "\\begin{align*}\n",
    "& \\sigma_z \\ket{z_+} =   \\sigma_z, \n",
    "& \\sigma_z \\ket{z_-} = - \\sigma_z.\n",
    "\\end{align*}\n",
    "\n",
    "Estas matrices podrían escribirse en otras bases, como por ejemplo la base de autoestados de $\\sigma_x$, i.e. $\\ket{x_+}, \\ket{x_-}$, que diagonalizaría la matriz $\\sigma_x$ o en la base de autoestados de $\\sigma_y$, i.e. $\\ket{y_+}, \\ket{y_-}$, que diagonalizaría la matriz $\\sigma_y$. Cabe destacar que solo podemos tener a la vez una de las tres matrices en forma diagonal (puesto que no conmutan). Por completitud, podemos ver la expresión de estos autoestados en función de los de $ \\sigma_z$:\n",
    "\\begin{align}\n",
    "& \\boxed{\\ket{x_+}  = \\frac{1}{\\sqrt{2}} \\lp \\ket{z_+} + \\ket{z_-} \\rp = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}  1 \\\\ 1  \\end{bmatrix}},\n",
    "& \\boxed{\\ket{x_-}  = \\frac{1}{\\sqrt{2}} \\lp \\ket{z_+} - \\ket{z_-} \\rp = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}  1 \\\\ -1  \\end{bmatrix}},   \\\\ \\rule{0mm}{10mm}\n",
    "& \\boxed{\\ket{y_+}  = \\frac{1}{\\sqrt{2}} \\lp \\ket{z_+} + i \\ket{z_-} \\rp = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}  1 \\\\ i  \\end{bmatrix}}, \n",
    "& \\boxed{\\ket{y_-}   = \\frac{1}{\\sqrt{2}} \\lp \\ket{z_+} - i \\ket{z_-} \\rp = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}  1 \\\\ -i \\end{bmatrix}}.\n",
    "\\end{align}\n",
    "donde\n",
    "\\begin{align}\n",
    "\\sigma_x \\ket{x_+} & = + \\ket{x_+},\n",
    "&&\\sigma_x \\ket{x_-}  =  - \\ket{x_-}  \\\\ \\rule{0mm}{3mm}\n",
    "\\sigma_y \\ket{y_+} & = + \\ket{y_+},\n",
    "&&\\sigma_y \\ket{y_-}   = - \\ket{y_-}.\n",
    "\\end{align}\n",
    "\n",
    "\\begin{mybox_blue}{Autoestados y autovectores. El espín}\n",
    "En esta sección hemos estado hablando de \\textbf{autoestados} en vez de \\textbf{autovectores}. Esto es \n",
    "por el significa físico que tienen las matrices de Pauli. Estas se usan, entre otras cosas, para \n",
    "describir el espín de una partícula, así que sus autovectores representan autoestados de espín de la partícula. \n",
    "En concreto, representan las proyecciones del espín sobre los tres ejes $x$, $y$ y $z$. 	\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Cuando decimos que una partícula tiene espín $+1/2$ o $-1/2$ habitualmente nos referimos a que la proyección\n",
    "del espín sobre el eje $z$ es $+1/2$ o $-1/2$ (obviando constantes multiplicativas). Es decir, está en el \n",
    "estado $\\ket{+}$ o $\\ket{-}$.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "En física cuántica, un autoestado de un operador es un estado que no evoluciona con el tiempo (si no hay influencias externas). \n",
    "Por ejemplo, cuando tenemos un electrón aislado con proyección del espín $+1/2$, este estado no va a cambiar con el tiempo,\n",
    "pues el electrón está aislado. \n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\section{Tensores}\n",
    "\n",
    "\\subsection{Producto tensorial}\n",
    "\n",
    "Llegados a este punto, un lector con ciertos conocimientos de Computación Cuántica podría plantearse la siguiente pregunta: ¿por qué durante toda la explicación anterior estamos tratando con espacios de Hilbert de dimensión arbitraria, si los qúbits tiene dimensión dos? \n",
    "\n",
    "Esto es muy sencillo de explicar. Con lo que vamos a trabajar no es con un solo qúbit, sino con un conjunto de qúbits. Cada qúbit vivirá en un espacio de Hilbelt de dimensión dos, pero el estado total del sistema de muchos qúbits vivirá en un espacio de dimensión mayor. Este espacio estará formado por el \\textbf{producto tensorial} de los espacios de Hilbert de cada qúbit.\n",
    "\n",
    "Es decir, el producto tensorial es una herramienta matemática que describe los \\textbf{sistemas compuestos} (en nuestro caso, sistemas compuestos por varios qúbits).\n",
    "\n",
    "\\SubsubiIt{Definiciones}\n",
    "\n",
    "\\Definicion{\n",
    "Dados dos vectores $\\ket{u}_1\\in \\mathcal{H}_1$ y  $\\ket{v}_2\\in \\mathcal{H}_2$, denominamos \\textbf{producto tensorial} al \\textbf{par ordenado}\n",
    "\\begin{equation}\n",
    "\\ket{uv} ~\\equiv \\ket{u}_1\\otimes \\ket{v}_2\n",
    "\\end{equation}\n",
    "}\n",
    "Este producto tensorial es \\textbf{bilineal}:\n",
    "\\begin{eqnarray*}\n",
    "\\big(\\ket{u}_1+\\ket{v}_1\\big)\\otimes \\big(\\ket{y}_2+\\ket{z}_2\\big) ~&\\equiv &\n",
    "\\ket{u}_1\\otimes\\ket{y}_2 ~+~ \\ket{u}_1\\otimes\\ket{z}_2 ~+~ \\ket{v}_1\\otimes\\ket{y}_2 ~+~~\n",
    "\\ket{v}_1\\otimes\\ket{z}_2 \\\\\n",
    "&=& \\ket{uy} + \\ket{uz} + \\ket{vy} + \\ket{vz}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Ahora viene la segunda definición clave:\n",
    "\\Definicion{\n",
    "El \\textbf{espacio producto tensorial}  $\\mathcal{H} = \\mathcal{H}_1 \\otimes \\mathcal{H}_2$ está formado por  \\textbf{todas} las combinaciones lineales posibles de  productos tensoriales \n",
    "\\begin{equation}\n",
    "\\ket{s}= a\\ket{u}_1\\otimes\\ket{u}_2 ~+~ b \\ket{v}_1\\otimes\\ket{v}_2 ~+ ~...\n",
    "\\end{equation}\n",
    "donde  $\\ket{u}_1,\\ket{v}_1,...\\in \\mathcal{H}_1\\, ~$ y $~\\, \\ket{u}_2,\\ket{v}_2,...\\in \\mathcal{H}~$,\n",
    "y $~a,b,... \\in {\\mathbb C}$ son coeficientes complejos.\n",
    "}\n",
    "\n",
    "\\begin{mybox_blue}{Notas para el resto de la sección}\n",
    "\\begin{itemize}\n",
    "\\item En el resto de esta lección nos restringiremos al caso de $\\mathcal{H}_1 = \\mathcal{H}_2$ y, por tanto, $d_1 = d_2 \\equiv d$, y  $\\mathcal{H}\\otimes \\mathcal{H} \\equiv \\mathcal{H}^{\\otimes 2}$ \n",
    "\\item Prescindiremos del subíndice $\\ket{u}_1\\otimes \\ket{y}_2=\\ket{u}\\otimes \\ket{y} \\equiv \\ket{uy}$ que estará implícito en el orden. \n",
    "\\item Para computación cuántica con \\textit{qúbits (qúdits)}, el valor relevante es $d=2\\,(d\\geq 3)$. \n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Base y dimension}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Sea $\\ket{e_i}$ una base de $\\mathcal{H}$. Entonces, una base de $\\mathcal{H}\\otimes \\mathcal{H}=\\mathcal{H}^{\\otimes 2}$ se obtiene\n",
    "a partir de \\textit{todos} los emparejamientos \n",
    "\\begin{equation}\n",
    "\\ket{e_{ij}} = \\ket{e_i}\\otimes \\ket{e_j}~~~~~~~~~~~~~~~~~~ i,j=1....d\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\\begin{itemize}\n",
    "\\item El número de parejas posibles es $d^2$, que coincide con la \\textbf{dimensión} de $\\mathcal{H}^{\\otimes 2}$.\n",
    "\\item Vemos que las etiquetas de los vectores de la base forman un \\textit{bi-índice} $ij=11,12,21,22,...$.\n",
    "\\item Un vector general se escribirá igualmente usando un bi-índice en lugar de un índice\n",
    "\\begin{equation}\n",
    "\\ket{\\omega} = \\sum_{i,j=1}^{d} w_{ij} \\ket{e_{ij}} ~=~\n",
    "w_{11}\\ket{e_{11}} + w_{12}\\ket{e_{12}} +\\ldots\n",
    "\\end{equation}\n",
    "donde $w_{ij}$ son $d^2$ componentes complejas.\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Producto de Kronecker}\n",
    "\n",
    "Como sabemos, cualquier vector admite, en una base, una representación como un vector columna con sus coeficientes como entradas. La matriz columna asociada $\\ket{uv}= \\ket{u}\\otimes \\ket{v}$ se forma a partir de las matrices columna de $\\ket{u}$ y $\\ket{v}$ mediante el denominado \\textbf{producto de Kronecker} o, también \\textit{producto tensorial}\n",
    "\\begin{equation}\n",
    "\\ket{uv} = \\ket{u}\\otimes \\ket{v} ~\\sim~ \n",
    "\\begin{bmatrix}u_1\\\\ u_2 \\end{bmatrix}\\otimes \\begin{bmatrix}v_1\\\\ v_2 \\end{bmatrix} ~\\equiv ~\n",
    "\\begin{bmatrix}u_1 \\begin{bmatrix}v_1\\\\ v_2 \\end{bmatrix} \\\\ u_2 \\begin{bmatrix}v_1\\\\ v_2 \\end{bmatrix}  \\end{bmatrix}\n",
    "~=~\\begin{bmatrix}u_1v_1\\\\ u_1v_2 \\\\ u_2 v_1 \\\\ u_2 v_2  \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "Con $d=2$ tendríamos $d^2 = 4$ elementos de la base de $\\mathcal{H}^{\\otimes 2}$\n",
    "$$\n",
    "\\ket{e_{11}}~=~ \\ket{e_{1}}\\otimes \\ket{e_{1}}~ \\sim~\n",
    "\\begin{bmatrix}1\\\\ 0\\end{bmatrix}\\begin{bmatrix}1\\\\ 0\\end{bmatrix} = \\begin{bmatrix}1\\\\0\\\\0 \\\\ 0\\end{bmatrix}\n",
    "~~~~~~,~~~~~\n",
    "\\ket{e_{12}}~=~ \\ket{e_{1}}\\otimes \\ket{e_{2}}~\\sim~\n",
    "\\begin{bmatrix}1\\\\ 0\\end{bmatrix}\\begin{bmatrix}0\\\\ 1\\end{bmatrix} = \\begin{bmatrix}0\\\\1\\\\0 \\\\ 0\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\ket{e_{21}}~=~ \\ket{e_{2}}\\otimes \\ket{e_{1}}~\\sim~\n",
    "\\begin{bmatrix}0\\\\ 1\\end{bmatrix}\\begin{bmatrix}1\\\\ 0\\end{bmatrix} = \\begin{bmatrix}0\\\\0\\\\1 \\\\ 0\\end{bmatrix}\n",
    "~~~~~,~~~~\n",
    "\\ket{e_{22}}~=~ \\ket{e_{2}}\\otimes \\ket{e_{2}}~\\sim~\n",
    "\\begin{bmatrix}0\\\\ 1\\end{bmatrix}\\begin{bmatrix}0\\\\ 1\\end{bmatrix} = \\begin{bmatrix}0\\\\0\\\\0 \\\\ 1\\end{bmatrix}\n",
    "$$\n",
    "El \\textit{vector más general}  $\\ket{w}\\in \\mathcal{H}\\otimes\\mathcal{H}$ admitirá una representación de la forma\n",
    "$$\n",
    "\\ket{w} ~= ~ \\sum_{i,j=1}^2 w_{ij} \\ket{e_{ij}}=~ \\begin{bmatrix}w_{11}\\\\ w_{12}\\\\ w_{21} \\\\ w_{22}  \\end{bmatrix}  ~  \n",
    "$$\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\SubsubiIt{Indexación equivalente}\n",
    "\n",
    "Podemos etiquetar las componentes (o los elementos de la base) con índices. Para ello debemos definir un mapa  entre bi-índices $i,j=1,2~$ e índices $a=1,...,4$\n",
    "\\begin{equation}\n",
    "w_{ij} =\\begin{bmatrix} w_{11} \\\\ w_{12} \\\\ w_{21} \\\\ w_{22} \\end{bmatrix} ~~~\\longleftrightarrow ~~~\n",
    "w_a  = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\\\ w_4 \\end{bmatrix} \\, ,\n",
    "\\end{equation}\n",
    "donde hemos querido resaltar que los vectores son los mismos, etiquetados de forma diferente. Haciendo lo mismo con los elementos de la base tenemmos que\n",
    "\\begin{equation}\n",
    "\\ket{w} ~= ~ \\sum_{i,j=1}^2 w_{ij} \\ket{e_{ij}} ~=~ \\sum_{a=1}^{4} w_{a} \\ket{e_{a}}\n",
    "\\end{equation}\n",
    "En el caso general, $i,j=1,...,d$ el mapa es $w_{ij}  \\to  w_a$ con\n",
    "\\begin{equation}\n",
    "a = d \\cdot (i-1) + j \n",
    "\\end{equation}\n",
    "\n",
    "\\subsection{Factorización y entrelazamiento}\n",
    "\n",
    "\\SubsubiIt{Estado factorizable o entrelazado}\n",
    "\n",
    "Llegamos a uno de los conceptos clave en Teoría Cuántica de la Información. \n",
    "\\Definicion{\n",
    "Decimos que, un vector $\\ket{w}\\in \\mathcal{H}\\otimes\\mathcal{H}$ es \\textbf{factorizable} cuando es posible encontrar vectores $\\ket{u},\\ket{v}\\in \\mathcal{H}$ tales que $ \\ket{w} = \\ket{u}\\otimes\\ket{v}$.\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Cuando esto no sea posible, decimos que  $\\ket{w}$ es un vector entrelazado.\n",
    "}\n",
    "\n",
    "Ya hemos visto que, dada una base $\\ket{e_i}$ de $\\mathcal{H}$, el vector más general que pertenece al espacio producto admite una descomposición \n",
    "$$\n",
    "\\ket{w} = \\sum_{i,j=1}^d w_{ij}\\ket{e_{i}}\\otimes \\ket{e_j} = w_{11}\\ket{e_1}\\otimes\\ket{e_1} + w_{12}\\ket{e_1}\\otimes\\ket{e_2} + ...\\, .\n",
    "$$\n",
    "Podría ocurrir que en otra base $\\ket{w} = \\tilde w_{11} \\ket{f_1}\\otimes\\ket{f_1}$ sólo tuviese un término y fuese factorizable. Discernir si un vector es factorizable o entrelazado no es algo que se pueda hacer a primera vista.\n",
    "\n",
    "\\SubsubiIt{Criterio de factorización}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "El estado es $\\ket{w}$ es factorizable si y sólo si las componentes $w_{ij}$ son factorizables en la forma $w_{ij} = u_i v_j~$ con $i,j=1,...,d$. \n",
    "\\end{mybox_gray2}\n",
    "\\begin{proof}\n",
    "$$\n",
    "\\ket{w}= \\sum_{i,j=1}^d w_{ij} \\ket{e_{ij}}  = \\sum_{i,j} u_{i}v_j \\ket{e_i}\\otimes \\ket{e_j}= \\sum_{i,j} u_{i} \\ket{e_i}\\otimes v_j\\ket{e_j}  ~ =~ \\sum_i u_i\\ket{e_i} \\otimes \\sum_j v_j\\ket{e_j} ~=~   \\ket{u}\\otimes \\ket{v}\n",
    "$$\n",
    "identidad que se puede leer en ambos sentidos\n",
    "\\end{proof}\n",
    "\n",
    "El carácter entrelazado de un vector es \\textit{genérico}, mientras que el carácter factorizable es \\textit{accidental}. Esto se sigue de un sencillo contaje: \n",
    "como función de $d$,  $\\{w_{ij}\\}$ forma un conjunto de $d^2$ parámetros complejos (grados de libertad). Sin embargo en $\\{u_i v_j\\}$ sólo hay $2d$ números independientes. Es evidente que $d^2>2d$.\n",
    "\n",
    "\\begin{mybox_blue}{Nota: caso con ${d=2}$ }\n",
    "En el caso  $d=2$  la condición $w_{ij} = u_i v_j$ es \\textit{equivalente} a verificar\n",
    "la anulación del  determinante de la matriz $2\\times 2$ formada por las componentes\n",
    "$$\n",
    "\\det w_{ij} =  w_{11}w_{22}- w_{12}w_{21} = u_1v_1u_2v_2-u_1v_2u_2v_1=0\n",
    "$$  \n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Descomposición de Schmidt}\n",
    "\n",
    "Vamos a estudiar el caso general en el que los \\textit{espacios factor} no son iguales $\\ket{w} \\in \\mathcal{H} \\otimes \\mathcal{H}_2$. Supongamos que, en sendas bases arbitrarias $\\{\\ket{e_{1,i}}, i=1,...,d_1\\}$  de $\\mathcal{H}_1$ y  $\\{\\ket{e_{2,a}},a=1,...,d_2\\}$  de $\\mathcal{H}_2$ nuestro vector se escribe\n",
    "\\begin{equation}\n",
    "\\ket{w} = \\sum_{i=1}^{d_1}\\sum_{a=1}^{d_2} w_{ia} \\ket{e_{1,i}}\\otimes \\ket{e_{2,a}}\n",
    "\\end{equation}\n",
    "Los valores de las \\textit{componentes} $w_{ia}$ \\textbf{dependen de las bases escogida}. En \\textit{otras} base $\\ket{\\tilde e_{1,i}}\\otimes\\ket{\\tilde e_{2,a}}$ encontraremos \\textit{otras} componentes $\\tilde w_{ia}$ para el \\textit{mismo} vector. \n",
    "\n",
    "Si existe una base en la que $\\tilde w_{ia}=0$ para todos los $i,a$ menos para uno (por ejemplo $\\tilde w_{11}\\neq 0$), entonces \n",
    "\\begin{equation}\n",
    "\\ket{w}= \\tilde w_{11}\\ket{\\tilde e_{1,1}}\\otimes \\ket{e_{2,1}}\n",
    "\\end{equation}\n",
    "y, secretamente, el vector $\\ket{w}$ sería factorizable.\n",
    "\n",
    "El siguiente teorema nos dice \\textbf{cuánto nos podemos acercar a esta situación}.\n",
    "\n",
    "\\Teorema{ (\\textbf{Teorema de Schmidt)} \n",
    "\n",
    "Para cada vector $\\ket{w}\\in \\mathcal{H}_1\\otimes \\mathcal{H}_2$, \\textbf{existen  bases } $\\{\\ket{f_{1,i}}\\}$  de $\\mathcal{H}_1$ y  $\\{\\ket{f_{2,i}}\\}$  de $\\mathcal{H}_2$, tales que, podemos expresar \n",
    "\\begin{equation} \\label{ec_formalismo_teorema_schmidt}\n",
    "\\ket{w} = \\sum_{i=1}^r s_i \\ket{f_{1,i}}\\otimes\\ket{f_{2,i}} \\, ,\n",
    "\\end{equation}\n",
    "con $s_i>0$, que   involucra el \\textbf{mínimo número}, $r$, de términos.\n",
    "}\n",
    "\n",
    "Es importante darse cuenta de que en la descomposición de la Ec. (\\ref{ec_formalismo_teorema_schmidt}) se está sumado solo sobre un índice. Este es igual en los dos elementos de la base en cada término. Es decir, si representamos $\\ket{\\omega}$ como una \\textbf{matriz} (en vez de como un vector), esta sería diagonal y rectangular, con los lados iguales a las dimensiones de los dos espacios $\\mathcal{H}_1$ y $\\mathcal{H}_2$.\n",
    "\n",
    "El número $1\\leq r\\leq {\\rm min}(d_1,d_2)$ se denomina \\textbf{Número de Schmidt} y  es la información relevante  porque:\n",
    "\\begin{itemize}\n",
    "\\item Cuando $r=1$, el estado $\\ket{w}$ será \\textit{factorizable}.\n",
    "\\item Cuando $r\\geq 2$, el estado será \\textit{entrelazado}.\n",
    "\\end{itemize}\n",
    "\n",
    "La demostración del Teorema de Schmidt es interesante porque nos da un \\textbf{método constructivo} para encontrar la descomposición. \n",
    "\n",
    "\\begin{proof}\n",
    "Supongamos que nuestro vector se escribe\n",
    "$$\n",
    "\\ket{w} = \\sum_{i=1}^{d_2}\\sum_{a=1}^{d_2} w_{ia} \\ket{e_{1,i}}\\otimes \\ket{e_{2,a}}\n",
    "$$\n",
    "\\vspace{0.3cm}\n",
    "\n",
    "La matriz de coeficientes $w_{ia}$ tiene  dimension $d_1\\times d_2$. El \\textbf{teorema de descomposición en valores singulares} nos garantiza que podemos expresar dicha matriz en la forma siguiente\n",
    "$$\n",
    "w = U\\Sigma V^\\dagger ~~~\\Rightarrow ~~~~w_{ia} = \\sum_{j=1}^{d_1}\\sum_{b=1}^{d_2} U_{ij}\\Sigma_{jb}V_{ab}^*\n",
    "$$\n",
    "donde $U$ y $V$ son unitarias $(d_1\\times d_1)$ y $(d_2\\times d_2)$ respectivamente, mientras que $\\Sigma$ es diagonal\n",
    "$$\n",
    "\\Sigma = \n",
    "\\overbrace{\\left.\n",
    "\\begin{bmatrix}\n",
    "s_1 &\\cdots  &    &  & & &  0  \\\\  \\vdots & \\ddots & & & & & \\vdots  \\\\  & & s_r & & & &  \\\\\n",
    "& &  & 0  & &  &    \\\\ & & & & & \\ddots &  \\\\  0 & &\\cdots  & & & & 0  \\\\ \\vdots & &&&& & \\vdots \\\\ 0 & & \\cdots & & & & 0\n",
    "\\end{bmatrix}   \\right\\}  }^{\\displaystyle d_2} d_1 ~~~~~~\\Rightarrow ~~~~~ \\Sigma_{jb} = s_j\\delta_{jb}\n",
    "$$\n",
    "Esto quiere decir que podemos escribir\n",
    "\\begin{eqnarray*}\n",
    "\\ket{w} &=& \\sum_{i=1}^{d_1}\\sum_{a=1}^{d_2}\\left( \\sum_{j=1}^{d_1}\\sum_{b=1}^{d_2} U_{ij}\\Sigma_{jb}V_{ab}^* \\right)\\ket{e_{1,i}}\\otimes \\ket{e_{2,a}}\n",
    "\\\\  \\rule{0mm}{10mm}\n",
    "&=& \\sum_{j=1}^{d_1}\\sum_{b=1}^{d_2}\\Sigma_{jb}\\left( \\sum_{i=1}^{d_1} U_{ij}\\ket{e_{1,i}} \\right)\\otimes  \\left( \\sum_{a=1}^{d_2} V_{ab}^* \\ket{e_{2,a}}\\right)\n",
    "\\\\   \\rule{0mm}{10mm}\n",
    "&=& \\sum_{j=1}^{d_1}\\sum_{b=1}^{d_2}\\Sigma_{jb} \\ket{f_{1,j}}\\otimes \\ket{f_{2,b}}\\\\   \\rule{0mm}{10mm}\n",
    "&=& \\sum_{j=1}^r s_j \\ket{f_{1,j}}\\otimes \\ket{f_{2,j}}\n",
    "\\end{eqnarray*}\n",
    "\\end{proof}\n",
    "Por tanto, podemos saber si un \\textbf{estado bipartito} es entrelazado calculando las descomposición en valores singulares de su matriz de coeficientes en cualquier base. \n",
    "\n",
    "\\subsection{Producto tensorial múltiple}\n",
    "\n",
    "El producto tensorial se puede generalizar a más de un factor:\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "El espacio $\\mathcal{H}_1\\otimes \\mathcal{H}_2 ... \\otimes \\mathcal{H}_n$ formado por \\textbf{todas} las \\textbf{n-tuplas} ordenadas de vectores \n",
    "\\begin{equation}\n",
    "\\ket{u} = \\ket{u_1u_2...u_n} \\equiv\\ket{u_1}\\otimes\\ket{u_2}\\otimes ...\\otimes \\ket{u_n}\n",
    "\\end{equation}\n",
    "donde $\\ket{u_i}\\in \\mathcal{H}_i$ y sus combinaciones lineales $\\{ a\\ket{u}+ b\\ket{v} + ...\\}$.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Salvo mención, en adelante asumiremos que todos los $\\mathcal{H}_j=\\mathcal{H}$ son iguales y de dimension $d$.\n",
    "\n",
    "\\SubsubiIt{Base}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Una base de $\\mathcal{H}^{\\otimes n}$ se obtiene a partir de cadenas \n",
    "\\begin{equation}\n",
    "\\ket{i_1 i_2.... i_n} = \n",
    "\\ket{i_1}\\ket{i_2}  ... \\ket{i_n}\n",
    "\\end{equation} \n",
    "donde $i_1,..,i_n=0,...,d-1$. \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{mybox_blue}{Nota: los multi-indices}\n",
    "Con la notación $i_1,..,i_n=0,...,d-1$ queremos decir que \\textbf{cada uno de los índices} $i_1,..,i_n$ toma valores de $0$ a $d-1$.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item El número de posibles cadenas es $d\\, d\\, ... \\, d = d^n$ que  es la dimensión de $\\mathcal{H}^{\\otimes n}$.\n",
    "\\begin{equation}\n",
    "{\\rm dim}_{\\mathbb C} \\mathcal{H}^{\\otimes n} = d^n\n",
    "\\end{equation}\n",
    "\n",
    "\\item Podemos cambiar de etiqueta\n",
    "\\begin{equation}\n",
    "\\ket{i_1...i_n} \\to \\ket{a}\n",
    "\\end{equation} \n",
    "con\n",
    "\\begin{equation}\n",
    "a = i_n + d i_{n-1} + d^2 i_{n-2}+...+d^{n-1} i_1~\\in ~(0,d^n-1)\n",
    "\\end{equation}\n",
    "\n",
    "\\item Si cada base $\\{\\ket{i}\\}$ es ortonormal, tendremos que la base producto también lo será\n",
    "\\begin{equation}\n",
    "\\braket{i_1 i_2... i_n}{j_1j_2...j_n} = \\delta_{i_1j_1}\\delta_{i_2j_2}...\\delta_{i_nj_n} ~~~~\\leftrightarrow ~~~~\n",
    "\\braket{a}{b} = \\delta_{ab}\n",
    "\\end{equation}\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Estado entrelazado}\n",
    "\n",
    "Un \\textbf{vector general} admitirá una expansión en esta base mediante $d^n$ \\textbf{componentes complejas}\n",
    "$u_{i_1 i_2...i_n}$ en la forma\n",
    "\\begin{equation}\n",
    "\\ket{u} = \\sum_{i_1,...,i_n=0}^{d-1} u_{i_1i_2...i_n} \\ket{i_1i_2...i_n} = \\sum_{a=0}^{d^n-1} u_a\\ket{a}\\, .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Nota: notación de multi-indices en el sumatorio}\n",
    "Véase que en el sumatorio anterior \\textbf{cada uno de los indice} se suma de 0 a $d-1$. Es decir\n",
    "\\begin{equation}\n",
    "\\sum_{i_1,...,i_n=0}^{d-1} = \\sum_{i_1}^{d-1} \\sum_{i_2}^{d-1} \\cdots \\sum_{i_n}^{d-1}\n",
    "\\end{equation}	\n",
    "\\end{mybox_blue}	\n",
    "\n",
    "Podemos obtener cualquier componente compleja proyectando sobre el elemento correspondiente de la base\n",
    "\\begin{equation}\n",
    "u_{i_1i_2...i_n} = \\braket{i_1 i_2... i_n}{u}~~~~~~\\leftrightarrow~~~~~~~~u_a = \\braket{a}{u}\n",
    "\\end{equation}\n",
    "\n",
    "\\SubsubiIt{Estado factorizable}\n",
    "\n",
    "Como ya comentamos, de lo más común es que un vector sea entrelazado. Lo que son casos particulares son los \\textbf{estados factorizables}. Un vector de $\\mathcal{H}^{\\otimes n}$ se podrá escribir en forma factorizada\n",
    "\\begin{equation}\n",
    "\\ket{w} = \\ket{v_1}\\ket{v_2}\\ldots\\ket{v_n} \\equiv \\ket{v_1 v_2 \\ldots v_n}\n",
    "\\end{equation}\n",
    "Escribiendo $\\ket{v_k} = \\sum_{i_k=1}^d v_{i_k}\\ket{i_k}$ vemos que un \\textit{vector factorizable} admite una expansión general en la que los coeficientes son factorizables\n",
    "\\begin{equation}\n",
    "u_{i_1i_2...i_n}  = v_{i_1} v_{i_2}.... v_{i_n}\n",
    "\\end{equation}\n",
    "están parametrizados por $nd$ cantidades $v_{i_k}, \\, i_k=1,...,d, \\, k=1,...,n$.\n",
    "\n",
    "\\begin{mybox_blue}{Notas}\n",
    "\\begin{itemize}\n",
    "\\item $nd \\ll d^n$. El crecimiento exponencial del número de estados entrelazados es el ingrediente crucial para la computación cuántica. Observar que $d^n$ es el \\textit{número de enteros} alcanzables por $n$ bits. Pero en computación cuántica es el \\textit{número de dimensiones} en la que podemos poner $d^n$ amplitudes complejas.  \n",
    "\\vspace{0.2cm}\n",
    "\n",
    "\\item No existe un criterio general para saber si un estado es, a priori, factorizable o entrelazado. \n",
    "\\vspace{0.2cm}\n",
    "\n",
    "\\item Además, hay formas de caracterizar matemáticamente el nivel de entrelazamiento (\\textit{entanglement witnesses}, \\textit{entanglement monotones} etc.) desde nulo (estado factorizable) hasta maximal (contiene todos los estados de la base con igual amplitud).\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\subsection{Espacio ${\\rm L}(\\mathcal{H}^\\otimes)$}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "El espacio $\\mathcal{H}^{\\otimes n}$ admite, como cualquier espacio vectorial, la acción de \\textit{operadores lineales} $A: \\mathcal{H}^{\\otimes n} \\to \\mathcal{H}^{\\otimes n}$ donde\n",
    "\\begin{equation}\n",
    "A:\\ket{u} \\to \\ket{v} \\equiv A\\ket{u}\n",
    "\\end{equation}\n",
    "El conjunto de todos los operadores lineales forman el espacio vectorial ${\\rm L}(\\mathcal{H}^{\\otimes n})$.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\SubsubiIt{Matrices}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item A cada operador, $A$, le podemos asociadar una \\textit{matriz}, una vez elijamos nuestra base  $\\{ \\ket{i_1 i_2... i_n}\\}$ donde, $i_a = 1,...,d$.\n",
    "\n",
    "\\item Los \\textit{elementos de matriz} ahora vendrán etiquetados por dos \\textit{multi-índices}. \n",
    "\\begin{equation}\n",
    "A_{i_1...i_n, \\, j_1...j_n} = \\bra{i_1...i_n}A\\ket{j_1...j_n}  ~~~~~\\leftrightarrow ~~~~~~ A_{ab}= \\bra{a}A\\ket{b}\n",
    "\\end{equation}\n",
    "donde hemos re-etiquetado los multi-índices como un solo índice\n",
    "\n",
    "\\item Con la matriz, el operador se reconstruye de la forma usual\n",
    "\\begin{eqnarray} \n",
    "A &=& \n",
    "\\sum_{i_1,...,i_n,\\, j_1,...,j_n=0}^{d-1} A_{i_1...i_n, \\, j_1...j_n} \\ketbra{i_1...i_n}{j_1...j_n}\n",
    "~~=~~\n",
    "\\sum_{a,b=a}^{d^{N}-1} A_{ab} \\ketbra{a}{b}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\item En $A_{i_1...i_n,\\,j_1...j_n} = A_{ab}$ hay $d^n\\times d^n = d^{2n}$ grados de libertad. Esta sería la dimensión del espacio  ${\\rm L}(\\mathcal{H}^{\\otimes n})$.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Producto tensorial de operadores}\n",
    "\n",
    "En ${\\rm L}(\\mathcal{H}^{\\otimes n})$ hay un análogo de los vectores factorizables de $\\mathcal{H}^{\\otimes n}$ que ahora serán \\textit{operadores factorizables}. Supongamos que existen $n$ operadores lineales $A^{(a)}\\, ,\\, a=1,...,n$ definidos sobre cada espacio factor $\\mathcal{H}$. \n",
    "\n",
    "\\Definicion{\n",
    "La acción del producto tensorial de operadores  $A = A^{(1)}\\otimes A^{(2)} \\otimes ...A^{(n)}$ sobre un vector $\\ket{v} = \\ket{v}_1\\otimes ...\\otimes \\ket{v_n}\\in \\mathcal{H}~$   viene dada por \n",
    "\\begin{equation}\n",
    "A\\ket{v} = A^{(1)}\\ket{v_1}\\otimes ... \\otimes A^{(n)} \\ket{v_n}\\, .	\n",
    "\\end{equation}	\n",
    "La acción sobre vectores generales se sigue imponiento linealidad\n",
    "\\begin{equation}\n",
    "A(\\ket{v} + \\ket{w}) = A\\ket{v} + A\\ket{w}\\, .\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "Se sigue automáticamente de la definición que:\n",
    "\\begin{itemize}\n",
    "\\item El adjunto de un producto tensorial de operadores es el producto de los adjuntos (no se permuta el orden)\n",
    "\\begin{equation}\n",
    "A^\\dagger = A^{(1)\\dagger} \\otimes ... \\otimes A^{(n)\\dagger}\n",
    "\\end{equation}\n",
    "\\item El producto tensorial de operadores hermíticos es hermítico\n",
    "$$ \n",
    "A^{(a)\\dagger} = A^{(a)} ~~\\Longrightarrow A^{\\dagger} = A \n",
    "$$\n",
    "\\item El producto tensorial de operadores unitarios, es unitario\n",
    "$$ \n",
    "A^{(a)\\dagger} = A^{(a)\\, -1} \\,  ~~\\Longrightarrow ~~A^{\\dagger} = A^{-1} \n",
    "$$\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Producto de Kronecker de matrices. Operadores factorizables.}\n",
    "\n",
    "¿Cómo será la matriz $A_{i_1...i_n, \\, j_1...j_n}$ de un operador factorizable, $ A = A^{(1)}\\otimes A^{(2)} \\otimes ...A^{(n)}$, en términos de las matrices  $ A^{(a)}_{ij}$ de sus factores? Vamos a tomar  $n=2$ por simplicidad\n",
    "\\begin{eqnarray}\n",
    "A = A^{(1)}\\otimes  A^{(2)} &=&\\left( \\sum_{i_1i_2}A^{(1)}_{i_1 j_1} \\ket{i_1}\\bra{j_1}\\right)\\left( \\sum_{i_2j_2}A^{(2)}_{i_2 j_2} \\ket{i_2}\\bra{j_2}\\right)\\\\\n",
    "&=& \\sum_{i_1 i_2 , j_1 j_2} A^{(1)}_{i_1 j_1}A^{(2)}_{i_2 j_2}\\ket{i_1 i_2}\\bra{j_1j_2} \\\\\n",
    "&=& \\sum_{i_1 i_2 , j_1 j_2} A_{i_1i_2,\\, j_1j_2}\\ket{i_1 i_2}\\bra{j_1j_2}\n",
    "\\end{eqnarray}\n",
    "Vemos que la matriz asociada a $A$ se obtiene  a partir de las matrices de $A^{(a)}$ mediante el  \\textit{producto exterior de las matrices}, o \\textbf{producto de Kronecker}.\n",
    "\\begin{equation}\n",
    "A_{i_1i_2,\\,j_1j_2} = A^{(1)}_{i_1j_1}A^{(2)}_{i_2 j_2} \n",
    "\\end{equation}\n",
    "El método para de \\textbf{representar} matricialmente el producto de Kronecker de dos matrices $A\\otimes B$ es sencillo. Supongamos que $d=2$ y tenemos un operador producto $A\\otimes B$. Entonces su matriz \n",
    "\\begin{equation}\n",
    "(A\\otimes B)_{ab} = \\begin{pmatrix} A_{00}B & A_{01}B \\\\ A_{10}B & A_{11}B \\end{pmatrix} = \\begin{pmatrix} A_{00}B_{00} & A_{00}B_{01} & A_{01}B_{00} & A_{01}B_{01} \\\\\n",
    "A_{00}B_{10} & A_{00}B_{11} & A_{01}B_{10} & A_{01}B_{11} \\\\\n",
    "A_{10}B_{00} & A_{10}B_{01} & A_{11}B_{00} & A_{11}B_{01} \\\\\n",
    "A_{10}B_{10} & A_{10}B_{11} & A_{11}B_{10} & A_{11}B_{11} \\end{pmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "El producto de Kronecker verifica las siguientes propiedades para dos matrices $A$  y $B$ de dimensiones $d_A$ y $d_B$. \n",
    "\\begin{eqnarray}\n",
    "(A\\otimes B)(C\\otimes D) &=& (AC)\\otimes (BD) \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "{\\rm tr}(A\\otimes B) &=& ({\\rm tr} A)({\\rm tr} B) \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "A\\otimes(B+D) &=& A\\otimes B + A\\otimes D \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "(A\\otimes B)^\\dagger &=& A^\\dagger\\otimes B^\\dagger \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "(A\\otimes B)^{-1} &=& A^{-1} \\otimes B^{-1} \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "\\det (A\\otimes B) &=& (\\det A)^{d_B}(\\det B)^{d_A}\n",
    "\\end{eqnarray}\n",
    "donde $AC$ significa el producto de matrices $A$ y $C$.\n",
    "\n",
    "\\Ejercicio{\n",
    "Demuestra estos resultados.\n",
    "}\n",
    "\n",
    "La generalización a todo $n$ es obvia. El producto de Kronecker de $n$ matrices $ A^{(a)}_{i_aj_a}$ asociadas a operadores $A^{(a)}$ es\n",
    "\\begin{equation}\n",
    "A_{i_1...i_n,\\,j_1...j_n} = A^{(1)}_{i_1j_1}...A^{(n)}_{i_n j_n} \n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{\n",
    "Calcula $\\sigma_1\\otimes \\sigma_2\\otimes \\sigma_3$\n",
    "}\n",
    "\n",
    "\\begin{mybox_blue}{Nota: operadores factorizables y no factorizables}\n",
    "Observar que en un operador general, la matriz $ A_{i_1...i_n,\\,j_1...j_n}$ tiene $d^n\\times d^n = d^{2n}$ entradas independientes. \n",
    "Sin embargo en un producto de Kronecker $A^{(1)}_{i_1j_1}...A^{(n)}_{i_n j_n}$ sólo hay $nd^2$.     \n",
    "Por tanto, los \\textit{operadores factorizables} forman un subconjunto muy pequeño dentro del conjunto de los operadores generales.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Generación de entrelazamiento}\n",
    "\n",
    "Supongamos que $\\ket{u} = \\ket{u_1}\\otimes\\ket{u_2}$ es factorizable. \n",
    "\\begin{itemize}\n",
    "\\item Si $A=A_1\\otimes A_2$ es un operador factorizable, el resultado $\\ket{v} = A\\ket{u} = A_1\\ket{u_1}\\otimes A_2\\ket{u_2}$ también es factorizable.\n",
    "\\item Inversamente, si buscamos un operador que genere entrelazamiento, entonces no puede ser factorizable $A\\neq A_1\\otimes A_2$\n",
    "\\end{itemize}\n",
    "\n",
    "\\Ejercicio{\n",
    "Considera la base $\\{\\ket{0},\\ket{1} \\}$ del espacio $\\mathcal{H}$ de dimensión 2. Sea $A= B + C$ un operador que actúa sobre el producto $\\mathcal{H}\\otimes \\mathcal{H}$,  donde $B$ y $C$ son operadores factorizables dados por  \n",
    "$$\n",
    "B = \\ketbra{0}{0}\\otimes I ~~~, ~~~~ \n",
    "C = \\ketbra{1}{1}\\otimes (\\ketbra{0}{1} + \\ketbra{1}{0})\n",
    "$$ \n",
    "Escribe los elementos $B_{ij}$ y $C_{ij}, i,j=1,2,3,4$  y obtén $A_{ij}$. Comprueba si $C$, $B$ y $A$ son operadores unitarios o no.\n",
    "}\n",
    "\n",
    "\\section{Probabilidades}\n",
    "\n",
    "La Mecánica Cuántica es \\textbf{intrinsecamente probabilística}. Por ello, es importate repasar algunos conceptos estadístico.\n",
    "\n",
    "\\subsection{Variables aleatorias}\n",
    "\n",
    "\\SubsubiIt{Variable aleatoria}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Denotamos con $(X,p(X))$ una  \\textbf{variable aleatoria} donde\n",
    "\\begin{itemize}\n",
    "\\item $X$ es el \\textbf{espacio muestral} de valores $\\{x_1, x_2,....,x_n\\}$ que pueden aparecer en una \\textit{consulta} a la variable aleatoria\n",
    "\n",
    "\\item $p(X)$ es la \\textbf{distribución de probabilidad}\n",
    "\\end{itemize}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\SubsubiIt{Distribución de probabilidad}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Una \\textbf{distribución de probabilidad} es una función real $x\\to p(x)$ que debe  verificar las dos condiciones siguientes\n",
    "\\begin{equation}\n",
    "p(x) \\in [0,1]~~~~~~~,~~~~~~~~\\sum_{x\\in X }p(x) = 1 \n",
    "\\end{equation}\n",
    "Es decir, la suma de probabilidades de todos los sucesos posibles debe ser la unidad.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\SubsubiIt{Media}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{media} de una variable aleatoria  viene dada por la expresión \n",
    "\\begin{equation}\n",
    "\\overline X  = \\sum_i x_i p(x_i)\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}	\n",
    "\n",
    "\\SubsubiIt{Varianza y desviación estándar}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{varianza}, $\\sigma_X^2$, es la  \\textit{media de la desviación cuadrática} $\\overline{(x_i - \\overline{X} )^2}$ \n",
    "\\begin{equation}\n",
    "\\sigma^2_X = \\sum_j (x_j-\\overline{X})^2 p(x_j) = \\overline{X^2} - \\overline{X}^2\n",
    "\\end{equation}\n",
    "La cantidad $\\sigma_X$ se denomina  \\textbf{desviación estándar}\n",
    "\\begin{equation}\n",
    "\\sigma_X = \\sqrt{\\overline{X^2} - \\overline{X}^2}\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}			\n",
    "\n",
    "\\subsection{La conexión estadística}\n",
    "\n",
    "Nuestro conocimiento del mundo se basa en la realización de \\textbf{experimentos}, el resultado de los cuales es (empíricamente) \\textbf{aleatorio}. Podemos pensar en el hecho de medir un sistema como la consulta de una variable aleatoria $(X,p(X))$ donde la distribución de probabilidad incorpora todo nuestro conocimiento acerca del sistema.\n",
    "\n",
    "\\SubsubiIt{Frecuencias e Histogramas}\n",
    "\n",
    "Cualquier consulta o medida da lugar a una \\textit{muestra} finita de valores $A_N = (a_1,a_2,...,a_N)$. Cada uno de estos resultados puede tomar cualquier valor $x_j$ del espacio muestral, es decir, $a_i\\in \\{x_1,...,x_n\\}$. A su vez, medidas diferentes ($a_i$ diferentes) pueden tomar valores iguales $x_j$, con números de aparición $n(x_i)$ tales que  $n(x_1) +  \\ldots + n(x_p) = N$. \n",
    "\n",
    "Estos datos se pueden agrupar en intervalos o \\textit{bins} que eliminen cierta precisión numérica. \n",
    "Por ejemplo, si truncamos nuestra precisión a las décimas de unidad,  $13.10$ y $13.19$ pertenecerán al mismo \\textit{bin}. \n",
    "\n",
    "Un \\textbf{histograma} es un diagrama en el que, por cada \\textit{bin}, hay una columna, cuya altura representa el número de sucesos que pertenecen a dicho \\textit{bin}. Podemos ver uno en la Fig. \\ref{Fig_formalismo_histograma}. \n",
    "\n",
    "\\begin{figure}[t]\n",
    "\\centering \n",
    "\\includegraphics[width=0.4\\linewidth]{Figuras/Fig_formalismo_histograma.png}\n",
    "\\caption{Ejemplo de histograma.}\n",
    "\\label{Fig_formalismo_histograma}\n",
    "\\end{figure}\n",
    "\n",
    "\\SubsubiIt{Ley de los grandes números}\n",
    "\n",
    "La conexión entre estadística y teoría de la probabilidad se da mediante la \\textbf{ley de los grandes números}. Lo que nos dice esta ley es que cuando el número de muestras tiende a infinito, $N\\to \\infty$, las fracciones relativas tienden a un número fijo que hereda, de toda la dinámica del sistema, ciertas propiedades que no se desvanecen. Este número es la probabilidad, es decir, \n",
    "\\begin{equation}\n",
    "f_N(x_i) = \\frac{n(x_i)}{N}~~~\\stackrel{N\\to\\infty}{\\longrightarrow}~~~{p(x_i)}\n",
    "\\end{equation}\n",
    "Un punto importante aquí es darnos cuenta de que experimentalmente sólo tenemos acceso a las frecuencias relativas $f_N(x_i)$ para un $N$ grande aunque \\textbf{finito}.\n",
    "\n",
    "Igualmente, nuestro conocimiento de la  media $\\overline X$  y la varianza $\\sigma_X^2$ siempre es aproximado, y se realiza a través de las medias y varianzas muestrales\n",
    "\\begin{eqnarray}\n",
    "\\overline{A}_N = \\sum_i x_i f_N(x_i)~~~&\\stackrel{N\\to\\infty}{\\longrightarrow}&~~~ \\overline{X}\\\\\n",
    "\\sigma_{A_N}^2 = \\sum_{i} (x_i - \\overline{A}_N)^2 f_N(x_i) ~~~&\\stackrel{N\\to\\infty}{\\longrightarrow}&~~~ \\sigma_X^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "Este es el enfoque \\textbf{frecuentista}.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{La distribución de Bernouilli}\n",
    "\\begin{mybox_gray2}{}\n",
    "Una \\textbf{variable aleatoria de Bernouilli} $X=(x,p(x))$ tiene dos posibles resultados\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Exito}:$\\to x=1$ con probabilidad $p(1) = p$\n",
    "\n",
    "\\item \\textbf{Fracaso}: $\\to x=0$ con probabilidad $p(0) = 1-p$\n",
    "\\end{itemize}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Podemos calcular fácilmente \n",
    "\\begin{align}\n",
    "\\overline X & = \\sum_i x_i p_i = 1 \\cdot p +0 \\cdot (1-p) = p \\\\\n",
    "\\sigma^2 & = \\sum_i (x-\\overline X)^2p_i = (1-p)^2p +(0-p) = p(1-p)\n",
    "\\end{align}\n",
    "\n",
    "\\SubsubiIt{La distribución Binomial}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{variable aleatoria binomia}l $X = (x,p(x))$ se define como\n",
    "\\begin{equation}\n",
    "x = \\text{número de éxitos obtenidos en } n \\text{ pruebas de Bernouilli sucesivas}\n",
    "\\end{equation}\n",
    "Claramente $x \\in (0,1,2,...n)$.\n",
    "\n",
    "Ahora es muy sencillo obtener la \\textbf{probabilidad} de un suceso con $x$ éxitos\n",
    "\\begin{equation}\n",
    "p(x) = \\begin{pmatrix}n\\\\ x\\end{pmatrix} p^x (1-p)^{n-x}\n",
    "\\end{equation}\n",
    "donde el primer factor tiene en cuenta las posibles ordenaciones en que aparecen $x$ éxitos en $n$ intentos.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Podemos ver esta distribución en la Fig. \\ref{Fig_formalismo_dist_binomial}.\n",
    "\n",
    "Un cálculo un poco más largo permite ver que, ahora\n",
    "\\begin{align}\n",
    "\\overline X &=  np\\\\ \\rule{0mm}{7mm}\n",
    "\\sigma^2 &= n p(1-p)\n",
    "\\end{align}\n",
    "\n",
    "\\begin{figure}[H]\n",
    "\\centering \n",
    "\\includegraphics[width=0.4\\linewidth]{Figuras/Fig_formalismo_dist_binomial.png}\n",
    "\\caption{Distribución binomial}\n",
    "\\label{Fig_formalismo_dist_binomial}\n",
    "\\end{figure}\n",
    "\n",
    "\\SubsubiIt{La distribución Normal o Gaussiana}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{distribución normal} (o \\textbf{gaussiana}) centrada en $\\mu$ y con anchura $\\sigma$ viene dada por\n",
    "\\begin{equation}\n",
    "p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp \\left({-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\right)\n",
    "\\end{equation}\n",
    "Nos encontramos ante una variable aleatoria con un espacio muestral continuo $x\\in (-\\infty,+\\infty)$. \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Podemos ver esta distribución en la Fig. \\ref{Fig_formalismo_dist_normal}. Tenemos además que\n",
    "\n",
    "\\begin{align}\n",
    "\\overline{X} &= \\int_{-\\infty}^{+\\infty} xp(x) dx = \\mu \\\\\n",
    "\\overline{(x-\\overline X)^2} &= \\int_{-\\infty}^{+\\infty} (x-\\mu)^2 p(x)dx =\\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "\\begin{figure}[h] \\setcounter{subfigure}{0}\n",
    "\\centering\n",
    "\\subfigure[Diferentes valores de $\\mu$ y $\\sigma$]{\\includegraphics[width=0.4\\linewidth]{Figuras/Fig_formalismo_dist_normal.png}}\n",
    "\\hspace{0.5cm}\n",
    "\\subfigure[Distribución de probabilidad en torno a la media]{\\includegraphics[width=0.45\\linewidth]{Figuras/Fig_formalismo_dist_normal_2.png}}\n",
    "\\caption{Distribución normal (o gaussina)}\n",
    "\\label{Fig_formalismo_dist_normal}\n",
    "\\end{figure}\n",
    "\n",
    "\\subsection{Probabilidades combinadas}\n",
    "\n",
    "Las probabilidades combinadas son la base de las \\textbf{correlaciones}. Es aquí donde la Mecánica Cuántica produce resultados inesperados clásicamente. Esto es porque cantidades que son independientes desde el punto de vista clásico, presentan correlaciones al hacer el experimento. \n",
    "\n",
    "Ahora vamos a examinar variables aleatorias formadas por dos espacios muestrales $X$ e $Y$. Dependiendo de la forma en que combinemos la observación de cada una tendremos distintas distribuciones de probabilidad\n",
    "\n",
    "\\SubsubiIt{Probabilidad combinada}\n",
    "\n",
    "Una forma de lidiar con las correlaciones es tratar el conjunto de varias variables aleatorias como una sola variable. Esta es la idea detrás de la \\textbf{probabilidad combinada}, \n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{distribución de probabilidad combinada} asocia un número $p(x,y)$ a la probabilidad de observación conjunta de $x$ \\textbf{e} $y$. \n",
    "\n",
    "De esta forma, tratamos las parejas de eventos  como un solo evento  $a = (x,y)$. Por eso, la condición de normalización ahora es \n",
    "\\begin{equation}\n",
    "\\sum_a p(a) = \\sum_{xy} p(x,y) = 1\\, .\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Distribución marginal}:\n",
    "\n",
    "La suma parcial sobre una de las dos variables conduce a sendas \\textbf{distribuciones marginales}\n",
    "\\begin{equation}\n",
    "q(x) = \\sum_{y} p(x,y) ~~~~~~~~~ \\tilde q(y) = \\sum_{x} p(x,y)\n",
    "\\end{equation}\n",
    "\n",
    "\\item \\textbf{Variables independientes}:\n",
    "\n",
    "Si dos variables aleatorias no presentan \\textbf{ninguna correlación}, decimos que son \\textbf{independientes}. En este caso las probabilidades combinadas factorizan \n",
    "\\begin{equation}\n",
    "p(x,y) = p(x) p(y)\n",
    "\\end{equation}\n",
    "La distribución de cada variable coincide con la que se deduce de marginalizar la otra\n",
    "\\begin{equation}\n",
    "\\sum_y p(x,y) = p(x)~~~~,~~~~\\sum_x p(x,y) = p(y)\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Probabilidad condicionada}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La distribución de \\textbf{probabilidad condicionada} $p(X|Y)$ asigna un número $p(x|y)$ a la probabilidad  de encontrar un suceso $X=x$ una vez \\textit{sabemos} que $Y=y$ ha sido el resultado de consultar $Y$. \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "La manera de acceder experimentalmente a estas distribuciones, es efectuar un muestreo $(a_i,b_i), i=1,...,N$ de valores de $(X,Y)$ y \\textit{seleccionar} sólo aquellos sucesos donde $b_i = y$ un valor concreto de $Y$.\n",
    "\n",
    "\\Teorema{ (\\textbf{Teorema de Bayes}): Las probabilidades condicionales y combinadas se relacionan de la forma siguiente\n",
    "\\begin{equation}\n",
    "p(x,y) = p(x|y)p(y) = p(y|x) p(x)\n",
    "\\end{equation}\n",
    "La segunda igualdad conduce al \\textbf{teorema de Bayes}\n",
    "\\begin{equation}\n",
    "p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\subsection{Entropía de una una variable aleatoria}\n",
    "\n",
    "\\Definicion{\n",
    "Dada una variable aleatoria $(X,p(X))$ definimos la \\textbf{entropía} asociada mediante la expresión\n",
    "\\begin{equation}\n",
    "H = -\\sum_x p(x)\\log p(x)\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item El signo negativo hace esta expresión positiva, debido a que $\\log p(x)\\leq 0$.\n",
    "\n",
    "\\item El valor de $H$ está acotado entre $H\\in [0,\\log(N)]$ donde $N$ es el número de sucesos $x$ posibles\n",
    "\n",
    "\\item Si $p(x_i)=0 \\,\\,  \\forall x_i$ excepto $p(x_0)=1$ para un evento posible $\\Rightarrow H=0$\n",
    "\n",
    "\\item Si $p(x_i) = 1/N$ es equiprobable $\\Rightarrow H = \\log(N)$ y este es el valor máximo. \n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "La entropía de la distribución de Bernoulli es \n",
    "\\begin{equation}\n",
    "H = - p\\log p -(1-p)\\log (1-p)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{figure}[H]\n",
    "\\centering \n",
    "\\includegraphics[width=0.5\\linewidth]{Figuras/Fig_formalismo_binaryentropy.png}\n",
    "\\caption{Entropía para una distribución de Bernouilli}\n",
    "\\label{Fig_formalismo_binaryentropy}\n",
    "\\end{figure}\n",
    "\\end{mybox_green}\n",
    "\n",
    "\\chapter{Fundamentos de Mecánica Cuántica} \\label{cap_fundamentos}\n",
    "\n",
    "En este capítulo vamos a hacer una introducción a los fundamentos de la Mecánica Cuántica. Este capitulo se basa en \\cite{Curso-JMas}, que a su vez toma como referencias los capítulos 1 y 3 de \\cite{Claude}, los capítulos 1, 3 y 4 de \\cite{le_bellac_2006} y los capítulos 1-6 de \\cite{fayngold2013quantum}. \n",
    "\n",
    "Para más información sobre Mecánica Cuántica, se recomienda el famoso libro de Griffits \\cite{griffiths_schroeter_2018}.\n",
    "\n",
    "\\section{Axiomas}\n",
    "\n",
    "\\subsection{¿Qué es un axioma?}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Axioma} es una proposición tan clara y evidente que se admite sin demostración. Aplicado en matemáticas y otras ciencias, es cada uno de los principios indemostrables sobre los que, por medio de un razonamiento deductivo, se construye una teoría.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{mybox_green}{Ejemplo}\n",
    "Un ejemplo son los axiomas (postulados) de la geometría euclidiana:\n",
    "\\begin{enumerate}\n",
    "\\item Es posible trazar una línea recta desde cualquier punto a cualquier otro punto.\n",
    "\\item Es posible prolongar un segmento de recta continuamente en ambas direcciones.\n",
    "\\item Es posible describir una circunferencia con cualquier centro y cualquier radio.\n",
    "\\item Es cierto que todos los ángulos rectos son iguales entre sí.\n",
    "\\item ("Postulado de las paralelas") Es cierto que, si una recta que cae sobre dos rectas hace que el ángulos interiores de un mismo lado sean menores que dos ángulos rectos, las dos rectas, si se producen indefinidamente, se intersecan en aquel lado en el que están los ángulos menores que los dos ángulos rectos.\n",
    "\\end{enumerate}\n",
    "\\end{mybox_green}	\n",
    "\n",
    "\\subsection{Axiomas de la mecánica cuántica}	\n",
    "\n",
    "La Mecánica Cuántica es una teoría fundamentada en unos pilares axiomáticos cuya selección admite cierta flexibilidad. La más aceptada constituye lo que se denomina la \\textbf{interpretación de Copenhagen}. \n",
    "\n",
    "\\SubsubiIt{Vector de estado}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "En un instante, $t$, la \\textbf{máxima información accesible} de un sistema está asociada a un \\textbf{vector de estado} $\\ket{\\psi}$, de norma unidad, $\\braket{\\psi}{\\psi}=1$,  \n",
    "perteneciente a un espacio de Hilbert $\\mathcal{H}$\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item La dimensión de $\\mathcal{H}$ está relacionada con el número de grados de libertad del sistema.\n",
    "\n",
    "\\item La \\textbf{fase global} del vector de estado no contiene información: dos vectores que difieran en una fase global representan al mismo estado ningún experimento permite distinguirlos\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} \\sim \\ket{\\psi'} =  e^{i\\varphi}\\ket{\\psi} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "\\item El vector de estado recibe también el nombre de \\textbf{función de onda}.\n",
    "\\end{itemize}\n",
    "\\SubsubiIt{Medidas}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "A una magnitud física medible, le está asociado   un operador hermítico  $ A= A^\\dagger$ que denominamos \\textbf{observable}.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Los resultados de una medición no pueden dar como resultado nada más que uno de los valores propios de $A \\Rightarrow \\lambda_n$.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item Las magnitudes medibles son números reales, de ahí la exigencia de que $A$ deba ser un operador hermítico.\n",
    "\n",
    "\\item La información contenida en $\\ket{\\psi}$ es \\textbf{intrínsecamente probabilística} (no hay variables ocultas). Los resultados de una medida son inciertos, pero $\\psi$ codifica una distribución de probabilidad. \n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Regla de Born}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La probabilidad de obtener  el autovalor $\\lambda_k$ como resultado de una cierta medición, viene dada por la expresión\n",
    "\\begin{equation}\n",
    "p(\\lambda_k)~ = ~|\\braket{\\lambda_k}{\\psi}|^2\n",
    "\\end{equation}\n",
    "donde $\\ket{\\lambda_k}$ es el autovector asociado. \n",
    "\\end{mybox_gray2}\n",
    "\n",
    "El valor $\\braket{\\lambda_k}{\\psi}$ se denomina \\textbf{amplitud}.\n",
    "\n",
    "La fórmula anterior es cierta cuando el autovalor en cuestion es \\textit{no degenerado}. La expresión correcta cuando $\\lambda_k$ tiene degeneración $d_k$ es\n",
    "\\begin{equation} \\label{ec_fundamentos_p_para_lambda_degenerado}\n",
    "\\boxed{p(\\lambda_k)~ = ~ \\sum_{a=1}^{d_k}|\\braket{\\lambda^a_k}{\\psi}|^2}\n",
    "\\end{equation}   \n",
    "\n",
    "\\SubsubiIt{Colapso de la función de ondas}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "Si el resultado de una medida  ha sido  $\\lambda_n$, el estado del sistema, inmediatamente después de la medida, viene dado por el vector propio  $\\ket{\\lambda_n} \\in \\mathcal{H}$, normalizado $|\\braket{\\lambda_n}{\\lambda_n}|=1$\n",
    "\\begin{equation}\n",
    "\\ket{\\psi}~\\stackrel{\\lambda_n}{\\Longrightarrow}~ \\ket{\\lambda_n} \n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\SubsubiIt{Evolución en el tiempo}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "El cambio  del estado del sistema $\\ket{\\psi(t)}$ es \\textit{determinista} y \n",
    "está gobernado por la \\textbf{Ecuación de Schrödinger}\n",
    "\\begin{equation} \\label{ec_fundamentos_ec_de_schrodinger}\n",
    "i\\hbar \\frac{\\partial\\ket{\\psi}}{\\partial t} = H \\ket{\\psi} \\, ,\n",
    "\\end{equation}\n",
    "donde el Hamiltoniano, $H$, es un operador hermítico que \\textit{caracteriza} el sistema, y $\\hbar$ es una \\textit{constante universal} denominada \\textbf{constante de Planck}\n",
    "\\begin{equation}\n",
    "\\hbar = 1.054 \\times 10^{-34} \\, J \\cdot s\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item $J$=Julio: Unidad en el Sistema Internacional para la Energía\n",
    "\\item $s=$segundos: Unidad en el Sistema Internacional para el tiempo. \n",
    "\\end{itemize}\n",
    "\n",
    "\\section{Bases ortogonales}\n",
    "\n",
    "En Mecánica Cuántica especificamos un estado usando las componentes de la expansión del mismo en una base ortogonal. Existen infinitas bases posibles para expresar un vector. ¿Cuál es la mejor base? La respuesta es que depende del proceso que estudiemos. \n",
    "\n",
    "Por ejemplo, si el proceso es la \\textit{medida} de un cierto observable $A = A^\\dagger$, según los postulados el resultado de nuestra medición sólo puede ser uno de los \\textit{valores propios} $\\lambda_i$\n",
    "\\begin{equation}\n",
    "A \\ket{\\lambda_k} = \\lambda_k \\ket{\\lambda_k} \\,,\n",
    "\\end{equation}\n",
    "donde $\\ket{\\lambda_k}$ son los autovectores $k = 1,2,\\dots$. Estos autovectores forman una base ortonormal (ver Ecs. (\\ref{ec_op_hermitico_autovec_ortonorm}) y (\\ref{ec_op_hermitico_autovec_ortogonal})). Esta es la base natural adaptaba al proceso de medida de $A$. En particular, para conocer con que probabilidad se producirá cada resultado, expandiremos el estado de la forma\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = \\sum_{i=1}^{N} a_i \\ket{\\lambda_i} \\, .\n",
    "\\end{equation}\n",
    "El axioma III (regla de Born) afirma que la \\textit{probabilidad de aparición} del resultado $\\lambda_i$ es precisamente\n",
    "\\begin{equation}\n",
    "p(\\lambda_i) = | \\braket{\\lambda_i}{\\psi} |^2 = |a_i|^2 \\, .\n",
    "\\end{equation}\n",
    "\n",
    "La forma de tener acceso experimental a los números $p(\\lambda_i)$ es mediante la repetición estadística. Si efectuamos la medida un número $n$ de veces con $n \\rightarrow \\infty$, y contamos la frecuencia de aparición de los distintos $\\lambda_i$, esto es \n",
    "\\begin{equation}\n",
    "p(\\lambda_i) \\approx \\frac{n(\\lambda_i)}{n} \\, ,\n",
    "\\end{equation}\n",
    "en el límite $n \\rightarrow \\infty$ dicha frecuencia experimental convergerá a la probabilidad teórica\n",
    "\\begin{equation}\n",
    "\\lim_{n \\rightarrow \\infty} \\frac{n(\\lambda_i)}{n} = p(\\lambda_i) = | a_i |^2 \\, .\n",
    "\\end{equation}\n",
    "Vemos que, \\textit{mediante la repetición estadística, solamente podemos recuperar el módulo de las amplitudes}\n",
    "\\begin{equation}\n",
    "|a_i| = \\lim_{n \\rightarrow \\infty} \\sqrt{\\frac{n(\\lambda_i)}{n}}\n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{Generalizar las expresiones anteriores al caso en que los autovalores $\\lambda_k$ puedan ser $d_k$ veces degenerados.\n",
    "}\n",
    "\n",
    "\\section{Medidas Estadísticas}\n",
    "\n",
    "\\subsection{Valor esperado}\n",
    "\n",
    "Vamos a reescribir la Ec. (\\ref{ec_fundamentos_p_para_lambda_degenerado})\n",
    "\\begin{eqnarray} \\label{ec_fundamentos_p_para_lambda_degenerado_proyector}\n",
    "p(\\lambda_k)~ \n",
    "&=& ~ \\sum_{a=1}^{d_k}|\\braket{\\lambda^a_k}{\\psi}|^2 \n",
    "= \\sum_{a=1}^{d_k} \\braket{\\psi}{\\lambda^a_k}\\braket{\\lambda^a_k}{\\psi}  \n",
    "=\\bra{\\psi}\\left(\\sum_{a=1}^{d_k}\\ketbra{\\lambda^a_k}{\\lambda^a_k}\\right) \\ket{\\psi}\\nonumber\\\\\n",
    "&=&  \\bra{\\psi}P_k\\ket{\\psi} \n",
    "\\end{eqnarray}    \n",
    "donde \n",
    "\\begin{equation}\n",
    "\\boxed{P_k = \\sum_{a=1}^{d_k} \\ket{\\lambda^a_k}\\bra{\\lambda^a_k}}\n",
    "\\end{equation}\n",
    "es el \\textbf{proyector sobre el subespacio propio} (ver Ec. (\\ref{ec_formalismo_proyec_subespacio_propio})).\n",
    "\n",
    "Por el \\textbf{valor esperado} $\\langle A\\rangle$ del \\textit{observable} $A$ en el estado $\\ket{\\psi}$, entendemos el \\textit{valor medio} de la variable aleatoria $\\lambda_n$ obtenida por el método descrito. \n",
    "\\begin{eqnarray}\n",
    "\\langle A\\rangle \n",
    "&= &  \\sum_k \\lambda_k p(\\lambda_k)\n",
    "=  \\sum_k \\lambda_k \\bra{\\psi}P_k\\ket{\\psi}  \\nonumber \\\\\n",
    "&=& \\bra{\\psi}\\left(\\sum_k \\lambda_k P_k  \\right) \\ket{\\psi} \n",
    "\\end{eqnarray}\n",
    "Reconocemos entre paréntesis la descomposición espectral de $A$. Llegamos así a la siguiente expresión para el valor esperado de un observable $A$ en un estado $\\ket{\\psi}$:\n",
    "\n",
    "\\Teorema{ El \\textbf{valor esperado de un operador} es\n",
    "\\begin{equation}\n",
    "\\langle A \\rangle=\\bra{\\psi}A \\ket{\\psi}\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item En particular, las probabilidades mismas se pueden expresar como \\textit{valores esperados del proyector asociado}\n",
    "\\begin{equation}\n",
    "p(\\lambda_k ) =  \\bra{\\psi}P_k\\ket{\\psi} = \\langle P_k\\rangle \n",
    "\\end{equation}\n",
    "\n",
    "\\item El valor esperado de un observable en uno de sus autoestados coincide con el autovalor asociado\n",
    "\\begin{equation}\n",
    "\\bra{\\lambda_i}A \\ket{\\lambda_i} = \\bra{\\lambda_i}\\lambda_i \\ket{\\lambda_i}  = \\lambda_i \\braket{\\lambda_i}{\\lambda_i} = \\lambda_i\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "El espectro de un observable está formado por números reales que podemos ordenar $\\lambda_{min}<...<\\lambda_{max}$.\n",
    "\n",
    "\\Teorema{\n",
    "El valor esperado de un observable $A$ está acotado entre sus valores propios mínimo y máximo\n",
    "\\begin{equation}\n",
    "\\lambda_{min} \\leq \\bra{\\psi}A\\ket{\\psi} \\leq \\lambda_{max}\n",
    "\\end{equation}\n",
    "y las desigualdades anteriores se saturan en los autoestados correspondientes\n",
    "}\n",
    "\n",
    "\\subsection{Varianza y Desviación estándar}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "La \\textbf{varianza} es la media de la desviación cuadrática de la variable aleatoria $(\\lambda,p(\\lambda))$ es decir \n",
    "\\begin{equation}\n",
    "~~\\sigma ^2 = \\overline{(\\lambda_i-\\bar\\lambda_i)^2}= \\overline{\\lambda^2} - \\overline{\\lambda}^2\n",
    "\\end{equation}\n",
    "de aquí se sigue, para la \\textbf{desviación estándar}\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\bra{\\psi}A^2\\ket{\\psi} - \\bra{\\psi} A\\ket{\\psi}^2}\n",
    "\\end{equation}\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\section{Evolución temporal}\n",
    "\n",
    "\\SubsubiIt{Ecuación de Schrödinger}\n",
    "\n",
    "El estado de un sistema $\\ket{\\psi(t)}$ posee la máxima información instantánea accesible de un sistema, es decir, a un tiempo dado $t$. Dado $\\ket{\\psi(t_0)}$ en un instante inicial $t_0$, la evolución posterior obedece a la  ecuación diferencial de Schrödinger\n",
    "\\begin{equation} \\label{ec_fundamentos_ec_de_schrodinger_con_t}\n",
    "i \\hbar \\frac{d}{d t}\\ket{\\psi(t)} = H(t) \\ket{\\psi(t)} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "\\begin{itemize}\n",
    "\\item El operador Hamiltoniano $H(t)$  contiene toda la información sobre la dinámica del sistema.\n",
    "\\item Hemos enfatizado el hecho de que, en el caso más general, $H(t)$ puede depender del tiempo.\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Conservación de la probabilidad}\n",
    "\n",
    "La hermiticidad de $H$ se relaciona directamente con la interpretación probabilística de $\\ket{\\psi}$. Efectivamente, en \\textit{la evolución temporal se conserva la norma del vector de estado}\n",
    "\\begin{eqnarray}\n",
    "\\frac{d}{dt}\\braket{\\psi(t)}{\\psi(t)} &=& \\left(\\rule{0mm}{3mm}\\frac{d}{dt}\\bra{\\psi(t)}\\right)\\ket{\\psi(t)} + \n",
    "\\bra{\\psi(t)}\\left(\\frac{d}{dt}\\ket{\\psi(t)} \\right)\\nonumber\\\\\n",
    "&=& \\left(\\bra{\\psi(t)}\\frac{i}{\\hbar}H^\\dagger\\right)\\ket{\\psi(t)} + \\bra{\\psi(t)}\\left(-\\frac{i}{\\hbar}H\\ket{\\psi(t)} \\right) \\\\\n",
    "&=&\\frac{i}{\\hbar} \\bra{\\psi(t)}(H^\\dagger - H)\\ket{\\psi(t)} = 0 \\nonumber\n",
    "\\end{eqnarray}\n",
    "Esto implica que la norma de $\\ket{\\psi(t)}$ se conserva $\\Rightarrow 1 = \\|\\ket{\\psi(0)}\\| =\\|\\ket{\\psi(t)}\\|$\n",
    "\n",
    "\\SubsubiIt{Operador de evolución}\n",
    "\n",
    "La conservación de la norma implica que la evolución $\\|\\ket{\\psi(0)\\|} =\\|\\ket{\\psi(t)}\\|$ es un \\textit{proceso unitario}. En otras palabras, debe existir un operador unitario \n",
    "\\begin{equation}\n",
    "U(t,t_0)^{-1}= U(t,t_0)^\\dagger \n",
    "\\end{equation}\n",
    "que lleve el estado inicial al actual a tiempo $t$\n",
    "\\begin{equation}\n",
    "U(t,t_0): \\ket{\\psi(t_0)}~~ \\to~~ \\rule{0mm}{3.5mm} \\ket{\\psi(t)} = U(t,t_0)\\ket{\\psi(t_0)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Propiedades de ${U(t,t_0)}$}\n",
    "El operador de evolución satisface las siguientes propiedades\n",
    "\\begin{itemize}\n",
    "\\item $U(t_0,t_0) = I$ \\, .\n",
    "\\item transitividad:  $U(t,t_1)U(t_1,t_0)= U(t,t_0)$\n",
    "\\item invertibilidad: $U(t,t_0)^{-1} = U(t_0,t)$\n",
    "\\end{itemize}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "Evidentemente, el operador de evolución debe estar relacionado con el Hamiltoniano, que es quien gobierna la dinámica. Veamos a ver que hay una ecuación de Schrödinger también para el operador de evolución\n",
    "\n",
    "\\Teorema{\n",
    "El operador de evolución satisface la siguiente ecuación de evolución\n",
    "\\begin{equation}\n",
    "i \\hbar \\frac{d}{dt}U(t,t_0) = H(t)\\, U(t,t_0)\n",
    "\\end{equation}\n",
    "}\n",
    "\\begin{proof}\n",
    "Tomando la derivada temporal de la ecuación $\\ket{\\psi(t)} = U(t,t_0)\\ket{\\psi(t_0)}$, que define $U(t,t_0)$, tenemos para cada miembro\n",
    "\n",
    "\\begin{eqnarray}\n",
    "i \\hbar \\frac{d}{dt}\\ket{\\psi(t)} &~=~&   H(t)\\ket{\\psi(t)} =  H(t)U(t,t_0)\\ket{\\psi(t_0)}  \\nonumber\\\\\n",
    "i \\hbar \\frac{d}{dt}\\ket{\\psi(t)} &~=~& i \\hbar \\frac{d}{dt}U(t,t_0)\\ket{\\psi(t_0)} = i \\hbar \\left(\\frac{d}{dt}U(t,t_0)\\right)\\ket{\\psi(t_0)}\n",
    "\\end{eqnarray}\n",
    "Igualando ambas expresiones, y teniendo en cuanto que $\\ket{\\psi_0}$ es arbitrario, obtenemos la ecuación deseada.\n",
    "\\end{proof}\n",
    "\n",
    "\\SubsubiIt{Caso de $H$ independiente del tiempo}\n",
    "\n",
    "Cuando $H$ no depende del tiempo podemos dar una expresión analítica para el operador de evolución\n",
    "\\Teorema{\n",
    "Para un hamiltoniano $H$ independiente del tiempo, el operador de evolución $U(t,t_0)$ es\n",
    "\\begin{equation}\n",
    "U(t,t_0) = \\exp\\left({-\\frac{i}{\\hbar} (t-t_0)H}\\right)\n",
    "\\end{equation}\n",
    "}\n",
    "\\begin{proof}\n",
    "Basta con demostrar que se satisface la ecuación de evolución y la condición de contorno\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{d}{dt}U(t,t_0) &=& \\frac{d}{dt} \\exp\\left({-\\frac{i}{\\hbar} (t-t_0)H}\\right)\n",
    "\\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "&=& \\frac{d}{dt}\\left( I +(t-t_0)\\left(-\\frac{i}{\\hbar} H\\right) + \\frac{1}{2!} \n",
    "(t-t_0)^2\\left(-\\frac{i}{\\hbar} H\\right)^2  + ...\\right) \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "&=& 0 +  \\left(-\\frac{i}{\\hbar} H\\right) +  (t-t_0)\\left(-\\frac{i}{\\hbar} H\\right)^2  + ... \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "&=&  \\left(-\\frac{i}{\\hbar} H\\right)\\left( I + (t-t_0) \\left(-\\frac{i}{\\hbar} H\\right) + ...\\right)\n",
    "\\nonumber \\\\ \\rule{0mm}{6mm} \n",
    "&=& \\left(-\\frac{i}{\\hbar} H\\right) \\exp\\left({-\\frac{i}{\\hbar} (t-t_0)H}\\right)    \\nonumber\\\\ \\rule{0mm}{6mm}\n",
    "&=& -\\frac{i}{\\hbar} H \\,  U(t,t_0)\n",
    "\\end{eqnarray}\n",
    "Además\n",
    "\\begin{equation}\n",
    "U(t_0,t_0) =  \\exp\\left({-\\frac{i}{\\hbar} (t_0-t_0)H}\\right)=\\exp(0) = I\n",
    "\\end{equation}\n",
    "\\end{proof}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "La cantidad ${-\\frac{i}{\\hbar} (t-t_0) H }$ es adimensional\n",
    "\\begin{equation}\n",
    "\\frac{1}{\\hbox{J}\\cdot \\hbox{s}}\\hbox{s}\\cdot\\hbox{J} = 1\n",
    "\\end{equation}\n",
    "Es decir, es un número puro. Por eso podemos exponenciarla. El operador de evolución $U(t,t_0)$ es, por tanto, también, una magnitud adimensional.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Evolución en la base de eutoestados de $H$}\n",
    "\n",
    "Sea $\\{\\ket{n}\\}$ una base de autoestados de $H \\, \\Rightarrow \\,H \\ket{n} = E_n \\ket{n}$, $n=1,..,N$. En esta base $H$ es una matriz $H_{mn}$ diagonal \n",
    "\\begin{equation}\n",
    "H_{mn} =  \\begin{bmatrix} E_0 &  & & \\\\  & E_1 &  & \\\\ & & \\ddots & \\\\ & & & \\end{bmatrix} =E_m \\delta_{mn} \\, .\n",
    "\\end{equation}\n",
    "Entonces la matriz de evolución es también diagonal \n",
    "\\begin{equation}\n",
    "U_{mn} = \\exp\\left(-\\frac{i}{\\hbar}t H_{mn}\\right) = \n",
    "\\begin{bmatrix} e^{-\\frac{i}{\\hbar}t E_0} &  & & \\\\  & e^{-\\frac{i}{\\hbar} t E_1}  &  & \\\\ & & \\ddots & \\\\ & & & \\end{bmatrix} = e^{-\\frac{i}{\\hbar} t  E_m }\\delta_{mn} \\, .\n",
    "\\end{equation}\n",
    "\n",
    "En conclusión:\n",
    "\\begin{itemize}\n",
    "\\item La evolución temporal de un autoestado de la energía es trivial (es una fase global)\n",
    "\\begin{equation}\n",
    "U(t,0)\\ket{n} = e^{-\\frac{i}{\\hbar} t E_n} \\ket{n}\\, \n",
    "\\end{equation}\n",
    "Es decir, un autoestado del hamiltoniano es un \\textbf{estado estacionario}. Si nuestro sistema está en un autoestado del hamiltoniano, este no cambiará con el tiempo.\n",
    "\n",
    "\\item Esta fase deja de ser trivial cuando afecta a una combinación lineal. La forma más eficaz de calcular la evolución de un estado arbitrario es expresarla en la base $\\{\\ket{n}\\}$. Es decir, si a $t=0$\n",
    "\\begin{equation}\n",
    "\\ket{\\psi(t=0)} = \\sum_n c_n \\ket{n} \\, \n",
    "\\end{equation}\n",
    "entonces, a tiempo $t$ \n",
    "\\begin{equation}\n",
    "\\ket{\\psi(t)} = \\sum_n c_n e^{-\\frac{i}{\\hbar}E_nt} \\ket{n} \\, .\n",
    "\\end{equation}\n",
    "En esta base, la evolución temporal lo que hace es que las fases relativas de los autoestados evolucionen a velocidades diferentes.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_orange}{Jupyter Notebook: 00-Fundamentos\\_MC\\_evolucion\\_temporal}\n",
    "Puede verse el Notebook \\textit{00-Fundamentos\\_MC\\_evolucion\\_temporal}. En el se muestran dos ejercicios resueltos sobre como calcular la evolución temporal en python.\n",
    "Qiskit en Python.\n",
    "\\end{mybox_orange}\n",
    "\n",
    "\\section{Estados Mezcla y Matriz Densidad}\n",
    "\n",
    "\\subsection{Estado puro y mezcla}\n",
    "\n",
    "Hasta ahora hemos estado estudiando casos \\textbf{ideales}, donde los estados que tenemos son \\textit{perfectos}, en el sentido de que tenemos el estado que creemos tener con una probabilidad del 100\\%. Esto en la vida real no es así. Cuando intentamos generar un estado cuántico, nunca vamos a generar estos estados perfectos, pues nuestros aparatos no son perfectos y nunca lo serán. Todo aparato lleva asociada una \\textbf{incertidumbre}, es decir, una probabilidad de error.\n",
    "\n",
    "A estos estados \\textit{perfectos} se los denomina \\textbf{estados puros}, mientras que al resto de estados se los denomina \\textbf{estados mezcla}.\n",
    "\n",
    "\\SubsubiIt{Estos puros}\n",
    "\n",
    "Si sabemos \\textit{con seguridad} que el  sistema se encuentra en un estado $\\ket{\\psi}\\in \\mathcal{H}$ \\textit{toda la incertidumbre} que queda es cuántica.\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Estado puro}:\n",
    "\n",
    "Si con \\textit{certeza total} podemos afirmar que el estado de un sistema está descrito por un vector $\\ket{\\psi}\\in \\mathcal{H}$ decimos que nuestro sistema se encuentra en un \\textbf{estado puro}.\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Tomemos un estado \\textbf{superposición} \n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = a\\ket{0} + b\\ket{1}\n",
    "\\end{equation}\n",
    "con $a,b \\neq 0$. \n",
    "La probabilidad de medir el estado $\\ket{0}$ será positiva\n",
    "\\begin{equation}\n",
    "p(0) = |\\braket{0}{\\psi}|^2  = \n",
    "\\left\\vert\\bra{0}\\big(a\\ket{0}+b\\ket{1}\\big)\\right\\vert^2=\\left\\vert a\\braket{0}{0}+b \\braket{0}{1}\\right\\vert^2 = |a|^2\n",
    "\\end{equation}\n",
    "la de medir el estado $\\ket{1}$ también\n",
    "\\begin{equation}\n",
    "p(1) = |\\braket{1}{\\psi}|^2  = \\left\\vert\\bra{1}\\big(a\\ket{0}+b\\ket{1}\\big)\\right\\vert^2 =\\left\\vert a\\braket{1}{0}+b \\braket{1}{1}\\right\\vert^2= |b|^2\n",
    "\\end{equation}\n",
    "y la de medir el estado $\\ket{+} =  \\frac{1}{\\sqrt{2}}(\\ket{0}+\\ket{1})$ será\n",
    "\\begin{eqnarray}\n",
    "p(+)&=&|\\braket{+}{\\psi}|^2 =  \\frac{1}{2}\\left\\vert\\big(\\bra{0}+ \\bra{1}\\big)\\big(a\\ket{0}+b\\ket{1}\\big)\\right\\vert^2 = \\frac{1}{2}\\left\\vert\\big(a\\braket{0}{0}+b\\braket{1}{1}\\big)\n",
    "\\right\\vert^2  \\nonumber \\\\\n",
    "&=&\\frac{1}{2}|a+b|^2  = \\frac{1}{2}(a+b)(a^* + b^*) \n",
    "\\\\\n",
    "&=& \\frac{1}{2}\\left(\\rule{0mm}{4mm} |a|^2 + |b|^2 + 2{\\rm Re}(ab^*) \\right) \\nonumber\n",
    "\\end{eqnarray}    \n",
    "El término que no tiene signo definido $2{\\rm Re}(ab^*)$ se denomina \\textit{interferencia}. \n",
    "Es el responsable de que $p(+)=0$ se pueda anular aun cuando $a,b\\neq 0$. Concretamente cuando $a=1=-b$\n",
    "\\begin{equation}\n",
    "\\ket{\\psi}=   \\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1}) = \\ket{-}\n",
    "\\end{equation}\n",
    "y los estados son ortogonales $|\\braket{\\psi}{+}|^2=|\\braket{-}{+}|^2= p(\\ket{-}\\to\\ket{+})=0$, obteniendo $p(+)=0$.\n",
    "\n",
    "\\SubsubiIt{Estados mezcla}\n",
    "\n",
    "¿Qué ocurre si no podemos tener la certeza de que el estado que describe el sistema sea $\\ket{\\psi}$?  \n",
    "\n",
    "Por ejemplo: supongamos que, \n",
    "\\begin{itemize}\n",
    "\\item a la salida de un polarizador de Stern Gerlach, encontramos que el estado es $\\ket{+}$, \n",
    "\\item pero la fiabilidad nominal de dicho aparato es del 90\\%. \n",
    "\\item Eso quiere decir que, con un 10\\% de probabilidad, el estado emergente ha sido, en realidad, $\\ket{-}$.\n",
    "\\end{itemize}\n",
    "Nuestro polarizador se comporta como una \\textit{variable aleatoria} $ \\{\\{\\ket{+},0.9\\},\\{\\ket{-},0.1\\}\\}$ de la que obtendremos, cada vez, un estado u otro con distinta probabilidad. \n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "Véase que esta incertidumbre debida al error del polarizador que genera el estado es clásica, no cuántica.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Estados mezcla}:\n",
    "\n",
    "En la situación más general, un  sistema estará en un \\textbf{estado mezcla} asociado a una variable aleatoria\n",
    "\\begin{equation}\n",
    "\\{\\ket{\\psi_\\alpha},p_\\alpha\\}\n",
    "\\end{equation}\n",
    "que indica que, con probabilidad $p_\\alpha$,  el estado real del sistema es $\\ket{\\psi_\\alpha}$\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item Un estado mezcla no es un vector en el espacio de Hilbert, sino que es una variable aleatoria donde el espacio muestral son vectores en el espacio de Hilbert.\n",
    "\n",
    "\\item Es importante recalcar que las probabilidades $p_\\alpha \\in  \\mathbb{R}$ son incertidumbres clásicas, y por tanto $p_k \\in \\lc 0,1 \\rc$, $\\sum_\\alpha p_\\alpha = 1$.\n",
    "\n",
    "\\item El estado mixto contiene al estado puro como caso particular en el que para un cierto valor $\\alpha = i$, tenemos $p_i = 1$ y el resto son cero. \n",
    "\\end{itemize}\n",
    "\n",
    "\\subsection{Operador densidad}\n",
    "\n",
    "El formalismo matemático que nos permite lidiar con los estados mezcla pasa por usar la \\textbf{matriz densidad}.\n",
    "\n",
    "Supongamos que a nuestro sistema le podemos asignar un estado mixto $\\{\\ket{\\psi_\\alpha},p_\\alpha\\}$. La probabilidad, $p(\\lambda_n)$, de encontrar un autovector $\\ket{\\lambda_n}$ como resultado de la medida de un observable $A$, debe ser la \\textit{suma ponderada} de probabilidades  de esa medida en cada uno de los estados $\\ket{\\psi_\\alpha}$\n",
    "\\begin{equation} \\label{ec_fundamentos_op_dens_prob}\n",
    "\\begin{array}{rcl} \n",
    "p(\\lambda_n) &=& \\sum_\\alpha p_\\alpha |\\braket{\\lambda_n}{\\psi_\\alpha}|^2  =  \\sum_\\alpha p_\\alpha \\braket{\\lambda_n}{\\psi_\\alpha}\\braket{\\psi_\\alpha}{\\lambda_n} \\\\ \\rule{0mm}{6mm}\n",
    "&=& \\bra{\\lambda_n}\\left(\\rule{0mm}{6mm}\\sum_\\alpha p_\\alpha \\ket{\\psi_\\alpha}\\bra{\\psi_\\alpha}\\right)\\ket{\\lambda_n} \\\\\n",
    "&\\equiv&\\bra{\\lambda_n}\\rho\\ket{\\lambda_n}\\\\\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "El resultado anterior muestra la aparición en escena de un \\textit{nuevo operador} formado con los datos del colectivo aleatorio $\\{\\ket{\\psi_\\alpha},p_\\alpha\\}$  \n",
    "\\begin{equation} \\label{ec_fundamentos_operador_densidad_diag}\n",
    "\\boxed{\\rho = \\sum_\\alpha p_\\alpha \\ketbra{\\psi_\\alpha}{\\psi_\\alpha} = \\sum_\\alpha p_\\alpha P_\\alpha}\n",
    "\\end{equation}\n",
    "$\\rho ~$ se denomina \\textbf{matriz densidad} y consiste en una suma ponderada de proyectores sobre cada uno de los subespacios generados por los estados posibles. Este es el objeto matemático que caracteriza un estado mezcla. \n",
    "\n",
    "En particular, como acabamos de ver, la probabilidad de medir el autovalor $\\lambda$ es el \\textit{valor esperado} del operador densidad en dicho estado\n",
    "\\begin{equation}\n",
    "\\boxed{p(\\lambda_n) =\\langle \\rho \\rangle_{\\ket{\\lambda_n}} = \\bra{\\lambda_n }\\rho\\ket{\\lambda_n}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_gray2}{}\n",
    "\\textbf{Operador densidad}:\n",
    "\n",
    "Un operador, $\\rho$, podrá ser el operador densidad de un sistema si cumple los siguientes requisitos    \n",
    "\\begin{itemize}\n",
    "\\item es hermítico $\\rho = \\rho^\\dagger$\n",
    "\\item es semidefinido positivo\n",
    "\\item tiene traza unidad ${\\rm tr }\\rho = 1$ \n",
    "\\end{itemize}\n",
    "\n",
    "\\end{mybox_gray2}\n",
    "\n",
    "Claramente la expresión dada anteriormente cumple con todos estos requisitos. \n",
    "\\begin{itemize}\n",
    "\\item Hermiticidad: se ve gracias a que los $p_\\alpha$ son probabilidades (números reales)\n",
    "\\begin{equation}\n",
    "\\rho^\\dagger = \\left(\\sum_\\alpha p_\\alpha \\ketbra{\\psi_\\alpha}{\\psi_\\alpha}\\right)^\\dagger = \n",
    "\\sum_\\alpha p^*_\\alpha \\ketbra{\\psi_\\alpha}{\\psi_\\alpha} = \\rho\n",
    "\\end{equation}\n",
    "\n",
    "\\item De hecho escrito en esta base, la matriz que representa $\\rho$ es diagonal\n",
    "\\begin{equation}\n",
    "\\rho = \\begin{bmatrix} p_1& 0 & ... & 0 \\\\ 0 & p_2 & ... & 0 \\\\ & &\\vdots  & \\\\ 0 & 0 & \\cdots & p_n  \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "Por tanto los números $p_\\alpha\\geq 0$ son los autovalores, que son no-negativos, lo cuál caracteriza un operador semidefinido positivo. \n",
    "\n",
    "\\item Finalmente la traza es la unidad debido a que $p_\\alpha$ son probabilidades\n",
    "\\begin{equation}\n",
    "{\\rm Tr}\\, \\rho = \\sum_\\alpha p_\\alpha = 1\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "Es importante darse cuenta de que un estado mezcla \\textbf{no se puede escribir como un vector de estado}. Solo los estados puros pueden ser escritos así. \n",
    "\\vspace{0.3cm}\n",
    "\n",
    "Por ejemplo, en el caso que veíamos antes de un polarizador que generaba el estado $\\ket{+}$ con una probabilidad del 90\\%, este se comportaba como una variable aleatoria $ \\{\\{\\ket{+},0.9\\},\\{\\ket{-},0.1\\}\\}$. El estado que sale de este polarizador es un estado mezcla que se puede expresar con siguiente matriz densidad\n",
    "\\begin{equation}\n",
    "\\rho = \\Lc 0.9 \\ketbra{+}{+}\\Rc + \\Lc 0.1 \\ketbra{-}{-} \\Rc\n",
    "\\end{equation}\n",
    "Este estado \\textbf{no es el mismo} que el estado puro\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = \\sqrt{0.9} \\ket{+} + \\sqrt{0.1} \\ket{-}\n",
    "\\end{equation}\n",
    "Es más, podemos escribir la matriz densidad de este segundo estado para ver que es diferente:\n",
    "\\begin{align}\n",
    "\\rho_{\\ket{\\psi}} \n",
    "& =	\\ketbra{\\psi}{\\psi} \n",
    "= \\lp \\sqrt{0.9} \\ket{+} + \\sqrt{0.1} \\ket{-} \\rp \n",
    "\\lp \\sqrt{0.9} \\bra{+} + \\sqrt{0.1} \\bra{-} \\rp \\\\\n",
    "& = \\Lc 0.9 \\ketbra{+}{+} \\Rc + \\Lc 0.1 \\ketbra{-}{-} \\Rc + \\Lc \\sqrt{0.9}\\sqrt{0.1} \\ketbra{+}{-} \\Rc  + \\Lc \\sqrt{0.9}\\sqrt{0.1} \\ketbra{-}{+} \\Rc\n",
    "\\end{align}\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "La matriz densidad de un estado mezcla \\textbf{no tiene porque ser diagonal}. La Ec. (\\ref{ec_fundamentos_operador_densidad_diag}) es simplemente el caso en el que estamos en una base donde la matriz es diagonal.\n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\SubsubiIt{Matriz densidad de un estado puro}\n",
    "\n",
    "La matriz densidad es un formalismo más general que el del vector estado, que sólo se aplica en el caso de estados puros. En efecto, la matriz densidad asociada a un estado puro $\\ket{\\psi_0}$ se obtiene haciendo todas las probabilidades $p_{\\alpha\\neq 0}=0$ y $p_{0} = 1$. Entonces el colectivo $\\{\\ket{\\psi_0},p_0=1\\}$ tiene asociado el operador\n",
    "\\begin{equation}\n",
    "\\rho = \\ketbra{\\psi_0}{\\psi_0} = \\begin{bmatrix}1 &  & \\\\ & 0 & \\\\ & & \\ddots  \\end{bmatrix}\n",
    "\\end{equation}\n",
    "Es evidente que esta expresión cumple, a mayores, la propiedad que caracteriza a un \\textbf{proyector}\n",
    "\\begin{equation}\n",
    "\\rho^2 = \\rho\n",
    "\\end{equation}\n",
    "y esto es una ecuación que \\textit{sólo verifican las matrices densidad asociadas a estados puros}.\n",
    "\n",
    "\\textbf{Por el contrario}, para un estado mezcla podemos ver que $\\rho^2 \\neq \\rho$\n",
    "\\begin{equation}\n",
    "\\rho^2  = \\sum_\\alpha p_\\alpha^2 \\ketbra{\\psi_\\alpha}{\\psi_\\alpha} \\neq  \\sum_\\alpha p_\\alpha \\ketbra{\\psi_\\alpha}{\\psi_\\alpha} = \\rho\n",
    "\\end{equation}\n",
    "\n",
    "Podemos extraer esta información de forma \\textit{independiente de la base} usando la función traza  ${\\rm Tr}$\n",
    "\\begin{itemize}\n",
    "\\item Si $\\ket{\\psi_\\alpha}$ son vectores ortonormales,  ${\\rm Tr } \\rho = \\sum p_\\alpha = 1$ pero  ${\\rm Tr }\\rho^2 = \\sum_\\alpha p_\\alpha^2\\leq 1$\n",
    "\n",
    "\\item La igualdad ${\\rm Tr} \\rho^2=1$ sólo se producirá si  $p_\\alpha = 1$ para un solo $\\alpha$. \n",
    "\\end{itemize}\n",
    "\n",
    "\\Teorema{\n",
    "Un estado  $\\rho$ será \\textit{puro} (\\textit{mezcla}) sí y solo sí ${\\rm Tr } \\rho^2 = 1~~\n",
    "({\\rm Tr } \\rho^2 <1)$  \n",
    "}\n",
    "\n",
    "\\SubsubiIt{Estado máximalmente mezclado}\n",
    "\n",
    "En el extremo opuesto de un estado puro, encontramos un estado \\textbf{maximalmente mezclado}, en el cual \\textit{todos} los proyectores aparecen de manera equiprobable $\\{\\ket{\\psi_\\alpha},p_\\alpha = \\frac{1}{d}\\}, \\alpha = 1,...,d$\n",
    "\\begin{equation}\n",
    "\\rho = \\sum_{\\alpha=1}^d \\frac{1}{d} \\ket{\\psi_\\alpha}\\bra{\\psi_\\alpha} = \\frac{1}{d} I = \\begin{bmatrix}\\frac{1}{d} &  & & \\\\ & \\frac{1}{d} &  &\\\\ & & &\\ddots & \\\\ & & & & \\frac{1}{d} \\end{bmatrix}\n",
    "\\end{equation}\n",
    "Por tanto, es una matriz diagonal proporcional a la identidad.\n",
    "\n",
    "\\SubsubiIt{Estado mezcla parcial}\n",
    "\n",
    "Entre los dos extremos mencionados anteriormente, estado puro y estado maximalmente mezclado, se sitúa cualquier estado $\\rho$ genérico. Si escribimos\n",
    "\\begin{equation}\n",
    "\\rho = \\sum_{\\alpha} p_\\alpha \\ketbra{\\psi_\\alpha}{\\psi_\\alpha}\n",
    "\\end{equation}\n",
    "el grado de mezcla es proporcional a la uniformidad en la distribución de valores $p_\\alpha$. \n",
    "\n",
    "\\SubsubiIt{Estado de Gibbs}\n",
    "\n",
    "Un caso muy importante de mezcla parcial es el \\textbf{estado de Gibbs}, que describe un sistema cuando alcanza el \\textit{equilibrio término a una temperatura }$T$. En este caso, los estados $\\{\\ket{\\psi_\\alpha}= \\ket{E_\\alpha}\\}$ son la \\textit{base de autoestados del operador Hamiltoniano},\n",
    "\\begin{equation}\n",
    "H\\ket{E_\\alpha} = E_\\alpha \\ket{E_\\alpha}\n",
    "\\end{equation}\n",
    "y los autovalores $E_\\alpha$, con $\\alpha = 1,2...d$, son los \\textit{niveles de energía} del sistema. \n",
    "\n",
    "Cuando un sistema se encuentra en contacto con un baño térmico a temperatura $T$ el estado de energía no está bien definido, sino que es una mezcla denominada \\textbf{colectivo canónico}\n",
    "\\begin{equation}\n",
    "\\left\\{\\rule{0mm}{5mm}\\ket{E_\\alpha}, p_\\alpha = e^{-E_\\alpha/k_BT}\\right\\}\n",
    "\\end{equation}\n",
    "Los coeficientes $p_\\alpha = e^{-E_\\alpha/k_BT}$ se denominan \\textit{coeficientes de Boltzmann}  codifican la probabilidad  de hallarse en el estado (nivel de energía) $\\ket{E_\\alpha}$. \n",
    "\n",
    "La matriz densidad que describe el estado de este sistema es el denominado \\textbf{estado de Gibbs}\n",
    "\\begin{equation}\n",
    "\\rho(T) = \\frac{1}{Z}\\sum_{\\alpha=1}^d e^{-E_\\alpha/k_BT} \\ket{E_\\alpha}\\bra{E_\\alpha} = \\frac{1}{Z} \\begin{bmatrix}e^{-E_0/k_BT}&  & \\\\ & e^{-E_1/k_BT} & \\\\ &  &\\ddots  \\end{bmatrix} \\, ,\n",
    "\\end{equation}\n",
    "donde $k_B$ es la constante de Bolzmann, y  $Z =\\sum_\\alpha e^{-E_\\alpha/k_BT}$ es la normalización necesaria para que ${\\rm tr}\\rho(T) = 1$. La \\textbf{energía del sistema} a cada temperatura, vendrá dada por un promedio sobre todos los autoestados pesados por la matriz densidad a dicha temperatura\n",
    "\\begin{equation}\n",
    "\\langle E \\rangle_T = {\\rm tr} (\\rho(T) H)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{mybox_blue}{Nota: autoestados del Hamiltoniano}\n",
    "Como ya comentamos, un autoestado de un operador es un estado donde el observable (operador) toma un valor concreto (el autovalor). Los autoestados del operador hamiltoniano son especiales, pues son los \\textbf{niveles de energía}. Es decir, los autovalores son las \\textbf{energías}. \n",
    "\\end{mybox_blue}\n",
    "\n",
    "\\Ejercicio{\n",
    "Probar  que recuperamos los casos puro y maximalmente mezclado en los límites siguientes\n",
    "\\begin{itemize}\n",
    "\\item $\\rho(T=0) = \\ketbra{E_0}{E_0}$\n",
    "\\item $\\rho(T=\\infty) = \\frac{1}{d} I$\n",
    "\\end{itemize}\n",
    "}\n",
    "\n",
    "\\Ejercicio{\n",
    "Genera aleatoriamente un estado de Gibbs a temperatura $T$ y grafica los valores de $p_\\alpha(T)$\n",
    "para distintos valores de $T$ (toma $k_B=1$).\n",
    "}\n",
    "\n",
    "\\SubsubiIt{Entropía de Von Neumann}\n",
    "\n",
    "La entropía de Von Neumann $S(\\rho)$ es una medida del \\textit{grado de mezcla} que hay en una matriz densidad. Se define  como sigue\n",
    "\\begin{equation}\n",
    "S(\\rho) = -{\\rm tr} (\\rho \\log \\rho )\\, .\n",
    "\\end{equation}\n",
    "Usando la descomposición espectral de $\\rho = \\sum_\\alpha p_\\alpha \\ket{\\psi_\\alpha}\\bra{\\psi_\\alpha}  \\, ,$ donde  $\\sum_i p_\\alpha =1$, la entropía de Von Neumann resulta ser \n",
    "\\begin{equation}\n",
    "S(\\rho) = -\\sum_\\alpha p_\\alpha \\log p_\\alpha\n",
    "\\end{equation}\n",
    "es decir, la entropía de la variable aleatoria $\\{\\ket{\\psi_\\alpha},p_\\alpha\\}$.\n",
    "\n",
    "\\begin{itemize}\n",
    "\\item Vemos que $S=0$ cuando el estado que representa $\\rho$ es puro ya que $p_\\alpha = \\delta_{\\alpha1}$. \n",
    "\\item Por el contrario, en un estado máximamente mezclado $p_\\alpha= 1/d$, $S = \\log d$ alcanza su máximo valor.\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsection{Medidas en estados mezcla}\n",
    "\n",
    "El escenario ahora es un estado general $\\rho$ sobre el que efectuamos una medida asociada a un observable que admite una descomposición espectral\n",
    "\\begin{equation}\n",
    "A = \\sum_n \\lambda_n \\ketbra{\\lambda_n}{\\lambda_n} = \\sum_n \\lambda_n P_n\n",
    "\\end{equation}\n",
    "\n",
    "Según el axioma del colapso de la función de onda, después de una medida, si el resultado ha sido $\\lambda_n$, el estado mezcla $\\rho$ colapsa al estado puro $\\rho\\to \\ketbra{\\lambda_n}{\\lambda_n}$. En términos de matriz densidad\n",
    "\\begin{equation}\n",
    "\\rho \\to \\ketbra{\\lambda_n}{\\lambda_n} = \\frac{P_n\\rho P_n}{p(\\lambda_n)} \\, .\n",
    "\\end{equation}\n",
    "Desarrollando un poco el numerador\n",
    "\\begin{eqnarray}\n",
    "P_n \\rho P_n &=& \\ketbra{\\lambda_n}{\\lambda_n} \\rho \\ketbra{\\lambda_n}{\\lambda_n}  = p(\\lambda_n) \\ketbra{\\lambda_n}{\\lambda_n}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Vamos a manipular un poco la expresión de la probabilidad que hemos visto en la Ec. (\\ref{ec_fundamentos_op_dens_prob}):\n",
    "\\begin{eqnarray}\n",
    "p(\\lambda_n) &=& \\bra{\\lambda_n}\\rho\\ket{\\lambda_n} = \\sum_i  \\braket{\\lambda_n}{i}\\bra{i}\\rho\\ket{\\lambda_n} =\n",
    "\\sum_i \\bra{i}\\rho\\ket{\\lambda_n}\\braket{\\lambda_n}{i} = \\sum_i \\bra{i}\\left( \\rho\\ket{\\lambda_n}\\bra{\\lambda_n}\\rule{0mm}{5mm}\\right)\\ket{i} \\nonumber\\\\\n",
    "&\\equiv& {\\rm tr}(\\rho P_n )\n",
    "\\end{eqnarray}\n",
    "Es decir,\n",
    "\\begin{equation}\n",
    "\\boxed{p(\\lambda_n) = \\bra{\\lambda_n}\\rho\\ket{\\lambda_n} = {\\rm tr} (\\rho P_n)}\n",
    "\\end{equation}\n",
    "\n",
    "Ahora podemos hallar el valor esperado de $A$\n",
    "\\begin{equation}\n",
    "\\langle A\\rangle_\\rho = \\sum_n \\lambda_n p(\\lambda_n) = \\sum_n \\lambda_n {\\rm tr}(\\rho P_n ) \n",
    "= {\\rm tr} \\left( \\rho \\sum_n \\lambda_n P_n \\right) = {\\rm tr }(\\rho A)\n",
    "\\end{equation}\n",
    "\n",
    "\\Teorema{\n",
    "El valor esperado de un observable $A$ en un estado general $\\rho$ es \n",
    "\\begin{equation}\n",
    "\\langle A\\rangle_\\rho = {\\rm tr}(\\rho A) \n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "\\subsection{Estado mezcla bipartito}\n",
    "\n",
    "De forma similar, podemos definir la matriz densidad en sistemas multipartitos. Si consideramos por simplicidad un espacio $\\mathcal{H}=\\mathcal{H}_1\\otimes\\mathcal{H}_2$, el siguiente operador $\\rho \\in {\\rm L}(\\mathcal{H})$ \n",
    "\\begin{equation}\n",
    "\\rho=\\sum_{ia,jb}\\rho_{ia,jb}\\ketbra{e_{ia}}{e_{jb}}\n",
    "\\end{equation}\n",
    "podrá describir el estado mezcla de un sistema bipartito si la matriz $\\rho_{ia,jb}$ verifica las tres condiciones que definen un operador densidad.  \n",
    "\n",
    "\\begin{mybox_blue}{Nota}\n",
    "No confundir estado \\textbf{mezcla} con estado \\textbf{entrelazado} Un estado $\\ket{\\psi}\\in \\mathcal{H}_1\\otimes\\mathcal{H}_2$ puede ser entrelazado, y aun así $\\rho = \\ketbra{\\psi}{\\psi}$ ser puro.\n",
    "\\end{mybox_blue}\n",
    "En el caso de vectores $\\ket{\\psi} \\in \\mathcal{H}_1\\otimes \\mathcal{H}_2$, ya hemos visto la división que existe entre vectores factorizables y entrelazados. Para estados $\\rho \\in {\\rm L}(\\mathcal{H}_1\\otimes \\mathcal{H}_2)$ tenemos más posibilidades:\n",
    "\\begin{itemize}\n",
    "\\item \\textbf{Factorizable}: si $\\rho$ es un operador factorizable \n",
    "\\begin{equation}\n",
    "\\rho = \\rho_1\\otimes \\rho_2\\, .\n",
    "\\end{equation}\n",
    "En este caso, $\\rho_{ia,jb} = \\rho_{1,ij}\\rho_{2,ab}$ y decimos que, en este estado, los subsistemas 1 y 2 están \\textit{descorrelacionados}. \n",
    "\n",
    "\\item \\textbf{Separable}: Si es combinación lineal de operadores factorizables\n",
    "\\begin{equation}\n",
    "\\rho=\\sum_a p_a \\, \\rho_{1a}\\otimes\\rho_{2a}\n",
    "\\end{equation}\n",
    "con $p_a\\in [0,1]$ y $\\sum_a p_a = 1$. En este caso existen correlaciones clásicas entre ambos sistemas.\n",
    "\n",
    "\\item \\textbf{No-separable:} en cualquier otro caso. En este caso hay correlaciones clásicas y cuánticas entre ambos sistemas.\n",
    "\n",
    "\\end{itemize}\n",
    "\n",
    "\\SubsubiIt{Traza parcial}\n",
    "\n",
    "A partir de un estado bipartito $\\rho \\in {\\rm L}(\\mathcal{H}_1\\otimes\\mathcal{H}_2)$  podemos definir estados $\\rho_1 \\in {\\rm L}(\\mathcal{H}_1)$ y $\\rho_2 \\in {\\rm L}(\\mathcal{H}_2)$ mediante la operación de \\textit{traza parcial}\n",
    "\\begin{equation}\n",
    "\\rho_1 = {\\rm Tr}_{\\mathcal{H}_2}\\rho = \\sum_{a=1}^{d_2} \\bra{e_a^{(2)}} \\rho \\ket{e_a^{(2)}}\\quad , \\quad \\rho_2 = {\\rm Tr}_{\\mathcal{H}_1}\\rho = \\sum_{a=1}^{d_1} \\bra{e_a^{(1)}} \\rho \\ket{e_a^{(1)}}\n",
    "\\end{equation}\n",
    "Sobre las matriz densidad $\\rho_{ia,jb}$ las trazas parciales dan matrices \n",
    "\\begin{equation}\n",
    "\\rho_{1,ij}= \\sum_{a=1}^{d_2} \\rho_{ia,ja} ~~~~,~~~~ \\rho_{2,ab} = \\sum_{i=1}^{d_1} \\rho_{ia,ib}\n",
    "\\end{equation}\n",
    "\n",
    "\\Ejercicio{\n",
    "Sea un estado bipartito $\\rho \\in {\\rm L}(\\mathcal{H}_1\\otimes\\mathcal{H}_2)$ y $A=A_1\\otimes I$ un observable que sólo depende del subsistema $1$. Demuestra que \n",
    "\\begin{equation}\n",
    "\\langle A \\rangle_\\rho  = {\\rm tr} (\\rho_1 A_1)\n",
    "\\end{equation}\n",
    "}\n",
    "\n",
    "Supongamos un \\textit{estado puro bipartito}  $\\rho=\\ketbra{\\psi}{\\psi}\\, \\in \\,  {\\rm L}(\\mathcal{H}_1\\otimes\\mathcal{H}_2)~\\Rightarrow ~ \\rho=\\rho^2$ es un proyector. Después de tomar la traza parcial  $\\rho\\to \\rho_1 = {\\rm tr}_{\\mathcal{H}_2}\\rho$ hay dos opciones\n",
    "\\begin{itemize}\n",
    "\\item Si $\\ket{\\psi}$ es \\textit{factorizable} $\\Rightarrow $ $\\rho_1$ permanece \\textit{puro}\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = \\ket{\\varphi}\\otimes \\ket{\\phi} ~~~ \\Rightarrow ~~~ \\rho_1 = {\\rm Tr}_{\\mathcal{H}_2}\\ketbra{\\psi}{\\psi} = \\ketbra{\\varphi}{\\varphi} = \\rho_1^2\n",
    "\\end{equation}\n",
    "\n",
    "\\item Si $\\ket{\\psi}$ es \\textit{entrelazado} $\\Rightarrow \\rho_1$ se vuelve \\textit{mezclado}. Podemos ver esto con la descomposición de Schmidt\n",
    "\\begin{equation}\n",
    "\\ket{\\psi} = \\sum_{a=1}^r \\sqrt{s_a}\\ket{f_a}\\ket{\\tilde f_a} ~~~\\Rightarrow ~~~ \\rho_1 = {\\rm Tr}_{\\mathcal{H}_2}\\ketbra{\\psi}{\\psi} = \\sum_{a=1}^r s_a \\ket{f_a}\\bra{f_a} \\neq \\rho_1^2\n",
    "\\end{equation}\n",
    "\n",
    "\\end{itemize}			\n",
    "\n",
    "En resumen: \\textbf{bajo \\textit{traza parcial}, el entrelazamiento induce \\textit{mezcla}}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534e04c",
   "metadata": {},
   "source": [
    "<figure><center>\n",
    "<img   src=\"https://quantumspain-project.es/wp-content/uploads/2022/11/Logo_QS_EspanaDigital.png\" align=center  width=\"2000px\"/>\n",
    "</center></figure>\n",
    "\n",
    "<center>\n",
    "<img align=\"left\" src=\"https://quantumspain-project.es/wp-content/uploads/2024/02/Banner-QS_GOB_v2.png\" width=\"1000px\" />\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
